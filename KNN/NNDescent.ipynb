{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNDescent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4s3np_UZreV"
      },
      "source": [
        "Rewritten NNDescent algorithm using matrices instead of dictionaries.\n",
        "\n",
        "TODO: Remove for-loops where possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlgkAi3gaby7"
      },
      "source": [
        "!pip install pykeops[colab] > install.log"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v23EimYwHprW"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "import matplotlib.pyplot  as plt\n",
        "from pykeops.torch import LazyTensor\n",
        "from pykeops.torch.cluster import cluster_ranges_centroids, from_matrix, sort_clusters\n",
        "#from collections import defaultdict\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "  torch.cuda.synchronize()\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device  = torch.device('cpu')\n",
        "\n",
        "class NNDescent:\n",
        "  def __init__(self, data, k=2, trees=5, init=4, leaf_multiplier=100, LT=False, a=10):\n",
        "    # The data is a (N x d) matrix with N instances of d-dimensional points\n",
        "    self.data = data.to(device)\n",
        "    N = data.shape[0]\n",
        "    self.k = k\n",
        "    self.a = a\n",
        "    self.numtrees = trees\n",
        "    self.big_leaves = None\n",
        "    \n",
        "    # A 2D tensor representing a directed graph.\n",
        "    # The value a = graph[i,j] represents an edge from point x_i to x_a.\n",
        "    self.graph = torch.zeros(size=[N, k], dtype=torch.long)\n",
        "    \n",
        "    # Initialize graph randomly or with forest\n",
        "    if init == 1:\n",
        "      self.initialize_graph_randomly()\n",
        "    elif init == 2:\n",
        "      self.initialize_graph_big_random(data)\n",
        "    elif init == 3:\n",
        "      self.initialize_graph_forest(data, leaf_multiplier)\n",
        "    elif init == 4:\n",
        "      self.initialize_graph_clusters(data, leaf_multiplier, LT)\n",
        "    \n",
        "    # A set of tuples (i,j) of indices for which the distance has already been calculated.\n",
        "    self.explored_edges = set()\n",
        "\n",
        "    # A 2D tensor representing the distance between point x_i and x_graph[i,j]\n",
        "    # self.k_distances = torch.zeros([N, k])\n",
        "    # self.calculate_all_distances()\n",
        "    \n",
        "\n",
        "  def initialize_graph_randomly(self):\n",
        "    '''\n",
        "    Initializes self.graph with random values such that each point has k distinct neighbors\n",
        "    '''\n",
        "    N, k = self.graph.shape\n",
        "    # Initialize graph randomly, removing self-loops\n",
        "    self.graph = torch.randint(high = N-1, size=[N,k], dtype=torch.long)\n",
        "    row_indices = torch.arange(N).unsqueeze(1).repeat(1,k)\n",
        "    self.graph[self.graph>=row_indices] += 1\n",
        "\n",
        "  def initialize_graph_big_random(self, data):\n",
        "    '''\n",
        "    Initializes self.graph randomly, but with more neighbours at the start\n",
        "    '''\n",
        "    N, k = self.graph.shape\n",
        "    temp_graph = torch.tensor([])\n",
        "        \n",
        "    # make 'trees', combine into giant graph with each element (row) having k * num_trees neighbours\n",
        "    # this is a small for loop - numtrees and k << datapoints\n",
        "    for j in range(self.numtrees):\n",
        "      tree_graph = torch.tensor([])\n",
        "      for i in range(k):\n",
        "        tree_graph = torch.cat((tree_graph,torch.randperm(N)),0) # generate randomly shuffled list of N indices\n",
        "      tree_graph = tree_graph.reshape(-1,k) # creates a N x k tensor with N indices, each appearing k times. This represents 1 'tree'\n",
        "      temp_graph = torch.cat((temp_graph,tree_graph),1) # combine into giant N x (k*num_trees) tensor. This represents the forest\n",
        "    \n",
        "    # find KNN for each row in giant graph\n",
        "    # TODO - implement the below without a for loop\n",
        "    for i, row in enumerate(temp_graph):\n",
        "      temp_row = torch.unique(row).type(torch.LongTensor) # remove duplicates\n",
        "      temp_row = temp_row[temp_row != i] # remove self\n",
        "      \n",
        "      temp_points = data[temp_row,:] # pick out elements from dataset\n",
        "      distances = dist_bulk(temp_points,data[i]) # Euclidean distances\n",
        "      indices = distances.topk(k=self.k, largest=False).indices # find indices of KNN\n",
        "      self.graph[i] = temp_row[indices] # assign KNN to graph\n",
        "      \n",
        "  def initialize_graph_forest(self, data, leaf_multiplier):\n",
        "    '''\n",
        "    Initializes self.graph with a forest of random trees, such that each point has k distinct neighbors\n",
        "    '''\n",
        "    N, k = self.graph.shape\n",
        "    dim = data.shape[1]\n",
        "    \n",
        "    temp_graph = torch.tensor(())\n",
        "    for j in range(self.numtrees):\n",
        "      # Create trees, obtain leaves\n",
        "      t = tree(data, k = k*leaf_multiplier)\n",
        "      \n",
        "      # Create temporary graph, 1 for each tree\n",
        "      # Leaves are of uneven size; select smallest leaf size as graph size\n",
        "      cols = min([len(leaf) for leaf in t.leaves])\n",
        "      rows = len(t.leaves)\n",
        "      tree_graph = torch.zeros((N, cols))\n",
        "      leaves = torch.tensor(())\n",
        "      idx_update = torch.tensor(())\n",
        "      \n",
        "      # Update graph using leaves\n",
        "      for leaf in t.leaves:\n",
        "        temp_idx = torch.as_strided(torch.tensor(leaf).repeat(1,2),size=[len(leaf),cols],stride=[1,1],storage_offset=1)\n",
        "        tree_graph[leaf,:] = temp_idx.float() # update graph. a lot of overwriting\n",
        "      # Concatenate all graphs from all trees into 1 giant graph\n",
        "      temp_graph = torch.cat((temp_graph,tree_graph), 1)\n",
        "\n",
        "      # Add the first tree's big_leaves to the NNDescent's big_leaves\n",
        "      if j==0:\n",
        "          self.big_leaves = torch.LongTensor(t.big_leaves)\n",
        "    \n",
        "    warning_count = 0 # number of indices for which some neighbours are random\n",
        "    # find KNN for each row in giant graph\n",
        "    # TODO - implement the below without a for loop\n",
        "    for i, row in enumerate(temp_graph):\n",
        "      temp_row = torch.unique(row).type(torch.LongTensor) # remove duplicates\n",
        "      temp_row = temp_row[temp_row != i] # remove self\n",
        "      \n",
        "      temp_points = data[temp_row,:] # pick out elements from dataset\n",
        "      d=((data[i].reshape(1,dim).unsqueeze(1)-temp_points.unsqueeze(0))**2).sum(-1)\n",
        "      distances, indices = torch.sort(d,dim=1)\n",
        "      indices = indices.flatten()[:k]\n",
        "      \n",
        "      indices = temp_row[indices]\n",
        "      \n",
        "      # pad with random indices if there are not enough neighbours\n",
        "      warning = False # warning flag\n",
        "      while len(indices) < k:\n",
        "        pad = torch.randint(high = N-1, size=[k-len(indices),], dtype=torch.long)\n",
        "        indices = torch.cat((indices,pad))\n",
        "        indices = torch.unique(indices).type(torch.LongTensor) # remove duplicates\n",
        "        indices = indices[indices != i] # remove self\n",
        "        warning = True\n",
        "\n",
        "      self.graph[i] = indices # assign KNN to graph\n",
        "      \n",
        "      if warning:\n",
        "        warning_count += 1\n",
        "    \n",
        "    if warning_count:\n",
        "      print(\"WARNING!\",warning_count,\" INDICES ARE RANDOM!\")\n",
        "\n",
        "      \n",
        "  def initialize_graph_clusters(self, data, leaf_multiplier, LT=False):\n",
        "    N,dim = data.shape\n",
        "    k = self.k\n",
        "    a = self.a\n",
        "    self.clusters = torch.ones(N,)*-1\n",
        "\n",
        "    data = data.to(device)\n",
        "    \n",
        "    # Create trees, obtain leaves\n",
        "    t = tree(data, k, leaf_multiplier, LT)\n",
        "    \n",
        "    self.leaves = len(t.leaves)\n",
        "\n",
        "    # Assign each point to a cluster, 1 cluster per tree in forest\n",
        "    for i, leaf in enumerate(t.leaves):\n",
        "      self.clusters[leaf] = i\n",
        "    self.centroids = t.centroids.clone()\n",
        "    \n",
        "    # Find nearest centroids\n",
        "    x_LT=LazyTensor(self.centroids.unsqueeze(1).to(device))\n",
        "    y_LT=LazyTensor(self.centroids.unsqueeze(0).to(device))\n",
        "    d=((x_LT-y_LT)**2).sum(-1)\n",
        "    indices = d.argKmin(K=a+1,dim=1).long()\n",
        "    self.centroids_neighbours = indices[:,1:].long()\n",
        "\n",
        "    self.graph = self.centroids_neighbours\n",
        "    \n",
        "    # Assign big_leaves by searching for the correct cluster\n",
        "    self.big_leaves = torch.LongTensor(t.big_leaves)\n",
        "    for i, index in enumerate(self.big_leaves):\n",
        "      self.big_leaves[i] = self.clusters[index]\n",
        "    return\n",
        "      \n",
        "  def calculate_all_distances(self):\n",
        "    '''\n",
        "    Updates the distances (self.k_distances) of the edges found in self.graph.\n",
        "    '''\n",
        "    # Note: Start with for loop for simplicity. TODO: Try to remove loop.\n",
        "    for i, row in enumerate(self.graph):\n",
        "      # Indices of current k neighbors in self.graph\n",
        "      neighbor_indices = [(i,int(r)) for r in row]\n",
        "\n",
        "      # The distances of those neighbors are saved in k_distances\n",
        "      self.k_distances[i] = torch.Tensor([dist(self.data[a],self.data[b]) for a,b in neighbor_indices])\n",
        "\n",
        "      # Add pairs to explored_edges set\n",
        "      self.explored_edges.update(neighbor_indices) \n",
        "    \n",
        "\n",
        "  def update_graph(self, iter=5):\n",
        "    '''\n",
        "      Updates the graph using algorithm: https://pynndescent.readthedocs.io/en/latest/how_pynndescent_works.html\n",
        "    '''\n",
        "    # [STEP 1: Start with random graph.] Iterate\n",
        "    start = time.time()\n",
        "    for it in range(iter):\n",
        "#       print(\"Iteration number\",it,\"with average distance of\",torch.mean(self.k_distances).item(),\"Took\", time.time()-start,\"seconds.\")\n",
        "      has_changed = False\n",
        "\n",
        "      # [STEP 2: For each node:] (TODO: Investigate whether this can be vectorized.)\n",
        "      for i, neighbors in enumerate(self.graph):\n",
        "        # Distances of current neighbors\n",
        "        dist_current_neighbors = self.k_distances[i]\n",
        "\n",
        "        # [STEP 3:Â Measure distance from the node to the neighbors of its neighbors]\n",
        "        # Find neighbors of neighbors\n",
        "        potential_neighbors = {a.item() for a in self.graph[neighbors].flatten() \\\n",
        "                               if a not in neighbors and a!=i and (i,int(a)) not in self.explored_edges}\n",
        "        potential_distances = torch.Tensor([dist(self.data[i],self.data[n]) for n in potential_neighbors])\n",
        "        self.explored_edges.update([(i,int(r)) for r in potential_neighbors])\n",
        "\n",
        "        # Concatenate potential neighbors to list of neighbors (indices and distances)\n",
        "        cat_idx = torch.cat([neighbors, torch.Tensor(list(potential_neighbors))])\n",
        "        cat_dist = torch.cat([self.k_distances[i], potential_distances])\n",
        "\n",
        "        # [STEP 4: If any are closer, then update the graph accordingly, and only keep the k closest]\n",
        "        # Sort using torch.sort(), which also returns sorted indices\n",
        "        dist_sorted, idx = torch.sort(cat_dist)\n",
        "        if torch.max(idx[:self.k]) >= self.k:\n",
        "          has_changed = True\n",
        "          self.graph[i] = cat_idx[idx[:self.k]]\n",
        "          self.k_distances[i] = dist_sorted[:self.k]\n",
        "        \n",
        "      # [STEP 5: If any changes were made, repeat iteration, otherwise stop]\n",
        "#       if not has_changed:\n",
        "#         print(\"Nothing changed in iteration\",it)\n",
        "#         break\n",
        "#     print(\"Done.\")\n",
        "\n",
        "  def k_nearest_graph_search(self,X,max_num_steps = 100, tree_init = True):\n",
        "    '''\n",
        "    Gets the k nearest neighbors of input x according to the graph, using this algorithm:\n",
        "      https://pynndescent.readthedocs.io/en/latest/how_pynndescent_works.html#Searching-using-a-nearest-neighbor-graph\n",
        "    Input: \n",
        "      x - a torch tensor of shape (N,d), where N is the number of dimentions of the input data.\n",
        "    Output:\n",
        "      The indices of the k nearest neighbors according using graph search with random initialization.\n",
        "    '''\n",
        "    # N datapoints of dimension d\n",
        "    N, d = X.shape\n",
        "    X = X.to(device)\n",
        "    \n",
        "    k = self.a\n",
        "    # Boolean mask to keep track of those points whose search is still ongoing\n",
        "    is_active = (torch.ones(N)==1).to(device)\n",
        "    \n",
        "    # If graph was initialized using trees, we can use information from there to initialize in a diversed manner.\n",
        "    if self.big_leaves is not None and tree_init:\n",
        "        candidate_idx = self.big_leaves.unsqueeze(0).repeat(N,1).to(device) # Shape: (N,32)\n",
        "    else:\n",
        "        # Random initialization for starting points of search. \n",
        "        candidate_idx = torch.randint(high=self.graph.shape[0], size=[N, k+1], dtype=torch.long).to(device)\n",
        "  \n",
        "    # Sort the candidates by distance from X\n",
        "    distances = ((self.centroids[candidate_idx] - X.unsqueeze(1))**2).sum(-1)\n",
        "    sorted, idx = torch.sort(distances, dim=1)\n",
        "    candidate_idx = torch.gather(candidate_idx, dim=1,index=idx)\n",
        "    # Truncate to k+1 nearest\n",
        "    candidate_idx = candidate_idx[:,:(k+1)]\n",
        "    \n",
        "    # Track the nodes we have explored already, in N x num_explored tensor\n",
        "    num_explored = self.k*2\n",
        "    explored = torch.full(size=[N,num_explored],fill_value=-1).to(device)\n",
        "\n",
        "    start = time.time()\n",
        "    # The initialization of candidates and explored set is done. Now we can search.\n",
        "    count = 0\n",
        "    while count < max_num_steps:\n",
        "        # print(\"Step\",count,\"- Search is completed for\",1-torch.mean(1.0*is_active).item(),\"- this step took\",time.time()-start,\"s\")\n",
        "        start=time.time()\n",
        "    \n",
        "        # [2. Look at nodes connected by an edge to the best untried node in graph]\n",
        "        # diff_bool.shape is (M, k+1, num_explored), where M is the number of active searches\n",
        "        diff_bool = (candidate_idx[is_active].unsqueeze(2) - explored[is_active].unsqueeze(1) == 0)\n",
        "        in_explored = torch.any(diff_bool, dim=2)\n",
        "        # batch_active is true for those who haven't been fully explored in the current batch\n",
        "        batch_active = ~torch.all(in_explored[:,:-1], dim=1)\n",
        "\n",
        "        # Update is_active mask. If none are active, break search\n",
        "        is_active[is_active.clone()] = batch_active\n",
        "        if not is_active.any():\n",
        "            break\n",
        "\n",
        "        # first_unexplored has indices of first unexplored element per row\n",
        "        first_unexplored = torch.max(~in_explored[batch_active],dim=1)[1].unsqueeze(1) \n",
        "        # Unexplored nodes to be expanded\n",
        "        unexplored_idx = torch.gather(candidate_idx[is_active], dim=1, index=first_unexplored).squeeze(-1)\n",
        "        explored[is_active,(count%num_explored)] = unexplored_idx\n",
        "    \n",
        "        # [3. Add all these nodes to our potential candidate pool]\n",
        "        # Add neighbors of the first unexplored point to the list of candidates\n",
        "        expanded_idx = torch.cat((self.graph[unexplored_idx],candidate_idx[is_active]), dim=1) \n",
        "    \n",
        "        # To avoid repeats, we use Hudson's unwanted_indices method to find repeats\n",
        "        expanded_idx = torch.sort(expanded_idx)[0]\n",
        "        shift = torch.cat((torch.full((len(expanded_idx),1),-1).to(device),torch.sort(expanded_idx,dim=1)[0][:,:-1]),dim=1)\n",
        "        unwanted_indices = (expanded_idx==shift)\n",
        "    \n",
        "        # [4. Sort by closeness].\n",
        "        distances = ((self.centroids[expanded_idx] - X[is_active].unsqueeze(1))**2).sum(-1)\n",
        "        # print(distances.max())\n",
        "        distances[unwanted_indices] += float('inf')\n",
        "        sorted, idx = torch.sort(distances,dim=1)\n",
        "        expanded_idx = torch.gather(expanded_idx,dim=1,index=idx)\n",
        "    \n",
        "        # [5. Truncate to k+1 best]\n",
        "        candidate_idx[is_active] = expanded_idx[:,:(k+1)] \n",
        "        \n",
        "        # [6. Return to step 2. If we have already tried all candidates in pool, we stop in the if not unexplored]\n",
        "        count += 1\n",
        "    \n",
        "    # Return the k candidates\n",
        "    print(\"Graph search finished after\",count,\"steps. Finished for:\",1-torch.mean(1.0*is_active).item())\n",
        "    return candidate_idx[:,:-1]\n",
        "\n",
        "  def predict(self,x):\n",
        "    '''\n",
        "    Predict output using tree. Hasn't been implemented yet. Needs labels y.\n",
        "    '''\n",
        "    pass\n",
        "\n",
        "  def final_brute_force(self, nearest_clusters, query_pts):\n",
        "    return self._final_brute_force(nearest_clusters,query_pts)\n",
        "\n",
        "  def _final_brute_force(self, nearest_clusters, query_pts):\n",
        "    if use_cuda:\n",
        "      torch.cuda.synchronize()\n",
        "    k = self.k\n",
        "    x = self.data.to(device)\n",
        "    x_labels = self.clusters.long()\n",
        "    y = query_pts.to(device)\n",
        "    y_labels = nearest_clusters[:,0]\n",
        "\n",
        "    x = x.contiguous()\n",
        "    y = y.contiguous()\n",
        "    x_labels = x_labels.to(device)\n",
        "    y_labels = y_labels.to(device)\n",
        "\n",
        "    clusters, a = self.graph.shape\n",
        "    r = torch.arange(clusters).repeat(a,1).T.reshape(-1).long()\n",
        "    keep = torch.zeros([clusters,clusters], dtype=torch.bool).to(device)\n",
        "    keep[r,self.graph.flatten()] = True\n",
        "    keep += torch.eye(clusters).bool().to(device)\n",
        "\n",
        "    x_ranges, x_centroids, _ = cluster_ranges_centroids(x, x_labels)\n",
        "    y_ranges, y_centroids, _ = cluster_ranges_centroids(y, y_labels)\n",
        "\n",
        "    x, x_labels = self.__sort_clusters(x, x_labels, store_x=True)\n",
        "    y, y_labels = self.__sort_clusters(y, y_labels, store_x=False)\n",
        "\n",
        "    x_LT = LazyTensor(x.unsqueeze(0).to(device).contiguous())\n",
        "    y_LT = LazyTensor(y.unsqueeze(1).to(device).contiguous())\n",
        "    D_ij = ((y_LT-x_LT)**2).sum(-1)\n",
        "    \n",
        "    x_ranges = x_ranges.to(device)\n",
        "    y_ranges = y_ranges.to(device)\n",
        "    ranges_ij = from_matrix(y_ranges, x_ranges, keep)\n",
        "    D_ij.ranges = ranges_ij\n",
        "    nn = D_ij.argKmin(K=k,axis=1)\n",
        "    return self.__unsort(nn)\n",
        "\n",
        "  def __sort_clusters(self,x,lab,store_x=True):\n",
        "    lab, perm = torch.sort(lab.view(-1))\n",
        "    if store_x:\n",
        "      self.__x_perm=perm \n",
        "    else:\n",
        "      self.__y_perm=perm\n",
        "    return x[perm],lab\n",
        "\n",
        "  def __unsort(self,nn):\n",
        "    return torch.index_select(self.__x_perm[nn],0,self.__y_perm.argsort())\n",
        "    \n",
        "    \n",
        "def dist(x,y):\n",
        "  # Square of euclidian distance. Skip the root for faster computation.\n",
        "  return torch.sum((x-y)**2)\n",
        "\n",
        "def dist_bulk(x,y):\n",
        "  # Square of euclidian distance. Skip the root for faster computation.\n",
        "  # For datasets\n",
        "  return ((x-y)**2).sum(-1)\n",
        "\n",
        "def dot_product(x, v):\n",
        "  # Calculate dot product between matrix x and vector v using LazyTensors\n",
        "  v_LT = LazyTensor(v.view(1,1,-1))\n",
        "  x_LT = LazyTensor(x.unsqueeze(0))\n",
        "  return (v_LT|x_LT).sum_reduction(axis=0).flatten()\n",
        "\n",
        "class tree: # NN clusters tree\n",
        "  '''\n",
        "  Random projection tree class that splits the data evenly per split\n",
        "  Each split is performed by calculating the projection distance of each datapoint to a random unit vector\n",
        "  The datapoints are then split by the median of of these projection distances\n",
        "  The indices of the datapoints are stored in tree.leaves, as a nested list\n",
        "  '''\n",
        "  def __init__(self, x, k=5, leaf_multiplier=1, LT=False):\n",
        "    self.min_size = k * leaf_multiplier\n",
        "    self.leaves = []\n",
        "    self.sizes = []\n",
        "    self.centroids = torch.tensor(()).to(device)\n",
        "    self.big_leaves = [] # leaves at depth = 5\n",
        "    indices = torch.arange(x.shape[0])\n",
        "\n",
        "    self.dim = x.shape[1]\n",
        "    self.data = x.to(device)\n",
        "    self.LT = LT # Boolean to choose LT or torch initialization\n",
        "\n",
        "    self.tree = self.make_tree(indices, depth = 0)\n",
        "    self.centroids = self.centroids.reshape(-1,x.shape[1])\n",
        "\n",
        "  def make_tree(self, indices, depth):\n",
        "    if depth == 5: # add to big_leaves if depth=5\n",
        "      self.big_leaves.append(int(indices[0]))\n",
        "    if indices.shape[0] > self.min_size:\n",
        "      v = self.choose_rule().to(device)\n",
        "\n",
        "      if self.LT:\n",
        "        distances = dot_product(self.data[indices],v) # create list of projection distances\n",
        "      else:\n",
        "        distances = torch.tensordot(self.data[indices],v,dims=1) # create list of projection distances\n",
        "\n",
        "      median = torch.median(distances)\n",
        "      left_bool = distances <= median # create boolean array where entries are true if distance <= median\n",
        "      self.make_tree(indices[left_bool], depth+1)\n",
        "      self.make_tree(indices[~left_bool], depth+1)\n",
        "    elif indices.shape[0] != 0:\n",
        "      self.leaves.append(indices.tolist())\n",
        "      self.sizes.append(indices.shape[0])\n",
        "      centroid = self.data[indices].mean(dim=0) # get centroid position\n",
        "      self.centroids = torch.cat((self.centroids,centroid))\n",
        "    return\n",
        "\n",
        "  def choose_rule(self):\n",
        "    v = torch.rand(self.dim) # create random vector\n",
        "    v /= torch.norm(v) # normalize to unit vector\n",
        "    return v\n",
        "    \n",
        "def init_accuracy(data, graph, k_distances):\n",
        "  '''\n",
        "  Takes in data and graph to check accuracy of graph's assigned k nearest neighbours\n",
        "  Uses torch brute force to find actual k nearest neighbours\n",
        "  Returns accuracy: proportion of correct nearest neighbours\n",
        "  Also returns distance error: (average_distance-true_distances)/true_distance (of k nearest neighbours)\n",
        "  '''\n",
        "  N, k = graph.shape\n",
        "\n",
        "  # Calculate true distances, indices\n",
        "  d=((data.unsqueeze(1)-data.unsqueeze(0))**2).sum(-1)+torch.Tensor([float('inf')]).repeat(len(data)).diag() # Infinity is added to diagonal\n",
        "  true_distances, true_indices = torch.sort(d,dim=1)\n",
        "\n",
        "  # get k nearest neighbours\n",
        "  true_indices = true_indices[:,:k]\n",
        "  true_distances = true_distances[:,:k]\n",
        "  \n",
        "  # Calculate number of correct nearest neighbours\n",
        "  accuracy = 0\n",
        "  for i in range(k):\n",
        "    accuracy += torch.sum(graph == true_indices).float()\n",
        "    true_indices = torch.roll(true_indices, 1, -1) # Create a rolling window (index positions may not match)\n",
        "  accuracy = float(accuracy/(N*k)) # percentage accuracy\n",
        "\n",
        "  # Calculate accuracy of distances\n",
        "  true_average = torch.mean(true_distances)\n",
        "  graph_average = torch.mean(k_distances)\n",
        "  distance_error = float((graph_average-true_average)/true_average)\n",
        "\n",
        "  return accuracy, distance_error\n",
        "\n",
        "def knn_accuracy_x_y(indices_test, x, y):\n",
        "  '''\n",
        "  Compares the test and ground truth indices (rows = KNN for each point in dataset)\n",
        "  Returns accuracy: proportion of correct nearest neighbours\n",
        "  \n",
        "  indices_test: k nearest neighbour indices (rows = KNN for each query point)\n",
        "  x: training points that the model is fitted to\n",
        "  y: query points for which we want to find the nearest KNN (chosen from x)\n",
        "  '''\n",
        "  N, k = indices_test.shape\n",
        "  \n",
        "  indices_truth = torch.argsort(((y.unsqueeze(1)-x.unsqueeze(0))**2).sum(-1),dim=1)\n",
        "  indices_truth = indices_truth[:,:k].to(device)\n",
        "  \n",
        "  # Calculate number of correct nearest neighbours\n",
        "  accuracy = 0\n",
        "  for i in range(k):\n",
        "    accuracy += torch.sum(indices_test == indices_truth).float()/N\n",
        "    indices_truth = torch.roll(indices_truth, 1, -1) # Create a rolling window (index positions may not match)\n",
        "  accuracy = float(accuracy/k) # percentage accuracy\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "def accuracy(indices_test, indices_truth):\n",
        "  '''\n",
        "  Compares the test and ground truth indices (rows = KNN for each point in dataset)\n",
        "  Returns accuracy: proportion of correct nearest neighbours\n",
        "  '''\n",
        "  N, k = indices_test.shape\n",
        "  \n",
        "  # Calculate number of correct nearest neighbours\n",
        "  accuracy = 0\n",
        "  for i in range(k):\n",
        "    accuracy += torch.sum(indices_test == indices_truth).float()/N\n",
        "    indices_truth = torch.roll(indices_truth, 1, -1) # Create a rolling window (index positions may not match)\n",
        "  accuracy = float(accuracy/k) # percentage accuracy\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "tmBCQvk6hDtg",
        "outputId": "42a7e684-8efa-4dda-82a9-3c699fb0bf53"
      },
      "source": [
        "# Testing out NNDescent class\n",
        "# torch.manual_seed(1)\n",
        "data = torch.Tensor([[1.0,1.0], [2.0,1.0], [3.0,1.0], [4.0,1.0],\n",
        "                     [1.0,2.0], [2.0,2.0], [3.0,2.0], [4.0,2.0]])  \n",
        "data = torch.randn(size=[1000,4])\n",
        "# print(data)  \n",
        "\n",
        "torch.set_printoptions(threshold=10)\n",
        "\n",
        "k = 5\n",
        "\n",
        "# Initialize NNDescent graph randomly\n",
        "\n",
        "print(\"Initializing RANDOMLY...\")\n",
        "start = time.time()\n",
        "n = NNDescent(data, k=k, init=1)\n",
        "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
        "print(\"Graph:\")\n",
        "print(n.graph)\n",
        "# print(\"Distances:\")\n",
        "print(torch.sqrt(n.k_distances))\n",
        "\n",
        "print(\"Updating...\\n\")\n",
        "start = time.time()\n",
        "n.update_graph(iter=25)\n",
        "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
        "print(\"Graph:\")\n",
        "print(n.graph)\n",
        "print(\"Distances:\")\n",
        "print(torch.sqrt(n.k_distances))\n",
        "#print(n.k_distances)\n",
        "accuracy, distance_error = init_accuracy(data, n.graph, n.k_distances)\n",
        "print(\"Accuracy: \",accuracy)\n",
        "print(\"Distance Error: \",distance_error,'\\n')\n",
        "\n",
        "\n",
        "\n",
        "# Initialize NNDescent graph with big random\n",
        "print(\"Initializing BIG RANDOM...\")\n",
        "start = time.time()\n",
        "n = NNDescent(data, k=k, init=2)\n",
        "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
        "print(\"Graph:\")\n",
        "print(n.graph)\n",
        "print(\"Distances:\")\n",
        "print(torch.sqrt(n.k_distances))\n",
        "\n",
        "print(\"Updating...\\n\")\n",
        "start = time.time()\n",
        "n.update_graph(iter=25)\n",
        "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
        "print(\"Graph:\")\n",
        "print(n.graph)\n",
        "print(\"Distances:\")\n",
        "print(torch.sqrt(n.k_distances))\n",
        "#print(n.k_distances)\n",
        "accuracy, distance_error = init_accuracy(data, n.graph, n.k_distances)\n",
        "print(\"Accuracy: \",accuracy)\n",
        "print(\"Distance Error: \",distance_error,'\\n')\n",
        "\n",
        "\n",
        "\n",
        "# Initialize NNDescent graph with forest\n",
        "print(\"Initializing FOREST...\")\n",
        "start = time.time()\n",
        "n = NNDescent(data, k=k, init=3)\n",
        "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
        "print(\"Graph:\")\n",
        "print(n.graph)\n",
        "print(\"Distances:\")\n",
        "print(torch.sqrt(n.k_distances))\n",
        "\n",
        "print(\"Updating...\\n\")\n",
        "start = time.time()\n",
        "n.update_graph(iter=25)\n",
        "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
        "print(\"Graph:\")\n",
        "print(n.graph)\n",
        "print(\"Distances:\")\n",
        "print(torch.sqrt(n.k_distances))\n",
        "#print(n.k_distances)\n",
        "accuracy, distance_error = init_accuracy(data, n.graph, n.k_distances)\n",
        "print(\"Accuracy: \",accuracy)\n",
        "print(\"Distance Error: \",distance_error,'\\n')\n",
        "\n",
        "\n",
        "\n",
        "# Brute force search\n",
        "print(\"BRUTE FORCE\")\n",
        "start = time.time()\n",
        "m=((data.unsqueeze(1)-data.unsqueeze(0))**2).sum(-1)#+torch.Tensor([float('inf')]).repeat(len(data)).diag() # Infinity is added to diagonal\n",
        "distances, brute_force = torch.sort(m,dim=1)\n",
        "brute_force = brute_force[:,1:k+1]\n",
        "distances = distances[:,1:k+1]\n",
        "  \n",
        "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
        "print(brute_force)\n",
        "print('mean distance',(distances).sqrt().mean())\n",
        "accuracy, distance_error = init_accuracy(data, brute_force, distances)\n",
        "print(\"Accuracy: \",accuracy)\n",
        "print(\"Distance Error: \",distance_error,'\\n')\n",
        "\n",
        "# Get k nearest neighbors using graph search\n",
        "print()\n",
        "print(\"Graph search\")\n",
        "#x = torch.Tensor([4, 0]).unsqueeze(0) # size 1 x d\n",
        "X = torch.randn(size=[1000,data.shape[1]])\n",
        "print(\"X is\",X)\n",
        "start = time.time()\n",
        "k_nearest = n.k_nearest_graph_search(X)\n",
        "print(\"Took\", time.time()-start,\"seconds.\")\n",
        "print(\"Nearest indices with graph search:\\n\",k_nearest)\n",
        "\n",
        "print(\"K is\",k)\n",
        "# Get k nearest using brute force knn\n",
        "print(\"\\nActual nearest using KNN\")\n",
        "print(\"Brute force search:\") # Crashes for 1 million points +\n",
        "start = time.time()\n",
        "m=((data.unsqueeze(0)-X.unsqueeze(1))**2).sum(-1)\n",
        "distances, brute_force = torch.topk(m,k=k,dim=1,largest=False)\n",
        "print(\"Took\", time.time()-start,\"seconds.\")\n",
        "print(\"Nearest indices with brute force:\\n\",brute_force)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing RANDOMLY...\n",
            "Took 0.4163076877593994 seconds.\n",
            "\n",
            "Graph:\n",
            "tensor([[388, 240, 724, 307, 676],\n",
            "        [ 39, 410, 547, 393, 341],\n",
            "        [678, 628, 392, 169, 946],\n",
            "        ...,\n",
            "        [327, 449, 480, 136, 973],\n",
            "        [161, 116, 796,  57, 458],\n",
            "        [678,  35, 472, 848, 355]])\n",
            "tensor([[1.8660, 4.4599, 3.3473, 2.3627, 2.2804],\n",
            "        [1.9366, 2.0393, 2.1813, 1.8742, 1.9006],\n",
            "        [2.4952, 1.8181, 2.6089, 1.4402, 1.3050],\n",
            "        ...,\n",
            "        [2.5797, 2.1167, 1.5458, 1.7441, 2.5093],\n",
            "        [3.3210, 4.2237, 4.5972, 2.1921, 3.8921],\n",
            "        [2.0741, 2.4372, 1.8790, 2.4712, 1.6521]])\n",
            "Updating...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-20783d20c07d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Updating...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"seconds.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Graph:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-feabfd2ff8d2>\u001b[0m in \u001b[0;36mupdate_graph\u001b[0;34m(self, iter)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# Find neighbors of neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mpotential_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplored_edges\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mpotential_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotential_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplored_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotential_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-feabfd2ff8d2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# Find neighbors of neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mpotential_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplored_edges\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mpotential_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotential_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplored_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotential_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-feabfd2ff8d2>\u001b[0m in \u001b[0;36mdist\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[0;31m# Square of euclidian distance. Skip the root for faster computation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdist_bulk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jVi2L9Wi0vL",
        "outputId": "a0a43fd4-7b76-44a6-c9fa-8157eddd6aa3"
      },
      "source": [
        "# Comparing the graph search accuracy of tree initialization\n",
        "N, d = 100000, 2\n",
        "k = 100 # This k can be different than the graph's k.\n",
        "a = 5\n",
        "\n",
        "x = torch.randn(size=[N,d])\n",
        "\n",
        "start = time.time()\n",
        "n = NNDescent(x, k=k, init=4, leaf_multiplier=N/32/k, a=a)\n",
        "print(\"Fitting took\", time.time()-start)\n",
        "\n",
        "print(n.leaves)\n",
        "\n",
        "y = torch.randn(size=[10000,x.shape[1]])\n",
        "#print(\"X is\",X)\n",
        "print(\"Search without tree init:\")\n",
        "start = time.time()\n",
        "k_nearest_random = n.k_nearest_graph_search(y, tree_init = False, max_num_steps=9)\n",
        "answer_random = n.final_brute_force(k_nearest_random, y)\n",
        "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
        "\n",
        "\n",
        "print(\"Search with tree init:\")\n",
        "start = time.time()\n",
        "k_nearest_forest = n.k_nearest_graph_search(y, tree_init = True, max_num_steps=9)\n",
        "answer_forest = n.final_brute_force(k_nearest_forest, y)\n",
        "print(\"Took\", time.time()-start,\"seconds.\")\n",
        "\n",
        "# print(\"Nearest indices with graph search:\\n\",k_nearest)\n",
        "\n",
        "x_LT=LazyTensor(x.unsqueeze(0).to(device))\n",
        "y_LT=LazyTensor(y.unsqueeze(1).to(device))\n",
        "d=((x_LT-y_LT)**2).sum(-1)\n",
        "brute_force = d.argKmin(K=k,dim=1).long()\n",
        "\n",
        "# m=((x.unsqueeze(0)-y.unsqueeze(1))**2).sum(-1).to(device)\n",
        "# distances, brute_force = torch.topk(m,k=k,dim=1,largest=False)\n",
        "\n",
        "# print(brute_force[0:5])\n",
        "\n",
        "print(\"Comparing (naively) the accuracy\")\n",
        "print(\"Random:\",(1.0*(brute_force==answer_random)).mean())\n",
        "print(\"Forest:\",(1.0*(brute_force==answer_forest)).mean())\n",
        "\n",
        "print(\"Accuracy Checkers\")\n",
        "# print('Random:', knn_accuracy_x_y(answer_random,x,y))\n",
        "# print('Forest:', knn_accuracy_x_y(answer_forest,x,y))\n",
        "print('Random:', accuracy(answer_random,brute_force))\n",
        "print('Forest:', accuracy(answer_forest,brute_force))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting took 0.06574106216430664\n",
            "32\n",
            "Search without tree init:\n",
            "Graph search finished after 9 steps. Finished for: 0.9996000000101048\n",
            "Took 0.30768918991088867 seconds.\n",
            "\n",
            "Search with tree init:\n",
            "Graph search finished after 5 steps. Finished for: 1.0\n",
            "Took 0.24472403526306152 seconds.\n",
            "Comparing (naively) the accuracy\n",
            "Random: tensor(0.8963, device='cuda:0')\n",
            "Forest: tensor(0.8964, device='cuda:0')\n",
            "Accuracy Checkers\n",
            "Random: 0.9391242861747742\n",
            "Forest: 0.9392243027687073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8WtFYCmrpDf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
