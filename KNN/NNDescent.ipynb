{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4s3np_UZreV"
   },
   "source": [
    "Rewritten NNDescent algorithm using matrices instead of dictionaries.\n",
    "\n",
    "TODO: Remove for-loops where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "v23EimYwHprW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#from collections import defaultdict\n",
    "\n",
    "class NNDescent:\n",
    "  def __init__(self, data, k=2, trees=5, init=2, leaf_multiplier=1):\n",
    "    # The data is a (N x d) matrix with N instances of d-dimensional points\n",
    "    self.data = data\n",
    "    N = data.shape[0]\n",
    "    self.k = k\n",
    "    self.numtrees = trees\n",
    "    \n",
    "    # A 2D tensor representing a directed graph.\n",
    "    # The value a = graph[i,j] represents an edge from point x_i to x_a.\n",
    "    self.graph = torch.zeros(size=[N, k], dtype=torch.long)\n",
    "    \n",
    "    # Initialize graph randomly or with forest\n",
    "    if init == 1:\n",
    "      self.initialize_graph_randomly()\n",
    "    elif init == 2:\n",
    "      self.initialize_graph_big_random(data)\n",
    "    elif init == 3:\n",
    "      self.leaves = self.initialize_graph_forest(data, leaf_multiplier)\n",
    "    \n",
    "#     accuracy, _ = init_accuracy(data,self.graph,torch.zeros([N, k]))\n",
    "#     print('Initial Accuracy: ',accuracy)\n",
    "    \n",
    "    # A set of tuples (i,j) of indices for which the distance has already been calculated.\n",
    "    self.explored_edges = set()\n",
    "\n",
    "    # A 2D tensor representing the distance between point x_i and x_graph[i,j]\n",
    "    self.k_distances = torch.zeros([N, k])\n",
    "    self.calculate_all_distances()\n",
    "    \n",
    "\n",
    "  def initialize_graph_randomly(self):\n",
    "    '''\n",
    "    Initializes self.graph with random values such that each point has k distinct neighbors\n",
    "    '''\n",
    "    N, k = self.graph.shape\n",
    "    # Initialize graph randomly, removing self-loops\n",
    "    self.graph = torch.randint(high = N-1, size=[N,k], dtype=torch.long)\n",
    "    row_indices = torch.arange(N).unsqueeze(1).repeat(1,k)\n",
    "    self.graph[self.graph>=row_indices] += 1\n",
    "\n",
    "  def initialize_graph_big_random(self, data):\n",
    "    '''\n",
    "    Initializes self.graph randomly, but with more neighbours at the start\n",
    "    '''\n",
    "    N, k = self.graph.shape\n",
    "    temp_graph = torch.tensor([])\n",
    "        \n",
    "    # make 'trees', combine into giant graph with each element (row) having k * num_trees neighbours\n",
    "    # this is a small for loop - numtrees and k << datapoints\n",
    "    for j in range(self.numtrees):\n",
    "      tree_graph = torch.tensor([])\n",
    "      for i in range(k):\n",
    "        tree_graph = torch.cat((tree_graph,torch.randperm(N)),0) # generate randomly shuffled list of N indices\n",
    "      tree_graph = tree_graph.reshape(-1,k) # creates a N x k tensor with N indices, each appearing k times. This represents 1 'tree'\n",
    "      temp_graph = torch.cat((temp_graph,tree_graph),1) # combine into giant N x (k*num_trees) tensor. This represents the forest\n",
    "    \n",
    "    # find KNN for each row in giant graph\n",
    "    # TODO - implement the below without a for loop\n",
    "    for i, row in enumerate(temp_graph):\n",
    "      temp_row = torch.unique(row).type(torch.LongTensor) # remove duplicates\n",
    "      temp_row = temp_row[temp_row != i] # remove self\n",
    "      \n",
    "      temp_points = data[temp_row,:] # pick out elements from dataset\n",
    "      distances = dist_bulk(temp_points,data[i]) # Euclidean distances\n",
    "      indices = distances.topk(k=self.k, largest=False).indices # find indices of KNN\n",
    "      self.graph[i] = temp_row[indices] # assign KNN to graph\n",
    "      \n",
    "  def initialize_graph_forest(self, data, leaf_multiplier):\n",
    "    '''\n",
    "    Initializes self.graph with a forest of random trees, such that each point has k distinct neighbors\n",
    "    '''\n",
    "    N, k = self.graph.shape\n",
    "    dim = data.shape[1]\n",
    "    \n",
    "    temp_graph = torch.tensor(())\n",
    "    for j in range(self.numtrees):\n",
    "      # Create trees, obtain leaves\n",
    "      t = tree(data, k = k*leaf_multiplier)\n",
    "      \n",
    "      # Create temporary graph, 1 for each tree\n",
    "      # Leaves are of uneven size; select smallest leaf size as graph size\n",
    "      cols = min([len(leaf) for leaf in t.leaves])\n",
    "      rows = len(t.leaves)\n",
    "      tree_graph = torch.zeros((N, cols))\n",
    "      leaves = torch.tensor(())\n",
    "      idx_update = torch.tensor(())\n",
    "      \n",
    "      # Update graph using leaves\n",
    "      for leaf in t.leaves:\n",
    "        temp_idx = torch.as_strided(torch.tensor(leaf).repeat(1,2),size=[len(leaf),cols],stride=[1,1],storage_offset=1)\n",
    "        tree_graph[leaf,:] = temp_idx.float() # update graph. a lot of overwriting\n",
    "#         idx_update = torch.cat((idx_update,temp_idx), 0)\n",
    "#         leaves = torch.cat((leaves,torch.tensor(leaf)), 0)\n",
    "#       leaves = leaves.unique().long()\n",
    "#       tree_graph[leaves,:] = idx_update.float()\n",
    "      # Concatenate all graphs from all trees into 1 giant graph\n",
    "      temp_graph = torch.cat((temp_graph,tree_graph), 1)\n",
    "    \n",
    "    warning_count = 0 # number of indices for which some neighbours are random\n",
    "    # find KNN for each row in giant graph\n",
    "    # TODO - implement the below without a for loop\n",
    "    for i, row in enumerate(temp_graph):\n",
    "      temp_row = torch.unique(row).type(torch.LongTensor) # remove duplicates\n",
    "      temp_row = temp_row[temp_row != i] # remove self\n",
    "      \n",
    "      temp_points = data[temp_row,:] # pick out elements from dataset\n",
    "      d=((data[i].reshape(1,dim).unsqueeze(1)-temp_points.unsqueeze(0))**2).sum(-1)\n",
    "      distances, indices = torch.sort(d,dim=1)\n",
    "      indices = indices.flatten()[:k]\n",
    "      \n",
    "      indices = temp_row[indices]\n",
    "      \n",
    "      # pad with random indices if there are not enough neighbours\n",
    "      warning = False # warning flag\n",
    "      while len(indices) < k:\n",
    "        pad = torch.randint(high = N-1, size=[k-len(indices),], dtype=torch.long)\n",
    "        indices = torch.cat((indices,pad))\n",
    "        indices = torch.unique(indices).type(torch.LongTensor) # remove duplicates\n",
    "        indices = indices[indices != i] # remove self\n",
    "        warning = True\n",
    "\n",
    "      self.graph[i] = indices # assign KNN to graph\n",
    "      \n",
    "      if warning:\n",
    "        warning_count += 1\n",
    "    \n",
    "    if warning_count:\n",
    "      print(\"WARNING!\",warning_count,\" INDICES ARE RANDOM!\")\n",
    "        \n",
    "  def calculate_all_distances(self):\n",
    "    '''\n",
    "    Updates the distances (self.k_distances) of the edges found in self.graph.\n",
    "    '''\n",
    "    # Note: Start with for loop for simplicity. TODO: Try to remove loop.\n",
    "    for i, row in enumerate(self.graph):\n",
    "      # Indices of current k neighbors in self.graph\n",
    "      neighbor_indices = [(i,int(r)) for r in row]\n",
    "\n",
    "      # The distances of those neighbors are saved in k_distances\n",
    "      self.k_distances[i] = torch.Tensor([dist(self.data[a],self.data[b]) for a,b in neighbor_indices])\n",
    "\n",
    "      # Add pairs to explored_edges set\n",
    "      self.explored_edges.update(neighbor_indices) \n",
    "    \n",
    "\n",
    "  def update_graph(self, iter=5):\n",
    "    '''\n",
    "      Updates the graph using algorithm: https://pynndescent.readthedocs.io/en/latest/how_pynndescent_works.html\n",
    "    '''\n",
    "    # [STEP 1: Start with random graph.] Iterate\n",
    "    start = time.time()\n",
    "    for it in range(iter):\n",
    "#       print(\"Iteration number\",it,\"with average distance of\",torch.mean(self.k_distances).item(),\"Took\", time.time()-start,\"seconds.\")\n",
    "      has_changed = False\n",
    "\n",
    "      # [STEP 2: For each node:] (TODO: Investigate whether this can be vectorized.)\n",
    "      for i, neighbors in enumerate(self.graph):\n",
    "        # Distances of current neighbors\n",
    "        dist_current_neighbors = self.k_distances[i]\n",
    "\n",
    "        # [STEP 3: Measure distance from the node to the neighbors of its neighbors]\n",
    "        # Find neighbors of neighbors\n",
    "        potential_neighbors = {a.item() for a in self.graph[neighbors].flatten() \\\n",
    "                               if a not in neighbors and a!=i and (i,int(a)) not in self.explored_edges}\n",
    "        potential_distances = torch.Tensor([dist(self.data[i],self.data[n]) for n in potential_neighbors])\n",
    "        self.explored_edges.update([(i,int(r)) for r in potential_neighbors])\n",
    "\n",
    "        # Concatenate potential neighbors to list of neighbors (indices and distances)\n",
    "        cat_idx = torch.cat([neighbors, torch.Tensor(list(potential_neighbors))])\n",
    "        cat_dist = torch.cat([self.k_distances[i], potential_distances])\n",
    "\n",
    "        # [STEP 4: If any are closer, then update the graph accordingly, and only keep the k closest]\n",
    "        # Sort using torch.sort(), which also returns sorted indices\n",
    "        dist_sorted, idx = torch.sort(cat_dist)\n",
    "        if torch.max(idx[:self.k]) >= self.k:\n",
    "          has_changed = True\n",
    "          self.graph[i] = cat_idx[idx[:self.k]]\n",
    "          self.k_distances[i] = dist_sorted[:self.k]\n",
    "        \n",
    "      # [STEP 5: If any changes were made, repeat iteration, otherwise stop]\n",
    "#       if not has_changed:\n",
    "#         print(\"Nothing changed in iteration\",it)\n",
    "#         break\n",
    "#     print(\"Done.\")\n",
    "\n",
    "  def k_nearest_graph_search(self,x):\n",
    "    '''\n",
    "    Gets the k nearest neighbors of input x according to the graph, using this algorithm:\n",
    "      https://pynndescent.readthedocs.io/en/latest/how_pynndescent_works.html#Searching-using-a-nearest-neighbor-graph\n",
    "    Input: \n",
    "      x - a torch tensor of shape (1,d), where d is the number of dimentions of the input data.\n",
    "      TODO: Add support for batches, so x can be of shape (n, d). Not sure how to batch-ify the graph search...\n",
    "    Output:\n",
    "      The indices of the k nearest neighbors according using graph search with random initialization.\n",
    "    '''\n",
    "\n",
    "    # Random initialization for starting point of search\n",
    "    random_start = torch.randint(len(self.data),size=[1], dtype=torch.long)\n",
    "    # A list of random initialization and its neighbors\n",
    "    candidate_idx = torch.cat([self.graph[random_start].squeeze(),random_start], dim=0) \n",
    "    # Track the nodes we have explored already\n",
    "    explored = [random_start]\n",
    "    \n",
    "    count = 0\n",
    "    while True:\n",
    "      count += 1\n",
    "      # [2. Look at nodes connected by an edge to the best untried node in graph]\n",
    "      unexplored = [i for i in candidate_idx if i not in explored]\n",
    "      if not unexplored:\n",
    "        # if nothing is unexplored, the search is over\n",
    "        break \n",
    "    \n",
    "      # Add neighbors of the first unexplored point to the list of candidates\n",
    "      candidate_idx = torch.cat([self.graph[unexplored[0]],candidate_idx], dim=0) \n",
    "      # and mark it as explored\n",
    "      explored = explored + [unexplored[0]]\n",
    "    \n",
    "      # [4. Sort by closeness]\n",
    "      distances = ((self.data[candidate_idx].unsqueeze(1) - x.unsqueeze(0))**2).sum(-1).squeeze() \n",
    "      sorted, idx = torch.sort(distances,dim=0)\n",
    "      candidate_idx = candidate_idx[idx]\n",
    "    \n",
    "      # [5. Truncate to k best]\n",
    "      # TODO: use Hudson's unwanted_indices method from \"Loop replacement.ipynb\" to get unique values.\n",
    "      # It might be faster and is probably more useful when algo supports predictions for batches.\n",
    "      candidate_idx = torch.unique_consecutive(candidate_idx)[:k] # unique_consecutive doesn't sort\n",
    "    \n",
    "      # [6. Return to step 2. If we have already tried all candidates in pool, we stop in the if not unexplored]\n",
    "    \n",
    "    # Return the k candidates\n",
    "#     print(\"Graph search finished after\",count,\"steps\")\n",
    "    return candidate_idx\n",
    "\n",
    "  def predict(self,x):\n",
    "    '''\n",
    "    Predict output using tree. Hasn't been implemented yet. Needs labels y.\n",
    "    '''\n",
    "    pass\n",
    "    \n",
    "def dist(x,y):\n",
    "  # Square of euclidian distance. Skip the root for faster computation.\n",
    "  return torch.sum((x-y)**2)\n",
    "\n",
    "def dist_bulk(x,y):\n",
    "  # Square of euclidian distance. Skip the root for faster computation.\n",
    "  # For datasets\n",
    "  return ((x-y)**2).sum(-1)\n",
    "\n",
    "class tree:\n",
    "  '''\n",
    "  Random projection tree class that splits the data evenly per split\n",
    "  Each split is performed by calculating the projection distance of each datapoint to a random unit vector\n",
    "  The datapoints are then split by the median of of these projection distances\n",
    "  The indices of the datapoints are stored in tree.leaves, as a nested list\n",
    "  '''\n",
    "  def __init__(self, x, k=5):\n",
    "    self.min_size = 2*k-1\n",
    "    self.leaves = []\n",
    "    self.sizes = []\n",
    "    self.big_leaves = [] # leaves at depth = 5\n",
    "    indices = torch.arange(x.shape[0])\n",
    "    self.tree = self.make_tree(x, indices, depth = 0)\n",
    "\n",
    "  def make_tree(self, x, indices, depth):\n",
    "    if depth == 5: # add to big_leaves if depth=5\n",
    "      self.big_leaves.append(int(indices[0]))\n",
    "    if x.shape[0] > self.min_size:\n",
    "      v = self.choose_rule(x)\n",
    "      distances = torch.tensordot(x,v,dims=1) # create list of projection distances\n",
    "      median = torch.median(distances)\n",
    "      left_bool = distances <= median # create boolean array where entries are true if distance <= median\n",
    "      right_bool = ~left_bool # inverse of left_bool\n",
    "      left_indices = indices[left_bool]\n",
    "      right_indices = indices[right_bool]\n",
    "      self.make_tree(x[left_bool,:],left_indices, depth+1)\n",
    "      self.make_tree(x[right_bool,:],right_indices, depth+1)\n",
    "    elif x.shape[0] != 0:\n",
    "      self.leaves.append(indices.tolist())\n",
    "      self.sizes.append(x.shape[0])\n",
    "    return\n",
    "\n",
    "  def choose_rule(self, x):\n",
    "    dim = x.shape[1]\n",
    "    v = torch.rand(dim) # create random vector\n",
    "    v /= torch.norm(v) # normalize to unit vector\n",
    "    return v\n",
    "    \n",
    "def init_accuracy(data, graph, k_distances):\n",
    "  '''\n",
    "  Takes in data and graph to check accuracy of graph's assigned k nearest neighbours\n",
    "  Uses torch brute force to find actual k nearest neighbours\n",
    "  Returns accuracy: proportion of correct nearest neighbours\n",
    "  Also returns distance error: (average_distance-true_distances)/true_distance (of k nearest neighbours)\n",
    "  '''\n",
    "  N, k = graph.shape\n",
    "\n",
    "  # Calculate true distances, indices\n",
    "  d=((data.unsqueeze(1)-data.unsqueeze(0))**2).sum(-1)+torch.Tensor([float('inf')]).repeat(len(data)).diag() # Infinity is added to diagonal\n",
    "  true_distances, true_indices = torch.sort(d,dim=1)\n",
    "\n",
    "  # get k nearest neighbours\n",
    "  true_indices = true_indices[:,:k]\n",
    "  true_distances = true_distances[:,:k]\n",
    "  \n",
    "  # Calculate number of correct nearest neighbours\n",
    "  accuracy = 0\n",
    "  for i in range(k):\n",
    "    accuracy += torch.sum(graph == true_indices).float()\n",
    "    true_indices = torch.roll(true_indices, 1, -1) # Create a rolling window (index positions may not match)\n",
    "  accuracy = float(accuracy/(N*k)) # percentage accuracy\n",
    "\n",
    "  # Calculate accuracy of distances\n",
    "  true_average = torch.mean(true_distances)\n",
    "  graph_average = torch.mean(k_distances)\n",
    "  distance_error = float((graph_average-true_average)/true_average)\n",
    "\n",
    "  return accuracy, distance_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmBCQvk6hDtg",
    "outputId": "0d0f5ad8-403c-4a83-9fbc-e08ddd712bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing RANDOMLY...\n",
      "Took 0.26776623725891113 seconds.\n",
      "\n",
      "Graph:\n",
      "tensor([[283, 393, 892, 703, 938],\n",
      "        [927, 940, 193, 732, 745],\n",
      "        [642, 502, 738, 510, 746],\n",
      "        ...,\n",
      "        [229, 453, 454, 725, 900],\n",
      "        [396, 173, 724, 167, 398],\n",
      "        [ 32, 559, 599, 469, 534]])\n",
      "tensor([[2.8006, 4.2443, 1.6745, 3.0122, 4.3294],\n",
      "        [1.4599, 2.9824, 2.2894, 2.6771, 1.6102],\n",
      "        [3.2738, 1.9093, 2.6684, 2.6792, 0.6659],\n",
      "        ...,\n",
      "        [3.6319, 1.7984, 0.7561, 3.5464, 3.3226],\n",
      "        [3.8295, 5.5575, 5.9965, 4.3221, 5.0886],\n",
      "        [2.1696, 4.1616, 4.6453, 2.4167, 3.8013]])\n",
      "Updating...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7fa4872992ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Updating...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"seconds.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Graph:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0be5121f8127>\u001b[0m in \u001b[0;36mupdate_graph\u001b[0;34m(self, iter)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# [STEP 3: Measure distance from the node to the neighbors of its neighbors]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Find neighbors of neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         potential_neighbors = {a.item() for a in self.graph[neighbors].flatten() \\\n\u001b[0m\u001b[1;32m    170\u001b[0m                                if a not in neighbors and a!=i and (i,int(a)) not in self.explored_edges}\n\u001b[1;32m    171\u001b[0m         \u001b[0mpotential_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotential_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0be5121f8127>\u001b[0m in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Find neighbors of neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         potential_neighbors = {a.item() for a in self.graph[neighbors].flatten() \\\n\u001b[0;32m--> 170\u001b[0;31m                                if a not in neighbors and a!=i and (i,int(a)) not in self.explored_edges}\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mpotential_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotential_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplored_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotential_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;31m# type hint doesn't understand the __contains__ result array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         raise RuntimeError(\n",
      "\u001b[0;32m~/my_env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Testing out NNDescent class\n",
    "# torch.manual_seed(1)\n",
    "data = torch.Tensor([[1.0,1.0], [2.0,1.0], [3.0,1.0], [4.0,1.0],\n",
    "                     [1.0,2.0], [2.0,2.0], [3.0,2.0], [4.0,2.0]])  \n",
    "data = torch.randn(size=[1000,4])\n",
    "# print(data)  \n",
    "\n",
    "torch.set_printoptions(threshold=10)\n",
    "\n",
    "k = 5\n",
    "\n",
    "# Initialize NNDescent graph randomly\n",
    "\n",
    "print(\"Initializing RANDOMLY...\")\n",
    "start = time.time()\n",
    "n = NNDescent(data, k=k, init=1)\n",
    "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
    "print(\"Graph:\")\n",
    "print(n.graph)\n",
    "# print(\"Distances:\")\n",
    "print(torch.sqrt(n.k_distances))\n",
    "\n",
    "print(\"Updating...\\n\")\n",
    "start = time.time()\n",
    "n.update_graph(iter=25)\n",
    "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
    "print(\"Graph:\")\n",
    "print(n.graph)\n",
    "print(\"Distances:\")\n",
    "print(torch.sqrt(n.k_distances))\n",
    "#print(n.k_distances)\n",
    "accuracy, distance_error = init_accuracy(data, n.graph, n.k_distances)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Distance Error: \",distance_error,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize NNDescent graph with big random\n",
    "print(\"Initializing BIG RANDOM...\")\n",
    "start = time.time()\n",
    "n = NNDescent(data, k=k, init=2)\n",
    "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
    "print(\"Graph:\")\n",
    "print(n.graph)\n",
    "print(\"Distances:\")\n",
    "print(torch.sqrt(n.k_distances))\n",
    "\n",
    "print(\"Updating...\\n\")\n",
    "start = time.time()\n",
    "n.update_graph(iter=25)\n",
    "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
    "print(\"Graph:\")\n",
    "print(n.graph)\n",
    "print(\"Distances:\")\n",
    "print(torch.sqrt(n.k_distances))\n",
    "#print(n.k_distances)\n",
    "accuracy, distance_error = init_accuracy(data, n.graph, n.k_distances)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Distance Error: \",distance_error,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize NNDescent graph with forest\n",
    "print(\"Initializing FOREST...\")\n",
    "start = time.time()\n",
    "n = NNDescent(data, k=k, init=3)\n",
    "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
    "print(\"Graph:\")\n",
    "print(n.graph)\n",
    "print(\"Distances:\")\n",
    "print(torch.sqrt(n.k_distances))\n",
    "\n",
    "print(\"Updating...\\n\")\n",
    "start = time.time()\n",
    "n.update_graph(iter=25)\n",
    "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
    "print(\"Graph:\")\n",
    "print(n.graph)\n",
    "print(\"Distances:\")\n",
    "print(torch.sqrt(n.k_distances))\n",
    "#print(n.k_distances)\n",
    "accuracy, distance_error = init_accuracy(data, n.graph, n.k_distances)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Distance Error: \",distance_error,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Brute force search\n",
    "print(\"BRUTE FORCE\")\n",
    "start = time.time()\n",
    "m=((data.unsqueeze(1)-data.unsqueeze(0))**2).sum(-1)#+torch.Tensor([float('inf')]).repeat(len(data)).diag() # Infinity is added to diagonal\n",
    "distances, brute_force = torch.sort(m,dim=1)\n",
    "brute_force = brute_force[:,1:k+1]\n",
    "distances = distances[:,1:k+1]\n",
    "  \n",
    "print(\"Took\", time.time()-start,\"seconds.\\n\")\n",
    "print(brute_force)\n",
    "print('mean distance',(distances).sqrt().mean())\n",
    "accuracy, distance_error = init_accuracy(data, brute_force, distances)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Distance Error: \",distance_error,'\\n')\n",
    "\n",
    "# Get k nearest neighbors using graph search\n",
    "print()\n",
    "print(\"Graph search\")\n",
    "#x = torch.Tensor([4, 0]).unsqueeze(0) # size 1 x d\n",
    "x = torch.randn(size=[1,data.shape[1]])\n",
    "print(\"x is\",x)\n",
    "start = time.time()\n",
    "k_nearest = n.k_nearest_graph_search(x)\n",
    "print(\"Took\", time.time()-start,\"seconds.\")\n",
    "print(\"Nearest indices with graph search:\",k_nearest)\n",
    "print(\"coordinates of nearest dots:\",n.data[k_nearest])\n",
    "\n",
    "# Get k nearest using brute force knn\n",
    "print(\"\\nActual nearest using KNN\")\n",
    "start = time.time()\n",
    "m=((data.unsqueeze(1)-x.unsqueeze(0))**2).sum(-1).squeeze() # Infinity is added to diagonal\n",
    "print(m)\n",
    "brute_force = torch.sort(m,dim=0)[1][:k]\n",
    "print(\"Took\", time.time()-start,\"seconds.\")\n",
    "print(\"The KNN nearest are:\",brute_force)\n",
    "print(\"coordinates of nearest dots:\",n.data[brute_force])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NNDescent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
