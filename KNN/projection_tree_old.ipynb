{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx \n",
    "from collections import defaultdict\n",
    "import time\n",
    "import statistics\n",
    "import pprint\n",
    "# from pykeops.numpy import LazyTensor as LazyTensor_np\n",
    "\n",
    "def dist(x,y):\n",
    "    return np.sum((x-y)**2)\n",
    "\n",
    "class graph:\n",
    "    def __init__(self):\n",
    "        self.graph=defaultdict(set)\n",
    "        self.ddict=defaultdict(float)\n",
    "        self.explored_edges=defaultdict(set)\n",
    "    def add_key(self,a,x):\n",
    "        self.keys[a].add(x)\n",
    "    def add_edge(self,a,b):\n",
    "        self.graph[str(a)].add(b)\n",
    "        self.graph[str(b)].add(a)\n",
    "    def replace_edge_list(self,a,x):\n",
    "        self.graph[str(a)]=set(x)\n",
    "    def del_edge(self,a,b):\n",
    "        self.graph[str(a)].remove(b)\n",
    "        self.graph[str(b)].remove(a)\n",
    "    def edge_list(self):\n",
    "        edge=set()\n",
    "        for key in set(self.graph.keys()):\n",
    "            tmp=set([(int(key),i) for i in self.graph[key]])\n",
    "            edge=edge.union(tmp)\n",
    "        return edge\n",
    "    def get_edge(self,a):\n",
    "        return self.graph[str(a)]\n",
    "    def visualize(self): \n",
    "        G = nx.Graph() \n",
    "        G.add_edges_from(self.edge_list()) \n",
    "        nx.draw_networkx(G) \n",
    "        plt.show() \n",
    "\n",
    "class tree:\n",
    "    def __init__(self,x):\n",
    "        self.min_size=5\n",
    "        self.leaves=[]\n",
    "        self.sizes=[]\n",
    "#         self.min_size=x.shape[0]/10\n",
    "        self.tree=self.make_tree(x)\n",
    "\n",
    "    def make_tree(self,x):\n",
    "        node=dict()\n",
    "        node['left']=[]\n",
    "        node['right']=[]\n",
    "        node['elements']=[]\n",
    "        node['isleaf']=False\n",
    "        if x.shape[0] > self.min_size:\n",
    "            v,threshold=self.choose_rule(x)\n",
    "            distances=np.dot(x,v) # create array of distances\n",
    "            left_bool=distances<=threshold # create boolean array where entries are true if distance <= threshold\n",
    "            right_bool=np.invert(left_bool)\n",
    "#             left_bool=np.empty(0,dtype=bool)\n",
    "#             for i in range(len(x)):\n",
    "#                 if np.dot(x[i],v) <= threshold:\n",
    "#                     left_bool=np.append(left_bool,True)\n",
    "#                 else:\n",
    "#                     left_bool=np.append(left_bool,False)\n",
    "#             right_bool=np.invert(left_bool)\n",
    "            node['left']=self.make_tree(x[left_bool,:])\n",
    "            node['right']=self.make_tree(x[right_bool,:])\n",
    "#         else:\n",
    "        elif x.shape[0] != 0:\n",
    "            node['elements']=x.copy()\n",
    "            node['isleaf']=True\n",
    "            self.leaves.append(x)\n",
    "            self.sizes.append(len(x))\n",
    "        return node\n",
    "\n",
    "    def choose_rule(self,x):\n",
    "        dim=x.shape[1]\n",
    "        v=np.random.random(dim)\n",
    "        v/=np.linalg.norm(v) # find random unit vector\n",
    "        \n",
    "        index=np.random.randint(x.shape[0]) # select random point in set x\n",
    "        \n",
    "        # find distance from this random point to furthest point in set x\n",
    "        x_1=x[index]\n",
    "#         x_1=x[:,None,:]\n",
    "#         x_2=x[None,:,:]\n",
    "        distances=((x_1-x)**2).sum(-1)\n",
    "        max_distance=np.max(distances)\n",
    "#         max_distance=0\n",
    "#         d_list=[]\n",
    "#         for i in range(x.shape[0]):\n",
    "#             distance=dist(x[i],x[index])\n",
    "#             d_list.append(distance)\n",
    "#             if distance > max_distance:\n",
    "#                 max_distance=distance\n",
    "#                 y=x[i]\n",
    "        max=6*np.sqrt(max_distance)/np.sqrt(dim)\n",
    "        d=np.random.uniform(-max,max)\n",
    "        median=statistics.median(distances)\n",
    "        threshold=median+d\n",
    "        return v, threshold\n",
    "    \n",
    "class forest:\n",
    "    def __init__(self,x,trees=10):\n",
    "        self.forest=[]\n",
    "        self.tree_num=trees\n",
    "        self.make_trees()\n",
    "        \n",
    "    def make_trees(self):\n",
    "        for i in range(self.tree_num):\n",
    "            t=tree(x)\n",
    "            self.forest.append(t)\n",
    "    \n",
    "    def find_leaf(self,x): # returns KNN based on all trees.\n",
    "        leaf_union=np.array([[]])\n",
    "        for tree in self.forest:\n",
    "            for leaf in tree.leaves:\n",
    "                if x in leaf:\n",
    "                    leaf_union=np.append(leaf_union,leaf,axis=0)\n",
    "                    break\n",
    "        distances=((leaf_union-x)**2).sum(-1)\n",
    "        indices=np.argmin(distances,axis=1)\n",
    "        indices=indices[:5]\n",
    "        return leaf_union[indices]\n",
    "\n",
    "#construct NN graph\n",
    "def construct_graph(x,k=3,count=3,init=3,RP=False):\n",
    "    def combi(x):\n",
    "        combi=set()\n",
    "        for i in x:\n",
    "            for j in x:\n",
    "                if (j,i) not in combi and i!=j:\n",
    "                    combi.add((i,j))\n",
    "        return combi  \n",
    "    g=graph()\n",
    "    l=len(x)\n",
    "    if RP == False:\n",
    "        for i in range(len(x)):\n",
    "            for r in range(init):\n",
    "                while True:\n",
    "                    j=int(l * np.random.random())\n",
    "                    if j!=i:\n",
    "                        break\n",
    "                g.add_edge(i,j)\n",
    "                d=dist(x[i],x[j])\n",
    "                g.ddict[(i,j)]=d\n",
    "                g.ddict[(j,i)]=d\n",
    "                g.explored_edges[i].add(j)\n",
    "                g.explored_edges[j].add(i)  \n",
    "    else: # use RP tree for graph initialisation\n",
    "        t=tree(x)\n",
    "        i_index=0\n",
    "        j_index=0\n",
    "        for leaf in t.leaves:\n",
    "            if len(leaf)!=1:\n",
    "                for i in leaf:\n",
    "                    for j in leaf:\n",
    "                        if i.all()!=j.all():\n",
    "                            g.add_edge(i_index,j_index)\n",
    "                            d=dist(i,j)\n",
    "                            g.ddict[(i_index,j_index)]=d\n",
    "                            g.ddict[(j_index,i_index)]=d\n",
    "                            g.explored_edges[i_index].add(j_index)\n",
    "                            g.explored_edges[j_index].add(i_index)\n",
    "                        j_index+=1\n",
    "                    i_index+=1\n",
    "\n",
    "  #start update here\n",
    "    for i in range(count):\n",
    "        neighbours_set=set()\n",
    "\n",
    "        for index in range(l):\n",
    "            el=g.get_edge(index)\n",
    "            neighbours=set([j for j in combi(el) if j[1] not in g.get_edge(j[0])])\n",
    "            neighbours_set=neighbours_set.union(neighbours)   \n",
    "\n",
    "        if neighbours_set==set():      \n",
    "            break\n",
    "\n",
    "        for pair in list(neighbours_set):\n",
    "            d=dist(x[pair[0]],x[pair[1]])\n",
    "            g.ddict[pair]=d\n",
    "            g.ddict[(pair[1],pair[0])]=d\n",
    "            g.explored_edges[pair[0]].add(pair[1])\n",
    "            g.explored_edges[pair[1]].add(pair[0])\n",
    "\n",
    "    \n",
    "    #recalculate all neighbours\n",
    "    for index in range(l):\n",
    "        nodes_update=list(g.explored_edges[index])\n",
    "      \n",
    "        dist_nodes=[g.ddict[(i,index)] for i in nodes_update] #the distances of these pairs\n",
    "        d,final_nodes=[list(j) for j in list(zip(*sorted(zip(dist_nodes,nodes_update))[:k]))] #sort these pairs and take the top k pairs\n",
    "\n",
    "        final_nodes=set(final_nodes)\n",
    "        g.replace_edge_list(index,final_nodes)       \n",
    "    \n",
    "    return g   \n",
    "\n",
    "def argmin(x,y,g,k=5):\n",
    "    indices=[]\n",
    "    d=[]\n",
    "    visited=set()\n",
    "    def add_index(i):\n",
    "        indices.append(i)\n",
    "        d.append(dist(y,x[i]))\n",
    "        add_index(np.random.randint(len(x)))\n",
    "    while True:\n",
    "        i=None\n",
    "        for index in indices:\n",
    "            #select this node for expansion\n",
    "            if index not in visited:\n",
    "                #print(index)\n",
    "                i=index\n",
    "                break\n",
    "        if i is None:\n",
    "            return indices\n",
    "        for new_node in g.get_edge(i):\n",
    "            if new_node not in indices:\n",
    "                add_index(new_node)    \n",
    "        visited.add(i)\n",
    "        d,indices=[list(i) for i in list(zip(*sorted(zip(d,indices))[:k]))]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing large dataset\n",
    "size=1000\n",
    "x = np.random.randn(size, 2)\n",
    "y = np.random.randn(size, 2)\n",
    "\n",
    "def get_k_argmin(x,y,k=3):\n",
    "    argmin=np.zeros([len(x),k])\n",
    "    for i in range(len(y)):\n",
    "        d=[dist(j,y[i]) for j in x]\n",
    "        argmin[i]=np.argsort(d)[:k]\n",
    "    return np.squeeze(argmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 2],\n",
      "       [3, 4]]), array([[ 7,  8],\n",
      "       [ 9, 10],\n",
      "       [11, 12],\n",
      "       [ 5,  6]])]\n",
      "[2, 4]\n"
     ]
    }
   ],
   "source": [
    "# x=np.array([[7,8],[9,10],[11,12],[1,2],[3,4],[5,6]])\n",
    "t=tree(x)\n",
    "print(t.leaves)\n",
    "print(t.sizes)\n",
    "# print(sum(t.sizes)/len(t.sizes))\n",
    "# print(len(t.sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct NN graph time taken: 21.847113609313965\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-1fcd01f2b563>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mnndescent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NN descent search time taken'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mnndescent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnndescent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#test nndescent\n",
    "nndescent=[]\n",
    "start=time.time()\n",
    "g=construct_graph(x,8,init=8,count=3)\n",
    "print('construct NN graph time taken:',time.time()-start)\n",
    "start=time.time()\n",
    "for i in y:\n",
    "    nndescent.append(argmin(x,i,g,3)[0])\n",
    "print('NN descent search time taken',time.time()-start)\n",
    "nndescent=np.squeeze(np.array(nndescent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-31016b0b005e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnndescent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstruct_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'construct NN graph time taken:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-c9c14c535efa>\u001b[0m in \u001b[0;36mconstruct_graph\u001b[1;34m(x, k, count, init, RP)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mdist_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mddict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes_update\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#the distances of these pairs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnodes_update\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#sort these pairs and take the top k pairs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mfinal_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "#test nndescent with random projection tree\n",
    "nndescent=[]\n",
    "start=time.time()\n",
    "g=construct_graph(x,8,init=8,count=3,RP=True)\n",
    "print('construct NN graph time taken:',time.time()-start)\n",
    "start=time.time()\n",
    "for i in y:\n",
    "    nndescent.append(argmin(x,i,g,3)[0])\n",
    "print('NN descent search time taken',time.time()-start)\n",
    "nndescent=np.squeeze(np.array(nndescent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test argmin and argsort\n",
    "npargmin=[]\n",
    "npargsort=[]\n",
    "start=time.time()\n",
    "for j in y:\n",
    "    d=[dist(i,j) for i in x]\n",
    "    npargmin.append(np.argmin(d))\n",
    "\n",
    "print('argmin search time taken',time.time()-start)\n",
    "npargmin=np.array(npargmin) \n",
    "start=time.time()\n",
    "for j in y:\n",
    "    d=[dist(i,j) for i in x]\n",
    "    npargsort.append(np.argsort(d)[0])\n",
    "\n",
    "print('argsort search time taken',time.time()-start)\n",
    "npargsort=np.array(npargsort) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "4\n",
      "7037\n",
      "4\n",
      "[]\n",
      "[1.]\n",
      "[ True  True False False]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n",
      "[]\n",
      "{'1': {'2': array([[ 1,  2,  3,  4],\n",
      "       [ 5,  6,  7,  8],\n",
      "       [ 9, 10, 11, 12],\n",
      "       [13, 14, 15, 16]]),\n",
      "       '4': {'5'}},\n",
      " '2': {'2': {3}, '4': {'5'}}}\n",
      "{'1': {'2': array([[ 1,  2,  3,  4],\n",
      "       [ 5,  6,  7,  8],\n",
      "       [ 9, 10, 11, 12],\n",
      "       [13, 14, 15, 16]]), '4': {'5'}}, '2': {'2': {3}, '4': {'5'}}}\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print(x)\n",
    "x=np.append(x,[[13,14,15,16]],axis=0)\n",
    "print(x)\n",
    "print(x.shape[0])\n",
    "print(np.random.randint((10000)))\n",
    "print(len(x))\n",
    "y=np.empty(0)\n",
    "print(y)\n",
    "y=np.append(y,[1])\n",
    "print(y)\n",
    "\n",
    "left_bool = (x[:,3] < 10)\n",
    "print(left_bool)\n",
    "print(type(left_bool))\n",
    "print(x[left_bool,:])\n",
    "\n",
    "test=np.empty(0,dtype=bool)\n",
    "print(test)\n",
    "\n",
    "b=[[1,2,3],[4,5,6],[7,8,9]]\n",
    "a={}\n",
    "\n",
    "pprint.pprint(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17928501  0.09548515]\n",
      " [-0.65578304  0.86442423]]\n",
      "[[-0.16278965  2.30711348]\n",
      " [ 1.99754948 -2.91815543]]\n",
      "[-0.17928501  0.09548515]\n",
      "[[0.         0.81831768]\n",
      " [0.81831768 0.        ]]\n",
      "0.8183176812288301\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "size=2\n",
    "x = np.random.randn(size, 2)\n",
    "y = np.random.randn(size, 2)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "index = 0\n",
    "x_1=x[index]\n",
    "print(x_1)\n",
    "\n",
    "x_1=x[:,None,:]\n",
    "x_2=x[None,:,:]\n",
    "distances=((x_1-x_2)**2).sum(-1)\n",
    "print(distances)\n",
    "max_distance=np.max(distances)\n",
    "print(max_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[ 3  8]\n",
      " [ 5 12]\n",
      " [ 7 16]]\n",
      "[[ True  True]\n",
      " [ True  True]\n",
      " [ True  True]]\n",
      "[ 8 32 72]\n",
      "True\n",
      "[  8  32   0  72 128]\n",
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-f58035ef8444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "a=np.array(([1,2]))\n",
    "b=np.array(([[3,4],[5,6],[7,8]]))\n",
    "print(b.shape)\n",
    "c=np.dot(b,a)\n",
    "print(c)\n",
    "d=c>1\n",
    "print(d)\n",
    "distances=((a-b)**2).sum(-1)\n",
    "print(distances)\n",
    "\n",
    "print([1,2] in a)\n",
    "# e=np.append(b,a,axis=0)\n",
    "e=np.append([[3,4],[5,6]],[[1,2],[7,8],[9,10]],axis=0)\n",
    "distances=((a-e)**2).sum(-1)\n",
    "print(distances)\n",
    "indices=np.argmin(distances,axis=0)\n",
    "print(indices)\n",
    "print(distances[indices[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([11, 17, 23])\n",
      "tensor([True, True, True])\n",
      "tensor([True, True, True]) <class 'torch.Tensor'>\n",
      "tensor([ 8, 32, 72])\n",
      "True\n",
      "e tensor([[ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.],\n",
      "        [ 3.,  4.]])\n",
      "sliced tensor([[ 9., 10.],\n",
      "        [11., 12.]])\n",
      "shape 2\n",
      "distances tensor([ 72., 128., 200.,   8.])\n",
      "indices tensor([  8.,  72., 128.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a=torch.tensor(([1,2]))\n",
    "b=torch.tensor(([[3,4],[5,6],[7,8]]))\n",
    "print(b.shape)\n",
    "c=(b*a).sum(-1)\n",
    "print(c)\n",
    "d=c>8\n",
    "print(d)\n",
    "f=(d*(-1)).type(torch.bool)\n",
    "print(f,type(f))\n",
    "distances=((a-b)**2).sum(-1)\n",
    "print(distances)\n",
    "\n",
    "print(torch.tensor([1,2]) in a)\n",
    "# e=np.append(b,a,axis=0)\n",
    "e=torch.cat((torch.tensor([]),torch.tensor([[1,2],[7,8],[9,10],[11,12],[3,4]])),0)\n",
    "e=e[e!=torch.tensor([1,2])]\n",
    "e=torch.reshape(e,(-1,2))\n",
    "print('e',e)\n",
    "print('sliced',e[(1,2),:])\n",
    "print('shape',a.shape[0])\n",
    "distances=((a-e)**2).sum(-1)\n",
    "print('distances',distances)\n",
    "indices=distances.topk(k=3, largest=False).values\n",
    "print('indices',indices)\n",
    "# print(torch.index_select(distances, 0, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9288,  3.0501, -0.3409,  1.9870,  3.1102],\n",
      "        [ 0.1568,  1.2949, -0.8454,  0.9983, -2.6546],\n",
      "        [ 2.5131, -0.6652, -0.2224,  2.8916,  2.3770],\n",
      "        [ 4.5459, -2.5440,  1.1498,  1.6462, -3.0504],\n",
      "        [-0.4603, -4.6296,  0.0622,  0.0927,  2.0834]])\n"
     ]
    }
   ],
   "source": [
    "max = 5\n",
    "print((torch.rand() * 2 - 1) * max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      " tensor([[-1.0561,  0.5606,  1.1953,  0.3313],\n",
      "        [ 0.4535,  0.6016, -0.1120,  1.0139],\n",
      "        [-0.1144, -0.7559,  0.4429,  1.1954]])\n",
      "Indexed Matrix:\n",
      " tensor([[-1.0561,  0.5606,  1.1953,  0.3313],\n",
      "        [-0.1144, -0.7559,  0.4429,  1.1954],\n",
      "        [ 0.4535,  0.6016, -0.1120,  1.0139]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(\"Original Matrix:\\n\",x)\n",
    "indices = torch.tensor([0, 2, 1])\n",
    "print(\"Indexed Matrix:\\n\",torch.index_select(x, 0, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 0.]])\n",
      "tensor([[1., 0.]])\n",
      "2\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randint(0,10,(1,2)).type(torch.float)\n",
    "print(a)\n",
    "a=a/torch.norm(a,2)\n",
    "print(a)\n",
    "\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x.shape[0])\n",
    "index = torch.randint(0,x.shape[0]+1,(1,)) # select random point in set x\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-65.6179, -31.7254, -25.6140, -94.6345, -93.0680, -56.7784, -36.0555,\n",
      "        -48.5385,  25.4823, -15.4595])\n"
     ]
    }
   ],
   "source": [
    "print(torch.FloatTensor(1,).uniform_(-100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6]) torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor((1,2,3,4))\n",
    "b = torch.tensor((4,5,6))\n",
    "c = torch.cat((a,b),0)\n",
    "c = torch.unique(c).type(torch.LongTensor)\n",
    "print(c,c.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trees - SUPER inefficient\n",
    "\n",
    "class tree:\n",
    "  def __init__(self, x, k = 5):\n",
    "    '''\n",
    "    x - dataset (torch.tensor)\n",
    "    k - no. of nearest neighbours = max no. of elements in leaf\n",
    "    Creates a tree with elements of dataset x split into leaves in self.leaves\n",
    "    All elements within the same leaf node are KNN of each other\n",
    "    (e.g. self.leaves = [[x1,x2,x3],[x4,x5,x6]] -> [x1,x2,x3] is a leaf, x1, x2 and x3 are KNN)\n",
    "    '''\n",
    "    self.max_size = k\n",
    "    self.leaves = []\n",
    "    self.sizes = []\n",
    "#    self.max_size=x.shape[0]/10\n",
    "    self.tree = self.make_tree(x)\n",
    "\n",
    "  def make_tree(self,x):\n",
    "    '''\n",
    "    recursively splits inputs dataset x into subsets.\n",
    "    returns leaf and places elements into self.leaves, when no. of elements in input < max_size\n",
    "    x - dataset for splitting into leaf nodes\n",
    "    '''\n",
    "    node = dict()\n",
    "    node['left'] = []\n",
    "    node['right'] = []\n",
    "    node['elements'] = []\n",
    "    node['isleaf'] = False\n",
    "    if x.shape[0] > self.max_size: # if input size is larger than max leaf size, do the recursion\n",
    "      v,threshold = self.choose_rule(x)\n",
    "      distances = (x * v).sum(-1) # create array of dot product each datapoint and random vector v\n",
    "#       print('distances',distances,'threshold',threshold)\n",
    "      left_bool = distances <= threshold # create boolean array where entries are true if distance <= threshold\n",
    "      right_bool = ~left_bool\n",
    "#       print(left_bool,right_bool)\n",
    "      node['left'] = self.make_tree(x[left_bool,:])\n",
    "      node['right'] = self.make_tree(x[right_bool,:])\n",
    "#     else:\n",
    "    elif x.shape[0] != 0: # if 0 < input size < max leaf size, place all input elements into self.leaves\n",
    "      node['elements'] = x.detach().clone() \n",
    "      node['isleaf'] = True\n",
    "      self.leaves.append(x)\n",
    "      self.sizes.append(len(x))\n",
    "    return node\n",
    "\n",
    "  def choose_rule(self,x):\n",
    "    dim = x.shape[1]\n",
    "    v = torch.rand(dim) # create random vector\n",
    "    v = v / torch.norm(v,2) # normalize vector\n",
    "\n",
    "    index = torch.randint(0,x.shape[0],(1,)) # select random point in set x\n",
    "    \n",
    "    # find distance from this random point to furthest point in set x\n",
    "    x_1 = x[index]\n",
    "#         x_1=x[:,None,:]\n",
    "#         x_2=x[None,:,:]\n",
    "    distances = ((x_1 - x) ** 2).sum(-1)\n",
    "    distances = torch.sqrt(distances)\n",
    "    max_distance = torch.max(distances)\n",
    "    \n",
    "#     max_range = max_distance\n",
    "    max_range = 6 * max_distance / math.sqrt(dim)\n",
    "    d = torch.FloatTensor(1,).uniform_(-max_range, max_range) # select d uniformly within range\n",
    "#     print('distances',distances,'max_distance',max_distance,'d',d)\n",
    "#     print('d',d,'max',max_range)\n",
    "    median = statistics.median(distances)\n",
    "    threshold = median + d\n",
    "#     print('median',median,'threshold',threshold)\n",
    "    return v, threshold\n",
    "    \n",
    "class forest:\n",
    "  def __init__(self, x, trees = 10, k = 5):\n",
    "    '''\n",
    "    creates forest class that contains trees within self.forest\n",
    "    x - input dataset\n",
    "    trees - number of trees in forest\n",
    "    k - number of nearest neighbours = max size of leaf in each tree\n",
    "    '''\n",
    "    self.forest = []\n",
    "    self.tree_num = trees\n",
    "    self.k = k\n",
    "    self.make_trees(x)\n",
    "\n",
    "  def make_trees(self, x):\n",
    "    '''\n",
    "    creates tree_num trees and appends trees to self.forest\n",
    "    '''    \n",
    "    for i in range(self.tree_num):\n",
    "      t = tree(x, self.k)\n",
    "      self.forest.append(t)\n",
    "\n",
    "  def find_leaf(self, query):\n",
    "    '''\n",
    "    returns KNN based on all trees\n",
    "    step 1: find which leaf the query point sits in, for each tree in the forest\n",
    "    step 2: combine all elements from these leaves\n",
    "    step 3: find the k nearest neighbours out of this combined leaves set\n",
    "    \n",
    "    query - datapoint for which we want to find the KNN\n",
    "    note: query must belong in the dataset that the trees were made from\n",
    "    '''\n",
    "#     dim = query.shape[0]\n",
    "#     leaf_union = set()\n",
    "#     for tree in self.forest:\n",
    "#       for leaf in tree.leaves:\n",
    "#         if query in leaf:\n",
    "#           for element in leaf:\n",
    "#             # convert tensor to list, then to tuple, to be recognised by set. set used to remove duplicates\n",
    "#             leaf_union.add(tuple(element.tolist()))\n",
    "#           break\n",
    "#     leaf_union.remove(tuple(query.tolist())) # remove query from set\n",
    "#     leaf_union = list(leaf_union)\n",
    "#     leaf_union = torch.tensor(leaf_union) # convert tuple to list, then to tensor\n",
    "#     print('leaf_union',leaf_union)\n",
    "#     distances = ((leaf_union - query) ** 2).sum(-1)\n",
    "#     print('distances',distances,distances.shape[0])\n",
    "#     indices = distances.topk(k = self.k, largest = False).indices # find k nearest neighbours\n",
    "#     print(leaf_union[indices,:])\n",
    "#     return leaf_union[indices,:]\n",
    "\n",
    "    dim = query.shape[0]\n",
    "    leaf_union = torch.tensor(())\n",
    "    for tree in self.forest:\n",
    "      for leaf in tree.leaves:\n",
    "        if query in leaf:\n",
    "          leaf_union = torch.cat((leaf_union, leaf), 0)\n",
    "          break\n",
    "    leaf_union = torch.unique(leaf_union, dim = 0)\n",
    "    leaf_union = leaf_union.tolist()\n",
    "    leaf_union.remove(query.tolist()) # convert to list to remove query itself\n",
    "    leaf_union = torch.tensor(leaf_union)\n",
    "    print('leaf_union',leaf_union)\n",
    "    print('size',leaf_union.shape[0])\n",
    "#     leaf_union = leaf_union[leaf_union != query] # remove query point from the leaf union\n",
    "#     print('leaf_union',leaf_union)\n",
    "#     leaf_union = torch.reshape(leaf_union,(-1,dim)) # reshape into dimension\n",
    "    distances = ((leaf_union - query) ** 2).sum(-1)\n",
    "#     distances = distances[distances != 0] # remove zeros\n",
    "    print('distances',distances,distances.shape[0])\n",
    "    indices = distances.topk(k = self.k, largest = False).indices # find k nearest neighbours\n",
    "    print(leaf_union[indices,:])\n",
    "#     leaf_union = torch.index_select(leaf_union, 1, indices) # select k nearest neighbours via index\n",
    "    return leaf_union[indices,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.Tensor([[1.0,1.0], [2.0,1.0], [3.0,1.0], [4.0,1.0],\n",
    "                     [1.0,2.0], [2.0,2.0], [3.0,2.0], [4.0,2.0]])  \n",
    "data = torch.randn(size=[10000,4])\n",
    "# print(data)  \n",
    "\n",
    "# t=tree(data)\n",
    "# # print('leaves',t.leaves)\n",
    "# print('sizes',t.sizes)\n",
    "\n",
    "# f=forest(data,k=3,trees=10)\n",
    "# for tree in f.forest:\n",
    "# #   print(tree.leaves)\n",
    "#   print(tree.sizes)\n",
    "\n",
    "# f.find_leaf(torch.tensor([1.0,2.0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
