{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "plot_benchmark_KNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnGGFL5gu-HB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37efa178-5f31-4e65-bb60-7672937caa99"
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install si_prefix\n",
        "!pip install sphinx\n",
        "!pip install pykeops[full] > install.log\n",
        "import pykeops"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: si_prefix in /usr/local/lib/python3.6/dist-packages (1.2.2)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (1.8.5)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx) (0.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx) (20.9)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.23.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx) (0.7.12)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.9.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from sphinx) (53.0.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.15.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.2.4)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.6.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (2020.12.5)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->sphinx) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx) (1.1.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->sphinx) (1.1.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a7cSUpju-HE"
      },
      "source": [
        "\n",
        "# K-Nearest Neighbours search (WIP)\n",
        "\n",
        "Let's compare the performances of PyTorch, JAX, FAISS and KeOps fpr \n",
        "K-NN queries on random samples and standard datasets.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>In this demo, we use exact **bruteforce** computations \n",
        "    (tensorized for PyTorch and online for KeOps), without leveraging any multiscale\n",
        "    or low-rank (Nystroem/multipole) decomposition of the Kernel matrix.\n",
        "    First support for these approximation schemes is scheduled for\n",
        "    May-June 2021.</p></div>\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PHY22IfPelr",
        "outputId": "39af81ca-356a-4664-d031-4807a8349767"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZIUpuFpR-J8",
        "outputId": "ab5db61e-67de-46d8-8d10-c96194e0711b"
      },
      "source": [
        "cd /content/drive/My Drive/keops"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/keops\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AApYbJSFR6DJ",
        "outputId": "3e4fe74d-24ec-4159-c55d-5a40aefed517"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/keops/*.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/My Drive/keops/benchmark_utils.py'\n",
            "'/content/drive/My Drive/keops/dataset_utils.py'\n",
            "'/content/drive/My Drive/keops/ivf_functional.py'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehy3eQIFu-HF"
      },
      "source": [
        "## Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEPoK_WlU889"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/keops')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB6to_r-u-HF"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from functools import partial\n",
        "\n",
        "from benchmark_utils import (\n",
        "    flatten,\n",
        "    random_normal,\n",
        "    full_benchmark,\n",
        "    timer,\n",
        "    tensor,\n",
        "    int_tensor,\n",
        "    jax_tensor,\n",
        ")\n",
        "from dataset_utils import generate_samples\n",
        "\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDyKpw99u-HF"
      },
      "source": [
        "Benchmark specifications:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_tpkXaZu-HF"
      },
      "source": [
        "# Values of K that we'll loop upon:\n",
        "Ks = [1, 25, 100]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe8p3bOpu-HG"
      },
      "source": [
        "## Simple bruteforce implementations\n",
        "\n",
        "Define a simple Gaussian RBF product, using a **tensorized** implementation.\n",
        "Note that expanding the squared norm $\\|x-y\\|^2$ as a sum\n",
        "$\\|x\\|^2 - 2 \\langle x, y \\rangle + \\|y\\|^2$ allows us\n",
        "to leverage the fast matrix-matrix product of the BLAS/cuBLAS\n",
        "libraries.\n",
        "\n",
        "\n",
        "PyTorch bruteforce:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP_Xyycru-HG"
      },
      "source": [
        "\"\"\"\n",
        "def KNN_KeOps(K, metric=\"euclidean\", **kwargs):\n",
        "    def fit(x_train):\n",
        "        # Setup the K-NN estimator:\n",
        "        x_train = tensor(x_train)\n",
        "        start = timer()\n",
        "\n",
        "        # N.B.: The \"training\" time here should be negligible.\n",
        "        elapsed = timer() - start\n",
        "\n",
        "        def f(x_test):\n",
        "            x_test = tensor(x_test)\n",
        "            start = timer()\n",
        "\n",
        "            # Actual K-NN query:\n",
        "\n",
        "            elapsed = timer() - start\n",
        "\n",
        "            indices = indices.cpu().numpy()\n",
        "            return indices, elapsed\n",
        "\n",
        "        return f, elapsed\n",
        "\n",
        "    return fit\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def KNN_torch(K, metric=\"euclidean\", **kwargs):\n",
        "    def fit(x_train):\n",
        "        # Setup the K-NN estimator:\n",
        "        x_train = tensor(x_train)\n",
        "        start = timer()\n",
        "        # The \"training\" time here should be negligible:\n",
        "        x_train_norm = (x_train ** 2).sum(-1)\n",
        "        elapsed = timer() - start\n",
        "\n",
        "        def f(x_test):\n",
        "            x_test = tensor(x_test)\n",
        "            start = timer()\n",
        "\n",
        "            # Actual K-NN query:\n",
        "            if metric == \"euclidean\":\n",
        "                x_test_norm = (x_test ** 2).sum(-1)\n",
        "                diss = (\n",
        "                    x_test_norm.view(-1, 1)\n",
        "                    + x_train_norm.view(1, -1)\n",
        "                    - 2 * x_test @ x_train.t()\n",
        "                )\n",
        "\n",
        "            elif metric == \"manhattan\":\n",
        "                diss = (x_test[:, None, :] - x_train[None, :, :]).abs().sum(dim=2)\n",
        "\n",
        "            elif metric == \"angular\":\n",
        "                diss = -x_test @ x_train.t()\n",
        "\n",
        "            elif metric == \"hyperbolic\":\n",
        "                x_test_norm = (x_test ** 2).sum(-1)\n",
        "                diss = (\n",
        "                    x_test_norm.view(-1, 1)\n",
        "                    + x_train_norm.view(1, -1)\n",
        "                    - 2 * x_test @ x_train.t()\n",
        "                )\n",
        "                diss /= x_test[:, 0].view(-1, 1) * x_train[:, 0].view(1, -1)\n",
        "\n",
        "            out = diss.topk(K, dim=1, largest=False)\n",
        "\n",
        "            elapsed = timer() - start\n",
        "            indices = out.indices.cpu().numpy()\n",
        "            return indices, elapsed\n",
        "\n",
        "        return f, elapsed\n",
        "\n",
        "    return fit"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s8WYh3Wu-HH"
      },
      "source": [
        "PyTorch bruteforce, with small batches to avoid memory overflows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwNQDRJ0u-HH"
      },
      "source": [
        "def KNN_torch_batch_loop(K, metric=\"euclidean\", **kwargs):\n",
        "    def fit(x_train):\n",
        "        # Setup the K-NN estimator:\n",
        "        x_train = tensor(x_train)\n",
        "        Ntrain, D = x_train.shape\n",
        "        start = timer()\n",
        "        # The \"training\" time here should be negligible:\n",
        "        x_train_norm = (x_train ** 2).sum(-1)\n",
        "        elapsed = timer() - start\n",
        "\n",
        "        def f(x_test):\n",
        "            x_test = tensor(x_test)\n",
        "\n",
        "            # Estimate the largest reasonable batch size:\n",
        "            Ntest = x_test.shape[0]\n",
        "            #  torch.cuda.get_device_properties(deviceId).total_memory\n",
        "            av_mem = int(5e8)\n",
        "            Ntest_loop = min(max(1, av_mem // (4 * D * Ntrain)), Ntest)\n",
        "            Nloop = (Ntest - 1) // Ntest_loop + 1\n",
        "            # print(f\"{Ntest} queries, split in {Nloop} batches of {Ntest_loop} queries each.\")\n",
        "            out = int_tensor(Ntest, K)\n",
        "\n",
        "            start = timer()\n",
        "            # Actual K-NN query:\n",
        "            for k in range(Nloop):\n",
        "                x_test_k = x_test[Ntest_loop * k : Ntest_loop * (k + 1), :]\n",
        "                if metric == \"euclidean\":\n",
        "                    x_test_norm = (x_test_k ** 2).sum(-1)\n",
        "                    diss = (\n",
        "                        x_test_norm.view(-1, 1)\n",
        "                        + x_train_norm.view(1, -1)\n",
        "                        - 2 * x_test_k @ x_train.t()\n",
        "                    )\n",
        "\n",
        "                elif metric == \"manhattan\":\n",
        "                    diss = (x_test_k[:, None, :] - x_train[None, :, :]).abs().sum(dim=2)\n",
        "\n",
        "                elif metric == \"angular\":\n",
        "                    diss = -x_test_k @ x_train.t()\n",
        "\n",
        "                elif metric == \"hyperbolic\":\n",
        "                    x_test_norm = (x_test_k ** 2).sum(-1)\n",
        "                    diss = (\n",
        "                        x_test_norm.view(-1, 1)\n",
        "                        + x_train_norm.view(1, -1)\n",
        "                        - 2 * x_test_k @ x_train.t()\n",
        "                    )\n",
        "                    diss /= x_test_k[:, 0].view(-1, 1) * x_train[:, 0].view(1, -1)\n",
        "\n",
        "                out[Ntest_loop * k : Ntest_loop * (k + 1), :] = diss.topk(\n",
        "                    K, dim=1, largest=False\n",
        "                ).indices\n",
        "                del diss\n",
        "            # torch.cuda.empty_cache()\n",
        "\n",
        "            elapsed = timer() - start\n",
        "            indices = out.cpu().numpy()\n",
        "            return indices, elapsed\n",
        "\n",
        "        return f, elapsed\n",
        "\n",
        "    return fit"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AduYd69ou-HH"
      },
      "source": [
        "Distance matrices with JAX:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyFtOAXAu-HI"
      },
      "source": [
        "from functools import partial\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "@partial(jax.jit, static_argnums=(2, 3))\n",
        "def knn_jax_fun(x_train, x_test, K, metric):\n",
        "    if metric == \"euclidean\":\n",
        "        diss = (\n",
        "            (x_test ** 2).sum(-1)[:, None]\n",
        "            + (x_train ** 2).sum(-1)[None, :]\n",
        "            - 2 * x_test @ x_train.T\n",
        "        )\n",
        "    elif metric == \"manhattan\":\n",
        "        diss = jax.lax.abs(x_test[:, None, :] - x_train[None, :, :]).sum(-1)\n",
        "    elif metric == \"angular\":\n",
        "        diss = -x_test @ x_train.T\n",
        "    elif metric == \"hyperbolic\":\n",
        "        diss = (\n",
        "            (x_test ** 2).sum(-1)[:, None]\n",
        "            + (x_train ** 2).sum(-1)[None, :]\n",
        "            - 2 * x_test @ x_train.T\n",
        "        )\n",
        "        diss = diss / (x_test[:, 0][:, None] * x_train[:, 0][None, :])\n",
        "\n",
        "    indices = jax.lax.top_k(-diss, K)[1]\n",
        "    return indices"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efxgnou5u-HI"
      },
      "source": [
        "JAX bruteforce:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tNs_Wdfu-HI"
      },
      "source": [
        "def KNN_JAX(K, metric=\"euclidean\", **kwargs):\n",
        "    def fit(x_train):\n",
        "\n",
        "        # Setup the K-NN estimator:\n",
        "        start = timer(use_torch=False)\n",
        "        x_train = jax_tensor(x_train)\n",
        "        elapsed = timer(use_torch=False) - start\n",
        "\n",
        "        def f(x_test):\n",
        "            x_test = jax_tensor(x_test)\n",
        "\n",
        "            # Actual K-NN query:\n",
        "            start = timer(use_torch=False)\n",
        "            indices = knn_jax_fun(x_train, x_test, K, metric)\n",
        "            indices = np.array(indices)\n",
        "            elapsed = timer(use_torch=False) - start\n",
        "            return indices, elapsed\n",
        "\n",
        "        return f, elapsed\n",
        "\n",
        "    return fit"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry-KyfaJu-HI"
      },
      "source": [
        "JAX bruteforce, with small batches to avoid memory overflows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBi31b5Qu-HI"
      },
      "source": [
        "def KNN_JAX_batch_loop(K, metric=\"euclidean\", **kwargs):\n",
        "    def fit(x_train):\n",
        "\n",
        "        # Setup the K-NN estimator:\n",
        "        start = timer(use_torch=False)\n",
        "        x_train = jax_tensor(x_train)\n",
        "        elapsed = timer(use_torch=False) - start\n",
        "\n",
        "        def f(x_test):\n",
        "            x_test = jax_tensor(x_test)\n",
        "\n",
        "            # Estimate the largest reasonable batch size\n",
        "            #  torch.cuda.get_device_properties(deviceId).total_memory\n",
        "            av_mem = int(5e8)\n",
        "            Ntrain, D = x_train.shape\n",
        "            Ntest = x_test.shape[0]\n",
        "            Ntest_loop = min(max(1, av_mem // (4 * D * Ntrain)), Ntest)\n",
        "            Nloop = (Ntest - 1) // Ntest_loop + 1\n",
        "            # print(f\"{Ntest} queries, split in {Nloop} batches of {Ntest_loop} queries each.\")\n",
        "            indices = np.zeros((Ntest, K), dtype=int)\n",
        "\n",
        "            start = timer(use_torch=False)\n",
        "            # Actual K-NN query:\n",
        "            for k in range(Nloop):\n",
        "                x_test_k = x_test[Ntest_loop * k : Ntest_loop * (k + 1), :]\n",
        "                indices[Ntest_loop * k : Ntest_loop * (k + 1), :] = knn_jax_fun(\n",
        "                    x_train, x_test_k, K, metric\n",
        "                )\n",
        "            elapsed = timer(use_torch=False) - start\n",
        "            return indices, elapsed\n",
        "\n",
        "        return f, elapsed\n",
        "\n",
        "    return fit"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqMWi1rlu-HJ"
      },
      "source": [
        "KeOps bruteforce implementation:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI8sv_cnu-HJ"
      },
      "source": [
        "from pykeops.torch import LazyTensor, Vi, Vj\n",
        "\n",
        "\n",
        "def KNN_KeOps(K, metric=\"euclidean\", **kwargs):\n",
        "    def fit(x_train):\n",
        "        # Setup the K-NN estimator:\n",
        "        x_train = tensor(x_train)\n",
        "        start = timer()\n",
        "\n",
        "        # Encoding as KeOps LazyTensors:\n",
        "        D = x_train.shape[1]\n",
        "        X_i = Vi(0, D)\n",
        "        X_j = Vj(1, D)\n",
        "\n",
        "        # Symbolic distance matrix:\n",
        "        if metric == \"euclidean\":\n",
        "            D_ij = ((X_i - X_j) ** 2).sum(-1)\n",
        "        elif metric == \"manhattan\":\n",
        "            D_ij = (X_i - X_j).abs().sum(-1)\n",
        "        elif metric == \"angular\":\n",
        "            D_ij = -(X_i | X_j)\n",
        "        elif metric == \"hyperbolic\":\n",
        "            D_ij = ((X_i - X_j) ** 2).sum(-1) / (X_i[0] * X_j[0])\n",
        "\n",
        "        # K-NN query operator:\n",
        "        KNN_fun = D_ij.argKmin(K, dim=1)\n",
        "\n",
        "        # N.B.: The \"training\" time here should be negligible.\n",
        "        elapsed = timer() - start\n",
        "\n",
        "        def f(x_test):\n",
        "            x_test = tensor(x_test)\n",
        "            start = timer()\n",
        "\n",
        "            # Actual K-NN query:\n",
        "            indices = KNN_fun(x_test, x_train)\n",
        "\n",
        "            elapsed = timer() - start\n",
        "\n",
        "            indices = indices.cpu().numpy()\n",
        "            return indices, elapsed\n",
        "\n",
        "        return f, elapsed\n",
        "\n",
        "    return fit"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfSybhzpXV1f"
      },
      "source": [
        "from ivf_functional import IVF_flat as ivf\n",
        "def ivf_flat(K,  **kwargs):\n",
        "    KNN_meth = ivf(k=K)\n",
        "\n",
        "    def fit(x_train,clusters=50):\n",
        "        \n",
        "        x_train = tensor(x_train)\n",
        "\n",
        "        start = timer()\n",
        "        KNN_fun = KNN_meth.fit(x_train).kneighbors\n",
        "        elapsed = timer() - start\n",
        "\n",
        "        def f(x_test):\n",
        "            x_test = tensor(x_test)\n",
        "            start = timer()\n",
        "            indices = KNN.kneighbors(x_test)\n",
        "            elapsed = timer() - start\n",
        "\n",
        "            return indices, elapsed\n",
        "\n",
        "        return f, elapsed\n",
        "\n",
        "    return fit\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_5LC3WYu-HJ"
      },
      "source": [
        "## SciKit-Learn tree-based and bruteforce methods\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWWhRDy_u-HJ"
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "def KNN_sklearn(K, metric=\"euclidean\", algorithm=None, **kwargs):\n",
        "\n",
        "    if metric in [\"euclidean\", \"angular\"]:\n",
        "        p = 2\n",
        "    elif metric == \"manhattan\":\n",
        "        p = 1\n",
        "    else:\n",
        "        raise NotImplementedError(\"This distance is not supported.\")\n",
        "\n",
        "    KNN_meth = NearestNeighbors(n_neighbors=K, algorithm=algorithm, p=p, n_jobs=-1)\n",
        "\n",
        "    def fit(x_train):\n",
        "        # Setup the K-NN estimator:\n",
        "        start = timer()\n",
        "        KNN_fun = KNN_meth.fit(x_train).kneighbors\n",
        "        elapsed = timer() - start\n",
        "\n",
        "        def f(x_test):\n",
        "            start = timer()\n",
        "            distances, indices = KNN_fun(x_test)\n",
        "            elapsed = timer() - start\n",
        "\n",
        "            return indices, elapsed\n",
        "\n",
        "        return f, elapsed\n",
        "\n",
        "    return fit\n",
        "\n",
        "\n",
        "KNN_sklearn_auto = partial(KNN_sklearn, algorithm=\"auto\")\n",
        "KNN_sklearn_ball_tree = partial(KNN_sklearn, algorithm=\"ball_tree\")\n",
        "KNN_sklearn_kd_tree = partial(KNN_sklearn, algorithm=\"kd_tree\")\n",
        "KNN_sklearn_brute = partial(KNN_sklearn, algorithm=\"brute\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtbM6gcOu-HK"
      },
      "source": [
        "## NumPy vs. PyTorch vs. KeOps (Gpu)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8aKGYQHu-HK"
      },
      "source": [
        "def run_KNN_benchmark(name=None,**kwargs):\n",
        "\n",
        "    # Load the dataset and some info:\n",
        "    dataset = generate_samples(key=name,**kwargs)(1)\n",
        "    N_train, dimension = dataset[\"train\"].shape\n",
        "    N_test, _ = dataset[\"test\"].shape\n",
        "    metric = dataset[\"metric\"]\n",
        "\n",
        "    # Routines to benchmark:\n",
        "    routines = [\n",
        "        (ivf_flat, \"IVF-Flat Keops (GPU)\", {}),\n",
        "        (KNN_sklearn_auto, \"sklearn, auto (CPU)\", {}),\n",
        "        (KNN_sklearn_ball_tree, \"sklearn, Ball-tree (CPU)\", {}),\n",
        "        (KNN_sklearn_kd_tree, \"sklearn, KD-tree (CPU)\", {}),\n",
        "        (KNN_sklearn_brute, \"sklearn, bruteforce (CPU)\", {}),\n",
        "        (KNN_torch, \"PyTorch (GPU)\", {}),\n",
        "        (KNN_torch_batch_loop, \"PyTorch (small batches, GPU)\", {}),\n",
        "        (KNN_KeOps, \"KeOps (GPU)\", {}),\n",
        "        (KNN_JAX, \"JAX (GPU)\", {}),\n",
        "        (KNN_JAX_batch_loop, \"JAX (small batches, GPU)\", {}),\n",
        "    ]\n",
        "\n",
        "    # Actual run:\n",
        "    full_benchmark(\n",
        "        f\"K-NN search on: {N_test:,} queries on a dataset of {N_train:,} points\\nin dimension {dimension:,} with a {metric} metric.\",\n",
        "        routines,\n",
        "        generate_samples(key=name,**kwargs),\n",
        "        min_time=1e-4,\n",
        "        max_time=120,\n",
        "        problem_sizes=Ks,\n",
        "        xlabel=\"Number of neighbours K\",\n",
        "    )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35Qf2xcPu-HK"
      },
      "source": [
        "## On random samples:\n",
        "\n",
        "Small dataset in $\\mathbb{R}^3$:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWRzY8pSu-HK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f86652-a968-4120-d1da-1427c44209ec"
      },
      "source": [
        "run_KNN_benchmark(metric='euclidean',ntrain=10**5,ntest=10**5,d=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Benchmarking : K-NN search on: 100,000 queries on a dataset of 100,000 points\n",
            "in dimension 2 with a euclidean metric. ===============================\n",
            "IVF-Flat Keops (GPU) -------------\n",
            "** Too slow!\n",
            "sklearn, auto (CPU) -------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjodIoAMu-HL"
      },
      "source": [
        "Large dataset in $\\mathbb{R}^3$:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6CgaZCtu-HL"
      },
      "source": [
        "run_KNN_benchmark(\"R^D b\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}