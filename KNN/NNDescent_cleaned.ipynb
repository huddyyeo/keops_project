{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNDescent_cleaned.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4s3np_UZreV"
      },
      "source": [
        "NNDescent algorithm implementation using PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHHvHHhEDmOe"
      },
      "source": [
        "!pip install pykeops[colab] > install.log"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8X2Du_TGNZI"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "from pykeops.torch import LazyTensor\n",
        "from pykeops.torch.cluster import cluster_ranges_centroids, from_matrix, sort_clusters\n",
        "from pykeops.torch.utils import torchtools\n",
        "\n",
        "#use_cuda = torch.cuda.is_available()\n",
        "#if use_cuda:\n",
        "  #torch.cuda.synchronize()\n",
        "  #device = torch.device('cuda')\n",
        "#else:\n",
        "  #device  = torch.device('cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROrGhC9YYCsN"
      },
      "source": [
        "import torch\n",
        "\n",
        "from pykeops.torch import Genred, KernelSolve, default_dtype\n",
        "from pykeops.torch.cluster import swap_axes as torch_swap_axes\n",
        "from pykeops.torch.cluster import grid_cluster as torch_grid_cluster\n",
        "from pykeops.torch.cluster import from_matrix as torch_from_matrix\n",
        "from pykeops.torch.cluster import (\n",
        "    cluster_ranges_centroids as torch_cluster_ranges_centroids,\n",
        ")\n",
        "from pykeops.torch.cluster import cluster_ranges as torch_cluster_ranges\n",
        "from pykeops.torch.cluster import sort_clusters as torch_sort_clusters\n",
        "\n",
        "# from pykeops.torch.generic.generic_red import GenredLowlevel\n",
        "\n",
        "\n",
        "def is_on_device(x):\n",
        "    return x.is_cuda\n",
        "\n",
        "class torchtools:\n",
        "    copy = torch.clone\n",
        "    exp = torch.exp\n",
        "    log = torch.log\n",
        "    norm = torch.norm\n",
        "    sqrt = torch.sqrt\n",
        "\n",
        "    swap_axes = torch_swap_axes\n",
        "\n",
        "    Genred = Genred\n",
        "    KernelSolve = KernelSolve\n",
        "    grid_cluster = torch_grid_cluster\n",
        "    from_matrix = torch_from_matrix\n",
        "    cluster_ranges_centroids = torch_cluster_ranges_centroids\n",
        "    cluster_ranges = torch_cluster_ranges\n",
        "    sort_clusters = torch_sort_clusters\n",
        "\n",
        "    arraytype = torch.Tensor\n",
        "    float_types = [float]\n",
        "\n",
        "    arraytype = torch.Tensor\n",
        "    float_types = [float]\n",
        "\n",
        "    # GenredLowlevel = GenredLowlevel\n",
        "\n",
        "    @staticmethod\n",
        "    def eq(x, y):\n",
        "        return torch.eq(x, y)\n",
        "\n",
        "    @staticmethod\n",
        "    def transpose(x):\n",
        "        return x.t()\n",
        "\n",
        "    @staticmethod\n",
        "    def permute(x, *args):\n",
        "        return x.permute(*args)\n",
        "\n",
        "    @staticmethod\n",
        "    def contiguous(x):\n",
        "        return x.contiguous()\n",
        "\n",
        "    @staticmethod\n",
        "    def solve(A, b):\n",
        "        return torch.solve(b, A)[0].contiguous()\n",
        "\n",
        "    @staticmethod\n",
        "    def arraysum(x, axis=None):\n",
        "        return x.sum() if axis is None else x.sum(dim=axis)\n",
        "\n",
        "    @staticmethod\n",
        "    def long(x):\n",
        "        return x.long()\n",
        "\n",
        "    @staticmethod\n",
        "    def size(x):\n",
        "        return x.numel()\n",
        "\n",
        "    @staticmethod\n",
        "    def tile(*args):\n",
        "        return torch.Tensor.repeat(*args)\n",
        "\n",
        "    @staticmethod\n",
        "    def numpy(x):\n",
        "        return x.detach().cpu().numpy()\n",
        "\n",
        "    @staticmethod\n",
        "    def view(x, s):\n",
        "        return x.view(s)\n",
        "\n",
        "    @staticmethod\n",
        "    def is_tensor(x):\n",
        "        return isinstance(x, torch.Tensor)\n",
        "\n",
        "    @staticmethod\n",
        "    def dtype(x):\n",
        "        if hasattr(x, \"dtype\"):\n",
        "            return x.dtype\n",
        "        else:\n",
        "            return type(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_complex(x):\n",
        "        if type(x) == list:\n",
        "            return any(type(v) == complex for v in x)\n",
        "        elif type(x) == torch.Tensor:\n",
        "            return torch.is_complex(x)\n",
        "        else:\n",
        "            return type(x) == complex\n",
        "\n",
        "    @staticmethod\n",
        "    def view_as_complex(x):\n",
        "        sh = list(x.shape)\n",
        "        sh[-1] //= 2\n",
        "        sh += [2]\n",
        "        x = x.view(sh)\n",
        "        return torch.view_as_complex(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def view_as_real(x):\n",
        "        sh = list(x.shape)\n",
        "        sh[-1] *= 2\n",
        "        return torch.view_as_real(x).view(sh)\n",
        "\n",
        "    @staticmethod\n",
        "    def dtypename(dtype):\n",
        "        if dtype == torch.float32:\n",
        "            return \"float32\"\n",
        "        elif dtype == torch.float64:\n",
        "            return \"float64\"\n",
        "        elif dtype == torch.float16:\n",
        "            return \"float16\"\n",
        "        elif dtype == int:\n",
        "            return int\n",
        "        elif dtype == list:\n",
        "            return \"float32\"\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"[KeOps] {} data type incompatible with KeOps.\".format(dtype)\n",
        "            )\n",
        "\n",
        "    @staticmethod\n",
        "    def rand(m, n, dtype=default_dtype, device=\"cpu\"):\n",
        "        return torch.rand(m, n, dtype=dtype, device=device)\n",
        "\n",
        "    @staticmethod\n",
        "    def randn(m, n, dtype=default_dtype, device=\"cpu\"):\n",
        "        return torch.randn(m, n, dtype=dtype, device=device)\n",
        "\n",
        "    @staticmethod\n",
        "    def zeros(shape, dtype=default_dtype, device=\"cpu\"):\n",
        "        return torch.zeros(shape, dtype=dtype, device=device)\n",
        "\n",
        "    @staticmethod\n",
        "    def eye(n, dtype=default_dtype, device=\"cpu\"):\n",
        "        return torch.eye(n, dtype=dtype, device=device)\n",
        "\n",
        "    @staticmethod\n",
        "    def array(x, dtype=default_dtype, device=\"cpu\"):\n",
        "        if dtype == \"float32\":\n",
        "            dtype = torch.float32\n",
        "        elif dtype == \"float64\":\n",
        "            dtype = torch.float64\n",
        "        elif dtype == \"float16\":\n",
        "            dtype = torch.float16\n",
        "        else:\n",
        "            raise ValueError(\"[KeOps] data type incompatible with KeOps.\")\n",
        "        return torch.tensor(x, dtype=dtype, device=device)\n",
        "\n",
        "    @staticmethod\n",
        "    def device(x):\n",
        "        if isinstance(x, torch.Tensor):\n",
        "            return x.device\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def distance_function(metric):\n",
        "        def euclidean(x, y):\n",
        "            return ((x - y) ** 2).sum(-1)\n",
        "\n",
        "        def manhattan(x, y):\n",
        "            return ((x - y).abs()).sum(-1)\n",
        "\n",
        "        def angular(x, y):\n",
        "            return -(x | y)\n",
        "\n",
        "        def angular_full(x, y):\n",
        "            return angular(x, y) / ((angular(x, x) * angular(y, y)).sqrt())\n",
        "\n",
        "        def hyperbolic(x, y):\n",
        "            return ((x - y) ** 2).sum(-1) / (x[0] * y[0])\n",
        "\n",
        "        if metric == \"euclidean\":\n",
        "            return euclidean\n",
        "        elif metric == \"manhattan\":\n",
        "            return manhattan\n",
        "        elif metric == \"angular\":\n",
        "            return angular\n",
        "        elif metric == \"angular_full\":\n",
        "            return angular_full\n",
        "        elif metric == \"hyperbolic\":\n",
        "            return hyperbolic\n",
        "        else:\n",
        "            raise ValueError(\"Unknown metric\")\n",
        "\n",
        "    @staticmethod\n",
        "    def sort(x):\n",
        "        return torch.sort(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def unsqueeze(x, n):\n",
        "        return torch.unsqueeze(x, n)\n",
        "\n",
        "    @staticmethod\n",
        "    def arange(n, device=\"cpu\"):\n",
        "        return torch.arange(n, device=device)\n",
        "\n",
        "    @staticmethod\n",
        "    def repeat(x, n):\n",
        "        return torch.repeat_interleave(x, n)\n",
        "\n",
        "    @staticmethod\n",
        "    def to(x, device):\n",
        "        if isinstance(x, torch.Tensor):\n",
        "            return x.to(device)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def index_select(input, dim, index):\n",
        "        return torch.index_select(input, dim, index)\n",
        "\n",
        "    @staticmethod\n",
        "    def kmeans(x, distance=None, K=10, Niter=15, device=\"cuda\", approx=False, n=10):\n",
        "\n",
        "        from pykeops.torch import LazyTensor\n",
        "\n",
        "        if distance is None:\n",
        "            distance = torchtools.distance_function(\"euclidean\")\n",
        "\n",
        "        def calc_centroid(x, c, cl, n=10):\n",
        "            \"Helper function to optimise centroid location\"\n",
        "            c = torch.clone(c.detach()).to(device)\n",
        "            c.requires_grad = True\n",
        "            x1 = LazyTensor(x.unsqueeze(0))\n",
        "            op = torch.optim.Adam([c], lr=1 / n)\n",
        "            scaling = 1 / torch.gather(torch.bincount(cl), 0, cl).view(-1, 1)\n",
        "            scaling.requires_grad = False\n",
        "            with torch.autograd.set_detect_anomaly(True):\n",
        "                for _ in range(n):\n",
        "                    c.requires_grad = True\n",
        "                    op.zero_grad()\n",
        "                    c1 = LazyTensor(torch.index_select(c, 0, cl).unsqueeze(0))\n",
        "                    d = distance(x1, c1)\n",
        "                    loss = (\n",
        "                        d.sum(0) * scaling\n",
        "                    ).sum()  # calculate distance to centroid for each datapoint, divide by total number of points in that cluster, and sum\n",
        "                    loss.backward(retain_graph=False)\n",
        "                    op.step()\n",
        "            return c.detach()\n",
        "\n",
        "        N, D = x.shape\n",
        "        c = x[:K, :].clone()\n",
        "        x_i = LazyTensor(x.view(N, 1, D).to(device))\n",
        "\n",
        "        for i in range(Niter):\n",
        "            c_j = LazyTensor(c.view(1, K, D).to(device))\n",
        "            D_ij = distance(x_i, c_j)\n",
        "            cl = D_ij.argmin(dim=1).long().view(-1)\n",
        "\n",
        "            # updating c: either with approximation or exact\n",
        "            if approx:\n",
        "                # approximate with GD optimisation\n",
        "                c = calc_centroid(x, c, cl, n)\n",
        "\n",
        "            else:\n",
        "                # exact from average\n",
        "                c.zero_()\n",
        "                c.scatter_add_(0, cl[:, None].repeat(1, D), x)\n",
        "                Ncl = torch.bincount(cl, minlength=K).type_as(c).view(K, 1)\n",
        "                c /= Ncl\n",
        "\n",
        "            if torch.any(torch.isnan(c)):\n",
        "                raise ValueError(\n",
        "                    \"NaN detected in centroids during KMeans, please check metric is correct\"\n",
        "                )\n",
        "        return cl, c\n",
        "\n",
        "    @staticmethod\n",
        "    def is_tensor(x):\n",
        "        return isinstance(x, torch.Tensor)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v23EimYwHprW"
      },
      "source": [
        "class NNDescent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        data=None,\n",
        "        k=5,\n",
        "        metric=\"euclidean\",\n",
        "        initialization_method=\"forest\",\n",
        "        num_trees=5,\n",
        "        leaf_multiplier=128,\n",
        "        big_leaf_depth=5,\n",
        "        verbose=False,\n",
        "        backend=\"torch\",\n",
        "    ):\n",
        "        \"\"\"Initialize the NNDescent class.\n",
        "\n",
        "        Initializes the NNDescent class given all relevant parameters. If data is\n",
        "        provided, it fits the NNDescent search graph to the data.\n",
        "        NNDescent is an approximation strategy for k-Nearest Neighbor search. It\n",
        "        constructs a k-NN graph on the dataset, which is then navigated with a \n",
        "        graph-based search algorithm during query time.\n",
        "\n",
        "        The original paper on the method: https://www.cs.princeton.edu/cass/papers/www11.pdf\n",
        "        Our code was inspired by the PyNNDescent documentation: https://pynndescent.readthedocs.io/en/latest/how_pynndescent_works.html \n",
        "\n",
        "        Args:\n",
        "            data ((N,D) Tensor): Dataset of N datapoints of dimensionality D.\n",
        "            k (int): The number of nearest neighbors which we want to find for each query point\n",
        "            metric (string): Name of metric, either \"euclidean\" and \"manhattan\"\n",
        "            initialization_method (string): The type of initialization to be used for\n",
        "                the search graph. Can be \"random\", \"random_big\", \"forest\" or \"cluster\".\n",
        "            num_trees (int): Number of trees used in \"random_big\" or \"forest\" initializations.\n",
        "            big_leaf_depth (int): The depth at which the big leaves are taken to be used at\n",
        "                the start of search.\n",
        "            verbose (boolean): Determines whether or not to print information while fitting.\n",
        "            backend (string): Either \"torch\" or \"keops\". Determines if we want to use LazyTensors in cluster initialization.\n",
        "\n",
        "        Args not used when initialization_method = \"cluster\":\n",
        "            leaf_multiplier (int): Parameter for the Tree class for tree-based initializations.\n",
        "                when initialization_method = \"cluster\", this parameter is used to adjust the number\n",
        "                of clusters to be close to the value specified in the fit function.\n",
        "        \"\"\"\n",
        "\n",
        "        # Setting parameters\n",
        "        self.k = k\n",
        "        self.metric = metric\n",
        "        self.init_method = initialization_method\n",
        "        self.num_trees = num_trees\n",
        "        self.leaf_multiplier = leaf_multiplier\n",
        "        self.big_leaf_depth = big_leaf_depth\n",
        "        self.big_leaves = None\n",
        "        self.backend = backend\n",
        "\n",
        "        # Distance function\n",
        "        self.distance = torchtools.distance_function(metric)\n",
        "\n",
        "        # If data is provided, we call the fit function.\n",
        "        if data is not None:\n",
        "            self.fit(data, verbose=verbose)\n",
        "\n",
        "\n",
        "    def fit(self, X, iter=20, verbose=False, clusters=32, a=10, queue=5):\n",
        "        \"\"\"Fits the NNDescent search graph to the data set X.\n",
        "\n",
        "        Args:\n",
        "            X ((N,D) Tensor): Dataset of N datapoints of dimensionality D.\n",
        "            iter (int): Maximum number of iterations for graph updates\n",
        "            verbose (boolean): Determines whether or not to print information while fitting.\n",
        "            queue (int): The number of neighbors to which each node connects in the search graph.\n",
        "\n",
        "        Used only when initialization_method = \"cluster\":\n",
        "            clusters (int): The min no. of clusters that we want the data to be clustered into\n",
        "            a (int): The number of clusters we want to search over using the cluster method.\n",
        "\n",
        "        \"\"\"\n",
        "        self.data = X\n",
        "        self.device = X.device\n",
        "        self.queue = queue\n",
        "\n",
        "        if queue < self.k and self.init_method is not \"cluster\":\n",
        "            self.queue = self.k\n",
        "            print( \"Warning: Value of queue must be larger than or equal to k! Set queue = k.\" )\n",
        "        elif queue > a and self.init_method is \"cluster\":\n",
        "            raise ValueError(\"Value of queue must be smaller than value of a!\")\n",
        "        elif clusters < 2**self.big_leaf_depth:\n",
        "            # This is neccesary to use the more efficient initial points in the graph search.\n",
        "            raise ValueError(\"Minimum number of clusters is 2^big_leaf_depth!\")\n",
        "        elif a > clusters:\n",
        "            raise ValueError(\"Number of clusters must be larger than or equal to a!\")\n",
        "        elif X.is_cuda and self.init_method is not \"cluster\":\n",
        "            raise ValueError(\"CUDA not supported for non-cluster version of NNDescent.\")\n",
        "\n",
        "        # A 2D tensor representing a directed graph.\n",
        "        # The value a = graph[i,j] represents an edge from point x_i to x_a.\n",
        "        N = X.shape[0]\n",
        "        self.graph = torch.zeros(size=[N, self.queue], dtype=torch.long)\n",
        "\n",
        "        # Initialize graph\n",
        "        if self.init_method == \"random\":\n",
        "            self._initialize_graph_randomly()\n",
        "        elif self.init_method == \"random_big\":\n",
        "            self._initialize_graph_big_random(self.data, self.num_trees)\n",
        "        elif self.init_method == \"forest\":\n",
        "            self._initialize_graph_forest(\n",
        "                self.data, self.num_trees, self.leaf_multiplier, self.big_leaf_depth\n",
        "            )\n",
        "        elif self.init_method == \"cluster\":\n",
        "            # Parameters used only for cluster search\n",
        "            self.a = a\n",
        "            self.num_clusters = clusters\n",
        "            self._initialize_graph_clusters(self.data)\n",
        "\n",
        "        # A set of tuples (i,j) of indices for which the distance has already been calculated.\n",
        "        self.explored_edges = set()\n",
        "\n",
        "        if self.init_method != \"cluster\":\n",
        "            # A 2D tensor representing the distance between point x_i and x_graph[i,j]\n",
        "            self.k_distances = torch.zeros([N, self.queue])\n",
        "\n",
        "            # Update the graph\n",
        "            self._calculate_all_distances()\n",
        "            self._update_graph(iter=iter, verbose=verbose)\n",
        "\n",
        "    def _update_graph(self, iter, verbose=False):\n",
        "        \"\"\"Updates the current estimate for the kNN-graph with the iterative NN-Descent algorithm\n",
        "        \n",
        "        See https://pynndescent.readthedocs.io/en/latest/how_pynndescent_works.html for detailed explanation.\n",
        "\n",
        "        Args:\n",
        "            iter (int): Number of iterations to use when updating search graph.\n",
        "            verbose (boolean): Printing information about iterations while searching.\n",
        "        \"\"\"\n",
        "        # [STEP 1: Start with random graph.] Iterate\n",
        "        start = time.time()\n",
        "        for it in range(iter):\n",
        "            if verbose:\n",
        "                print(f\"Iteration number {it} with average distance of {torch.mean(self.k_distances).item()}. Took {time.time() - start} seconds.\")\n",
        "            has_changed = False\n",
        "\n",
        "            # [STEP 2: For each node:] (TODO: Investigate whether this can be vectorized.)\n",
        "            for i, neighbors in enumerate(self.graph):\n",
        "                # Distances of current neighbors\n",
        "                dist_current_neighbors = self.k_distances[i]\n",
        "\n",
        "                # [STEP 3: Measure distance from the node to the neighbors of its neighbors]\n",
        "                # Find neighbors of neighbors\n",
        "                potential_neighbors = {\n",
        "                    a.item()\n",
        "                    for a in self.graph[neighbors].flatten()\n",
        "                    if a not in neighbors\n",
        "                    and a != i\n",
        "                    and (i, int(a)) not in self.explored_edges\n",
        "                }\n",
        "                potential_distances = torch.Tensor(\n",
        "                    [\n",
        "                        self.distance(self.data[i], self.data[n])\n",
        "                        for n in potential_neighbors\n",
        "                    ]\n",
        "                )\n",
        "                self.explored_edges.update([(i, int(r)) for r in potential_neighbors])\n",
        "\n",
        "                # Concatenate potential neighbors to list of neighbors (indices and distances)\n",
        "                cat_idx = torch.cat(\n",
        "                    [neighbors, torch.Tensor(list(potential_neighbors))]\n",
        "                )\n",
        "                cat_dist = torch.cat([self.k_distances[i], potential_distances])\n",
        "\n",
        "                # [STEP 4: If any are closer, then update the graph accordingly, and only keep the k closest]\n",
        "                dist_sorted, idx = torch.sort(cat_dist)\n",
        "                if torch.max(idx[: self.queue]) >= self.queue:\n",
        "                    has_changed = True\n",
        "                    self.graph[i] = cat_idx[idx[: self.queue]]\n",
        "                    self.k_distances[i] = dist_sorted[: self.queue]\n",
        "\n",
        "            # [STEP 5: If any changes were made, repeat iteration, otherwise stop]\n",
        "            if not has_changed:\n",
        "                if verbose:\n",
        "                    print(f\"Fitting complete! Took {it} iterations.\")\n",
        "                break\n",
        "\n",
        "    def kneighbors(self, X, max_num_steps=100, tree_init=True, verbose=False):\n",
        "        \"\"\"Returns k nearest neighbors of input X using NNDescent.\n",
        "\n",
        "        Our code is largely based on this algorithm:\n",
        "          https://pynndescent.readthedocs.io/en/latest/how_pynndescent_works.html#Searching-using-a-nearest-neighbor-graph\n",
        "\n",
        "        If init_method = 'clusters', we first cluster the data. Each node in the graph then represents a cluster.\n",
        "        We then use the KeOps engine to perform the final nearest neighbours search over the nearest clusters to each query point\n",
        "\n",
        "        Args:\n",
        "            X ((N,D) Tensor): A query set for which to find k neighbors.\n",
        "            K (int): How many neighbors to search for. Must be <=self.k for non-cluster methods. Default: self.k\n",
        "            max_num_steps (int): The maximum number of steps to take during search.\n",
        "            tree_init (boolean): Determine whether or not to use big leaves from projection trees as the starting point of search.\n",
        "            verbose (boolean): Printing information about iterations while searching.\n",
        "    \n",
        "        Returns:\n",
        "            The indices of the k nearest neighbors in the fitted data.\n",
        "        \"\"\"\n",
        "\n",
        "        # N datapoints of dimension d\n",
        "        N, d = X.shape\n",
        "        k = self.queue\n",
        "\n",
        "        # Boolean mask to keep track of those points whose search is still ongoing\n",
        "        is_active = torch.ones(N) == 1\n",
        "\n",
        "        # If graph was initialized using trees, we can use information from there to initialize in a diversed manner.\n",
        "        if self.big_leaves is not None and tree_init:\n",
        "            candidate_idx = self.big_leaves.unsqueeze(0).repeat(N, 1)  # Shape: (N,2**self.big_leaf_depth)\n",
        "        else:\n",
        "            # Random initialization for starting points of search.\n",
        "            candidate_idx = torch.randint(\n",
        "                high=len(self.data), size=[N, k + 1], dtype=torch.long\n",
        "            )\n",
        "\n",
        "        if self.init_method == \"cluster\":\n",
        "            is_active = is_active.to(self.device)\n",
        "            candidate_idx = candidate_idx.to(self.device)\n",
        "\n",
        "        # Sort the candidates by distance from X\n",
        "        distances = self.distance(self.data[candidate_idx], X.unsqueeze(1))\n",
        "        # distances = ((self.data[candidate_idx] - X.unsqueeze(1))**2).sum(-1)\n",
        "        sorted, idx = torch.sort(distances, dim=1)\n",
        "        candidate_idx = torch.gather(candidate_idx, dim=1, index=idx)\n",
        "        # Truncate to k+1 nearest\n",
        "        candidate_idx = candidate_idx[:, : (k + 1)]\n",
        "\n",
        "        # Track the nodes we have explored already, in N x num_explored tensor\n",
        "        num_explored = k * 2\n",
        "        explored = torch.full(size=[N, num_explored], fill_value=-1)\n",
        "\n",
        "        if self.init_method == \"cluster\":\n",
        "            explored = explored.to(self.device)\n",
        "\n",
        "        start = time.time()\n",
        "        # The initialization of candidates and explored set is done. Now we can search.\n",
        "        count = 0\n",
        "        while count < max_num_steps:\n",
        "            if verbose:\n",
        "                print(f\"Step {count} - Search is completed for {1 - torch.mean(1.0 * is_active).item()} - this step took {time.time() - start} s\")\n",
        "            start = time.time()\n",
        "\n",
        "            # [2. Look at nodes connected by an edge to the best untried node in graph]\n",
        "            # diff_bool.shape is (M, k+1, num_explored), where M is the number of active searches\n",
        "            diff_bool = (\n",
        "                candidate_idx[is_active].unsqueeze(2) - explored[is_active].unsqueeze(1)\n",
        "                == 0\n",
        "            )\n",
        "            in_explored = torch.any(diff_bool, dim=2)\n",
        "            # batch_active is true for those who haven't been fully explored in the current batch\n",
        "            batch_active = ~torch.all(in_explored[:, :-1], dim=1)\n",
        "\n",
        "            # Update is_active mask. If none are active, break search\n",
        "            is_active[is_active.clone()] = batch_active\n",
        "            if not is_active.any():\n",
        "                break\n",
        "\n",
        "            # first_unexplored has indices of first unexplored element per row\n",
        "            first_unexplored = torch.max(~in_explored[batch_active], dim=1)[\n",
        "                1\n",
        "            ].unsqueeze(1)\n",
        "            # Unexplored nodes to be expanded\n",
        "            unexplored_idx = torch.gather(\n",
        "                candidate_idx[is_active], dim=1, index=first_unexplored\n",
        "            ).squeeze(-1)\n",
        "            explored[is_active, (count % num_explored)] = unexplored_idx\n",
        "\n",
        "            # [3. Add all these nodes to our potential candidate pool]\n",
        "            # Add neighbors of the first unexplored point to the list of candidates\n",
        "            expanded_idx = torch.cat(\n",
        "                (self.graph[unexplored_idx], candidate_idx[is_active]), dim=1\n",
        "            )\n",
        "\n",
        "            # We remove repeated indices from consideration by adding float('inf') to them.\n",
        "            expanded_idx = torch.sort(expanded_idx)[0]\n",
        "            temp = torch.full((len(expanded_idx), 1), -1)\n",
        "\n",
        "            if self.init_method == \"cluster\":\n",
        "                expanded_idx = expanded_idx.to(self.device)\n",
        "                temp = temp.to(self.device)\n",
        "\n",
        "            shift = torch.cat(\n",
        "                (\n",
        "                    temp,\n",
        "                    torch.sort(expanded_idx, dim=1)[0][:, :-1],\n",
        "                ),\n",
        "                dim=1,\n",
        "            )\n",
        "            unwanted_indices = expanded_idx == shift\n",
        "\n",
        "            # [4. Sort by closeness].\n",
        "            distances = self.distance(\n",
        "                self.data[expanded_idx], X[is_active].unsqueeze(1)\n",
        "            )\n",
        "            # distances = ((self.data[expanded_idx] - X[is_active].unsqueeze(1))**2).sum(-1)\n",
        "            distances[unwanted_indices] += float(\"inf\")\n",
        "            sorted, idx = torch.sort(distances, dim=1)\n",
        "            expanded_idx = torch.gather(expanded_idx, dim=1, index=idx)\n",
        "\n",
        "            # [5. Truncate to k+1 best]\n",
        "            candidate_idx[is_active] = expanded_idx[:, : (k + 1)]\n",
        "\n",
        "            # [6. Return to step 2. If we have already tried all candidates in pool, we stop in the if not unexplored]\n",
        "            count += 1\n",
        "\n",
        "        # Return the k candidates\n",
        "        if verbose:\n",
        "            print(f\"Graph search finished after {count} steps. Finished for: {(1 - torch.mean(1.0 * is_active).item()) * 100}%.\")\n",
        "\n",
        "        if self.init_method == \"cluster\":\n",
        "            return self.final_brute_force(candidate_idx[:, : self.k], X, verbose=verbose)\n",
        "        else:\n",
        "            return candidate_idx[:, : self.k]\n",
        "\n",
        "    def _calculate_all_distances(self):\n",
        "        \"\"\"Updates the distances (self.k_distances) of the edges found in self.graph.\"\"\"\n",
        "        # Uses loop for simplicity.\n",
        "        for i, row in enumerate(self.graph):\n",
        "            # Indices of current k neighbors in self.graph\n",
        "            neighbor_indices = [(i, int(r)) for r in row]\n",
        "            # The distances of those neighbors are saved in k_distances\n",
        "            self.k_distances[i] = torch.Tensor(\n",
        "                [self.distance(self.data[a], self.data[b]) for a, b in neighbor_indices]\n",
        "            )\n",
        "            # Add pairs to explored_edges set\n",
        "            self.explored_edges.update(neighbor_indices)\n",
        "\n",
        "    def _initialize_graph_randomly(self):\n",
        "        \"\"\"Initializes self.graph with random values such that each point has 'queue' distinct neighbors\"\"\"\n",
        "        N, k = self.graph.shape\n",
        "        # Initialize graph randomly, removing self-loops\n",
        "        self.graph = torch.randint(high=N - 1, size=[N, k], dtype=torch.long)\n",
        "        row_indices = torch.arange(N).unsqueeze(1).repeat(1, k)\n",
        "        self.graph[self.graph >= row_indices] += 1\n",
        "\n",
        "    def _initialize_graph_big_random(self, data, numtrees):\n",
        "        \"\"\"Initializes self.graph randomly, but with more neighbours at the start\"\"\"\n",
        "        N, k = self.graph.shape\n",
        "        temp_graph = torch.tensor([])\n",
        "\n",
        "        # make 'trees', combine into giant graph with each element (row) having k * num_trees neighbours\n",
        "        # this is a small for loop - numtrees and k << datapoints\n",
        "        for j in range(numtrees):\n",
        "            tree_graph = torch.tensor([])\n",
        "            for i in range(k):\n",
        "                tree_graph = torch.cat(\n",
        "                    (tree_graph, torch.randperm(N)), 0\n",
        "                )  # generate randomly shuffled list of N indices\n",
        "            tree_graph = tree_graph.reshape(\n",
        "                -1, k\n",
        "            )  # creates a N x k tensor with N indices, each appearing k times. This represents 1 'tree'\n",
        "            temp_graph = torch.cat(\n",
        "                (temp_graph, tree_graph), 1\n",
        "            )  # combine into giant N x (k*num_trees) tensor. This represents the forest\n",
        "\n",
        "        # find KNN for each row in giant graph\n",
        "        # TODO - implement the below without a for loop\n",
        "        for i, row in enumerate(temp_graph):\n",
        "            temp_row = torch.unique(row).type(torch.LongTensor)  # remove duplicates\n",
        "            temp_row = temp_row[temp_row != i]  # remove self\n",
        "\n",
        "            temp_points = data[temp_row, :]  # pick out elements from dataset\n",
        "            distances = self.distance(temp_points, data[i])  # Euclidean distances\n",
        "            indices = distances.topk(\n",
        "                k=self.queue, largest=False\n",
        "            ).indices  # find indices of KNN\n",
        "            self.graph[i] = temp_row[indices]  # assign KNN to graph\n",
        "\n",
        "    def _initialize_graph_forest(self, data, numtrees, leaf_multiplier, big_leaf_depth):\n",
        "        \"\"\"Initializes self.graph with a forest of random trees, such that each point has 'queue' distinct neighbors\"\"\"\n",
        "        N, k = self.graph.shape\n",
        "        dim = data.shape[1]\n",
        "\n",
        "        temp_graph = torch.tensor(())\n",
        "        for j in range(numtrees):\n",
        "            # Create trees, obtain leaves. RandomProjectionTree class is defined below.\n",
        "            t = RandomProjectionTree(data, k=k * leaf_multiplier, big_leaf_depth=big_leaf_depth)\n",
        "\n",
        "            # Create temporary graph, 1 for each tree\n",
        "            # Leaves are of uneven size; select smallest leaf size as graph size\n",
        "            cols = min([len(leaf) for leaf in t.leaves])\n",
        "            rows = len(t.leaves)\n",
        "            tree_graph = torch.zeros((N, cols))\n",
        "            leaves = torch.tensor(())\n",
        "            idx_update = torch.tensor(())\n",
        "\n",
        "            # Update graph using leaves\n",
        "            for leaf in t.leaves:\n",
        "                temp_idx = torch.as_strided(\n",
        "                    torch.tensor(leaf).repeat(1, 2),\n",
        "                    size=[len(leaf), cols],\n",
        "                    stride=[1, 1],\n",
        "                    storage_offset=1,\n",
        "                )\n",
        "                tree_graph[\n",
        "                    leaf, :\n",
        "                ] = temp_idx.float()  # update graph. a lot of overwriting\n",
        "            # Concatenate all graphs from all trees into 1 giant graph\n",
        "            temp_graph = torch.cat((temp_graph, tree_graph), 1)\n",
        "\n",
        "            # Add the first tree's big_leaves to the NNDescent's big_leaves\n",
        "            if j == 0 and t.big_leaves:\n",
        "                self.big_leaves = torch.LongTensor(t.big_leaves)\n",
        "\n",
        "        warning_count = 0  # number of indices for which some neighbours are random\n",
        "\n",
        "        # find KNN for each row in giant graph\n",
        "        # TODO - implement the below without a for loop\n",
        "        for i, row in enumerate(temp_graph):\n",
        "            temp_row = torch.unique(row).type(torch.LongTensor)  # remove duplicates\n",
        "            temp_row = temp_row[temp_row != i]  # remove self\n",
        "\n",
        "            temp_points = data[temp_row, :]  # pick out elements from dataset\n",
        "            d = self.distance(\n",
        "                data[i].reshape(1, dim).unsqueeze(1), temp_points.unsqueeze(0)\n",
        "            )\n",
        "            distances, indices = torch.sort(d, dim=1)\n",
        "            indices = indices.flatten()[:k]\n",
        "\n",
        "            indices = temp_row[indices]\n",
        "\n",
        "            # pad with random indices if there are not enough neighbours\n",
        "            warning = False  # warning flag\n",
        "            while len(indices) < k:\n",
        "                pad = torch.randint(\n",
        "                    high=N - 1,\n",
        "                    size=[\n",
        "                        k - len(indices),\n",
        "                    ],\n",
        "                    dtype=torch.long,\n",
        "                )\n",
        "                indices = torch.cat((indices, pad))\n",
        "                indices = torch.unique(indices).type(\n",
        "                    torch.LongTensor\n",
        "                )  # remove duplicates\n",
        "                indices = indices[indices != i]  # remove self\n",
        "                warning = True\n",
        "\n",
        "            self.graph[i] = indices  # assign KNN to graph\n",
        "\n",
        "            if warning:\n",
        "                warning_count += 1\n",
        "\n",
        "        if warning_count:\n",
        "            print(f\"WARNING! {warning_count} INDICES ARE RANDOM!\")\n",
        "\n",
        "    def _initialize_graph_clusters(self, data):\n",
        "        \"\"\"Initializes self.graph on cluster centroids, such that each cluster has 'a' distinct neighbors\"\"\"\n",
        "        N, dim = data.shape\n",
        "        k = self.k\n",
        "        a = self.a\n",
        "        backend = self.backend\n",
        "        leaf_multiplier = N / self.num_clusters / k  # to get number of clusters ~ num_clusters\n",
        "        self.clusters = torch.ones( N, ) * -1\n",
        "\n",
        "        data = data.to(self.device)\n",
        "\n",
        "        # Create trees, obtain leaves. RandomProjectionTree class is defined below.\n",
        "        t = RandomProjectionTree(\n",
        "            data, k, self.big_leaf_depth, leaf_multiplier, backend\n",
        "        )  \n",
        "\n",
        "        self.leaves = len(t.leaves)\n",
        "\n",
        "        # Assign each point to a cluster, 1 cluster per tree in forest\n",
        "        for i, leaf in enumerate(t.leaves):\n",
        "            self.clusters[leaf] = i\n",
        "        self.data_orig = self.data.clone()\n",
        "        self.data = t.centroids.clone()\n",
        "\n",
        "        # Find nearest centroids\n",
        "        x_LT = LazyTensor(self.data.unsqueeze(1).to(self.device))\n",
        "        y_LT = LazyTensor(self.data.unsqueeze(0).to(self.device))\n",
        "        d = self.distance(x_LT, y_LT)\n",
        "        indices = d.argKmin(K=a + 1, dim=1).long()\n",
        "        self.centroids_neighbours = indices[:, 1:].long()\n",
        "\n",
        "        self.num_clusters = self.centroids_neighbours.shape[0]\n",
        "        self.graph = self.centroids_neighbours\n",
        "\n",
        "        # Assign big_leaves by searching for the correct cluster\n",
        "        self.big_leaves = torch.LongTensor(t.big_leaves)\n",
        "        for i, index in enumerate(self.big_leaves):\n",
        "            self.big_leaves[i] = self.clusters[index]\n",
        "        return\n",
        "\n",
        "    def final_brute_force(self, nearest_clusters, query_pts, verbose=False):\n",
        "        \"\"\" Final brute force search over clusters in cluster method\"\"\"\n",
        "        if verbose:\n",
        "            print(\"Starting brute force search over clusters.\")\n",
        "        return self._final_brute_force(nearest_clusters, query_pts)\n",
        "\n",
        "    def _final_brute_force(self, nearest_clusters, query_pts):\n",
        "        \"\"\" Final brute force search over clusters in cluster method\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        k = self.k\n",
        "\n",
        "        x = self.data_orig.to(self.device)\n",
        "        x_labels = self.clusters.long()\n",
        "        y = query_pts.to(self.device)\n",
        "        y_labels = nearest_clusters[:, 0]\n",
        "\n",
        "        x = x.contiguous()\n",
        "        y = y.contiguous()\n",
        "        x_labels = x_labels.to(self.device)\n",
        "        y_labels = y_labels.to(self.device)\n",
        "\n",
        "        clusters, a = self.graph.shape\n",
        "        r = torch.arange(clusters).repeat(a, 1).T.reshape(-1).long()\n",
        "        keep = torch.zeros([clusters, clusters], dtype=torch.bool).to(self.device)\n",
        "        keep[r, self.graph.flatten()] = True\n",
        "        keep += torch.eye(clusters).bool().to(self.device)\n",
        "\n",
        "        x_ranges, x_centroids, _ = cluster_ranges_centroids(x, x_labels)\n",
        "        y_ranges, y_centroids, _ = cluster_ranges_centroids(y, y_labels)\n",
        "\n",
        "        x, x_labels = self.__sort_clusters(x, x_labels, store_x=True)\n",
        "        y, y_labels = self.__sort_clusters(y, y_labels, store_x=False)\n",
        "\n",
        "        x_LT = LazyTensor(x.unsqueeze(0).to(self.device).contiguous())\n",
        "        y_LT = LazyTensor(y.unsqueeze(1).to(self.device).contiguous())\n",
        "        D_ij = self.distance(y_LT, x_LT)\n",
        "\n",
        "        x_ranges = x_ranges.to(self.device)\n",
        "        y_ranges = y_ranges.to(self.device)\n",
        "        ranges_ij = from_matrix(y_ranges, x_ranges, keep)\n",
        "        D_ij.ranges = ranges_ij\n",
        "        nn = D_ij.argKmin(K=k, axis=1)\n",
        "        return self.__unsort(nn)\n",
        "\n",
        "    def __sort_clusters(self, x, lab, store_x=True):\n",
        "        lab, perm = torch.sort(lab.view(-1))\n",
        "        if store_x:\n",
        "            self.__x_perm = perm\n",
        "        else:\n",
        "            self.__y_perm = perm\n",
        "        return x[perm], lab\n",
        "\n",
        "    def __unsort(self, nn):\n",
        "        return torch.index_select(self.__x_perm[nn], 0, self.__y_perm.argsort())\n",
        "\n",
        "\n",
        "class RandomProjectionTree: \n",
        "    \"\"\"\n",
        "    Random projection tree class that splits the data evenly per split\n",
        "    Each split is performed by calculating the projection distance of each datapoint to a random unit vector\n",
        "    The datapoints are then split by the median of of these projection distances\n",
        "    The indices of the datapoints are stored in tree.leaves, as a nested list\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x, k=5, big_leaf_depth=5, leaf_multiplier=128, backend=\"torch\", device=None):\n",
        "        self.min_size = k * leaf_multiplier\n",
        "        self.leaves = []\n",
        "        self.sizes = []\n",
        "        if device is None:\n",
        "            self.device = x.device\n",
        "        else:\n",
        "            self.device = device\n",
        "        self.centroids = torch.tensor(()).to(self.device)\n",
        "        self.big_leaf_depth = big_leaf_depth\n",
        "        self.big_leaves = []  # leaves at depth = 5\n",
        "        indices = torch.arange(x.shape[0])\n",
        "\n",
        "        self.dim = x.shape[1]\n",
        "        self.data = x.to(self.device)\n",
        "        self.backend = backend  # Boolean to choose LT or torch initialization\n",
        "\n",
        "        self.tree = self.make_tree(indices, depth=0)\n",
        "        self.centroids = self.centroids.reshape(-1, x.shape[1])\n",
        "\n",
        "    def make_tree(self, indices, depth):\n",
        "        if depth == 5:  # add to big_leaves if depth=5\n",
        "            self.big_leaves.append(int(indices[0]))\n",
        "        if indices.shape[0] > self.min_size:\n",
        "            v = self.choose_rule().to(self.device)\n",
        "\n",
        "            if self.backend == \"keops\":\n",
        "                distances = self.dot_product(\n",
        "                    self.data[indices], v\n",
        "                )  # create list of projection distances\n",
        "            else:\n",
        "                distances = torch.tensordot(\n",
        "                    self.data[indices], v, dims=1\n",
        "                )  # create list of projection distances\n",
        "\n",
        "            median = torch.median(distances)\n",
        "            left_bool = (\n",
        "                distances <= median\n",
        "            )  # create boolean array where entries are true if distance <= median\n",
        "            self.make_tree(indices[left_bool], depth + 1)\n",
        "            self.make_tree(indices[~left_bool], depth + 1)\n",
        "        elif indices.shape[0] != 0:\n",
        "            self.leaves.append(indices.tolist())\n",
        "            self.sizes.append(indices.shape[0])\n",
        "            centroid = self.data[indices].mean(dim=0)  # get centroid position\n",
        "            self.centroids = torch.cat((self.centroids, centroid))\n",
        "        return\n",
        "\n",
        "    def choose_rule(self):\n",
        "        v = torch.rand(self.dim)  # create random vector\n",
        "        v /= torch.norm(v)  # normalize to unit vector\n",
        "        return v\n",
        "\n",
        "    def dot_product(self, x, v):\n",
        "        # Calculate dot product between matrix x and vector v using LazyTensors\n",
        "        v_LT = LazyTensor(v.view(1, 1, -1))\n",
        "        x_LT = LazyTensor(x.unsqueeze(0))\n",
        "        return (v_LT | x_LT).sum_reduction(axis=0).flatten()\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmBCQvk6hDtg"
      },
      "source": [
        "\n",
        "def accuracy(indices_test, indices_truth):\n",
        "  '''\n",
        "  Compares the test and ground truth indices (rows = KNN for each point in dataset)\n",
        "  Returns accuracy: proportion of correct nearest neighbours\n",
        "  '''\n",
        "  N, k = indices_test.shape\n",
        "  \n",
        "  # Calculate number of correct nearest neighbours\n",
        "  accuracy = 0\n",
        "  for i in range(k):\n",
        "    accuracy += torch.sum(indices_test == indices_truth).float()/N\n",
        "    indices_truth = torch.roll(indices_truth, 1, -1) # Create a rolling window (index positions may not match)\n",
        "  accuracy = float(accuracy/k) # percentage accuracy\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jVi2L9Wi0vL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5a2d9a-0cd7-4fe0-f719-e9de90c2c853"
      },
      "source": [
        "# Parameters\n",
        "N, d = 1000000, 3\n",
        "data = torch.randn(size=[N,d]).to(torch.device('cuda'))\n",
        "queue = 10 # Queue determines the search graph's connectivity.\n",
        "k = 5 # To find k neighbors\n",
        "a = 10 # This is used in the \"cluster\" method.\n",
        "n = NNDescent(k=k, backend=\"torch\", metric=\"euclidean\",initialization_method=\"cluster\")\n",
        "n.fit(data, a=a, clusters=528, queue=queue, verbose=True)\n",
        "print(\"N graph shape:\", n.graph.shape)\n",
        "\n",
        "# Query set\n",
        "X = torch.randn(size=[100000,data.shape[1]]).to(torch.device('cuda'))\n",
        "\n",
        "print(\"Search with NNDescent:\")\n",
        "start = time.time()\n",
        "answer_forest = n.kneighbors(X, max_num_steps=30, verbose=True)\n",
        "print(\"Took\", time.time()-start,\"seconds.\")\n",
        "print(\"Answer shape:\", answer_forest.shape)\n",
        "\n",
        "print(\"Let's do brute force for comparison\")\n",
        "start = time.time()\n",
        "x_LT=LazyTensor(data.unsqueeze(0))#.to(device))\n",
        "y_LT=LazyTensor(X.unsqueeze(1))#.to(device))\n",
        "d=n.distance(x_LT,y_LT)\n",
        "brute_force = d.argKmin(K=k,dim=1).long()\n",
        "print(\"Brute force took\", time.time()-start,\"seconds.\\n\")\n",
        "\n",
        "print(\"Comparing (naively) the accuracy\")\n",
        "print(\"Forest:\",accuracy(brute_force,answer_forest[:,:k]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N graph shape: torch.Size([1024, 10])\n",
            "Search with NNDescent:\n",
            "Step 0 - Search is completed for 0.0 - this step took 0.00015926361083984375 s\n",
            "Step 1 - Search is completed for 0.0 - this step took 0.01837754249572754 s\n",
            "Step 2 - Search is completed for 0.0 - this step took 0.019230127334594727 s\n",
            "Step 3 - Search is completed for 0.0 - this step took 0.01862049102783203 s\n",
            "Step 4 - Search is completed for 0.0 - this step took 0.018892765045166016 s\n",
            "Step 5 - Search is completed for 0.0 - this step took 0.018719911575317383 s\n",
            "Step 6 - Search is completed for 0.0 - this step took 0.018793821334838867 s\n",
            "Step 7 - Search is completed for 0.0 - this step took 0.018805503845214844 s\n",
            "Step 8 - Search is completed for 0.0 - this step took 0.015559673309326172 s\n",
            "Step 9 - Search is completed for 0.0 - this step took 0.013371706008911133 s\n",
            "Step 10 - Search is completed for 0.0 - this step took 0.013330698013305664 s\n",
            "Step 11 - Search is completed for 0.26986002922058105 - this step took 0.011777877807617188 s\n",
            "Step 12 - Search is completed for 0.7236000001430511 - this step took 0.006307125091552734 s\n",
            "Step 13 - Search is completed for 0.9322400018572807 - this step took 0.0029778480529785156 s\n",
            "Step 14 - Search is completed for 0.9868200002238154 - this step took 0.004194974899291992 s\n",
            "Step 15 - Search is completed for 0.9961800000164658 - this step took 0.001827239990234375 s\n",
            "Step 16 - Search is completed for 0.9982300000265241 - this step took 0.0017931461334228516 s\n",
            "Step 17 - Search is completed for 0.9990300000063144 - this step took 0.0017786026000976562 s\n",
            "Step 18 - Search is completed for 0.9994700000388548 - this step took 0.0017366409301757812 s\n",
            "Step 19 - Search is completed for 0.9996800000080839 - this step took 0.0016961097717285156 s\n",
            "Step 20 - Search is completed for 0.9997900000016671 - this step took 0.0017354488372802734 s\n",
            "Step 21 - Search is completed for 0.9998900000064168 - this step took 0.0016906261444091797 s\n",
            "Step 22 - Search is completed for 0.9999600000010105 - this step took 0.00171661376953125 s\n",
            "Graph search finished after 22 steps. Finished for: 100.0%.\n",
            "Starting brute force search over clusters.\n",
            "Took 0.26961421966552734 seconds.\n",
            "Answer shape: torch.Size([100000, 5])\n",
            "Let's do brute force for comparison\n",
            "Brute force took 0.47512269020080566 seconds.\n",
            "\n",
            "Comparing (naively) the accuracy\n",
            "Forest: 0.8309219479560852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dekNcr18rjkY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}