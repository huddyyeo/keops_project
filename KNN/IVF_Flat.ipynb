{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IVF-Flat.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_KYgrAPQNiR",
        "outputId": "32cb1c7b-20d0-4b8f-d562-854e10ae45cb"
      },
      "source": [
        "!pip install sphinx\n",
        "!pip install pykeops[full] > install.log\n",
        "import pykeops\n",
        "pykeops.clean_pykeops()\n",
        "import time\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from pykeops.torch import LazyTensor\n",
        "import numpy as np\n",
        "from pykeops.torch.cluster import cluster_ranges_centroids\n",
        "from pykeops.torch.cluster import sort_clusters\n",
        "from pykeops.torch.cluster import from_matrix\n",
        "use_cuda = torch.cuda.is_available()\n",
        "dtype = torch.float32 if use_cuda else torch.float64\n",
        "if use_cuda:\n",
        "    torch.cuda.synchronize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (1.8.5)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.0.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.15.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.6.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx) (0.7.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from sphinx) (51.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx) (20.8)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.11.2)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx) (0.16)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.9.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.2.4)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->sphinx) (2018.9)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->sphinx) (1.1.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (2.10)\n",
            "Cleaning /root/.cache/pykeops-1.4.2-cpython-36/...\n",
            "    - /root/.cache/pykeops-1.4.2-cpython-36/libKeOpstorch1c124fa0f1.cpython-36m-x86_64-linux-gnu.so has been removed.\n",
            "    - /root/.cache/pykeops-1.4.2-cpython-36/libKeOpstorch52de9bd20c.so has been removed.\n",
            "    - /root/.cache/pykeops-1.4.2-cpython-36/keops_hash.log has been removed.\n",
            "    - /root/.cache/pykeops-1.4.2-cpython-36/libKeOpstorch5fba8c75d5.so has been removed.\n",
            "    - /root/.cache/pykeops-1.4.2-cpython-36/libKeOpstorch5fba8c75d5.cpython-36m-x86_64-linux-gnu.so has been removed.\n",
            "    - /root/.cache/pykeops-1.4.2-cpython-36/libKeOpstorch52de9bd20c.cpython-36m-x86_64-linux-gnu.so has been removed.\n",
            "    - /root/.cache/pykeops-1.4.2-cpython-36/libKeOpstorch1c124fa0f1.so has been removed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HNr9MReQVNM"
      },
      "source": [
        "def KMeans(x, K=10, Niter=15, verbose=False):\n",
        "    \"\"\"Implements Lloyd's algorithm for the Euclidean metric.\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    N, D = x.shape  # Number of samples, dimension of the ambient space\n",
        "\n",
        "    c = x[:K, :].clone()  # Simplistic initialization for the centroids\n",
        "\n",
        "    x_i = LazyTensor(x.view(N, 1, D))  # (N, 1, D) samples\n",
        "    c_j = LazyTensor(c.view(1, K, D))  # (1, K, D) centroids\n",
        "\n",
        "    # K-means loop:\n",
        "    # - x  is the (N, D) point cloud,\n",
        "    # - cl is the (N,) vector of class labels\n",
        "    # - c  is the (K, D) cloud of cluster centroids\n",
        "    for i in range(Niter):\n",
        "\n",
        "        # E step: assign points to the closest cluster -------------------------\n",
        "        D_ij = ((x_i - c_j) ** 2).sum(-1)  # (N, K) symbolic squared distances\n",
        "        cl = D_ij.argmin(dim=1).long().view(-1)  # Points -> Nearest cluster\n",
        "\n",
        "        # M step: update the centroids to the normalized cluster average: ------\n",
        "        # Compute the sum of points per cluster:\n",
        "        c.zero_() #sets c to 0\n",
        "        #scatter_add_(dim,index,src) \n",
        "        #https://pytorch-scatter.readthedocs.io/en/1.3.0/functions/add.html\n",
        "        #adds elements of a source by allocating using a indexing vector\n",
        "        c.scatter_add_(0, cl[:, None].repeat(1, D), x) #[50,2], obtains the sum of all values that are in the same cluster\n",
        "        #repeat basically duplicates the whole vector once and concatenates to itself\n",
        "\n",
        "        # Divide by the number of points per cluster:\n",
        "        Ncl = torch.bincount(cl, minlength=K).type_as(c).view(K, 1)#bincount gives number of bins per cluster\n",
        "        c /= Ncl  # in-place division to compute the average\n",
        "\n",
        "    if verbose:  # Fancy display -----------------------------------------------\n",
        "        if use_cuda:\n",
        "            torch.cuda.synchronize()\n",
        "        end = time.time()\n",
        "        print(\n",
        "            f\"K-means for the Euclidean metric with {N:,} points in dimension {D:,}, K = {K:,}:\"\n",
        "        )\n",
        "        print(\n",
        "            \"Timing for {} iterations: {:.5f}s = {} x {:.5f}s\\n\".format(\n",
        "                Niter, end - start, Niter, (end - start) / Niter\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return cl, c\n",
        "\n",
        "def k_argmin(x,y,k=5):\n",
        "  x_LT=LazyTensor(x.unsqueeze(1))\n",
        "  y_LT=LazyTensor(y.unsqueeze(0))\n",
        "  d=((x_LT-y_LT)**2).sum(-1)\n",
        "  return d.argmin(dim=1).long().view(-1)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57N-Y6ftGnbB"
      },
      "source": [
        "N, D, K = 10000, 2, 50\n",
        "x = 0.7 * torch.randn(N, D, dtype=dtype) + 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnfZAIpUQYAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05651a7-22d4-4b20-9b90-5367d8aaeded"
      },
      "source": [
        "#start of the algorithm\n",
        "if use_cuda:\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "#c = x[:K, :].clone()\n",
        "cl, c = KMeans(x, K)\n",
        "cl=k_argmin(x,c) #updating to correct assignment\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling libKeOpstorch5fba8c75d5 in /root/.cache/pykeops-1.4.2-cpython-36:\n",
            "       formula: ArgMin_Reduction(Sum(Square((Var(0,2,0) - Var(1,2,1)))),0)\n",
            "       aliases: Var(0,2,0); Var(1,2,1); \n",
            "       dtype  : float32\n",
            "... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEiq0bVCZUuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9263481-0b01-4ab2-c62b-26a22d5eeac9"
      },
      "source": [
        "if use_cuda:\n",
        "    torch.cuda.synchronize()\n",
        "c1=LazyTensor(c.unsqueeze(1)) #c cluster position\n",
        "c2=LazyTensor(c.unsqueeze(0))\n",
        "d=((c1-c2)** 2).sum(-1)\n",
        "#d[a,b]=dist from c[a] to c[b]\n",
        "ncl=d.argKmin(K=5,dim=1) #top 5 nearest clusters\n",
        "x_ranges, x_centroids, _ = cluster_ranges_centroids(x, cl)\n",
        "\n",
        "x, x_labels = sort_clusters(x,cl)\n",
        "x_LT=LazyTensor(x.unsqueeze(1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling libKeOpstorch52de9bd20c in /root/.cache/pykeops-1.4.2-cpython-36:\n",
            "       formula: ArgKMin_Reduction(Sum(Square((Var(0,2,0) - Var(1,2,1)))),5,0)\n",
            "       aliases: Var(0,2,0); Var(1,2,1); \n",
            "       dtype  : float32\n",
            "... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfdriOHEGQyO"
      },
      "source": [
        "#creating mask\n",
        "r=torch.arange(50).repeat(5,1).T.reshape(-1).long()\n",
        "keep= torch.zeros([K,K], dtype=torch.bool)          \n",
        "keep[r,ncl.view(-1)]=True                           \n",
        "#K=50, 50 x 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjE8z6NP04rV"
      },
      "source": [
        "y = 0.7 * torch.randn(N, D, dtype=dtype) + 0.3\n",
        "if use_cuda:\n",
        "    torch.cuda.synchronize()\n",
        "y_labels=k_argmin(y,c)# 0 3 10 38 ...\n",
        "y_ranges, y_centroids, _ = cluster_ranges_centroids(y, y_labels)\n",
        "if use_cuda:\n",
        "    torch.cuda.synchronize()\n",
        "y, y_labels = sort_clusters(y, y_labels)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaF7j4Xc6GNh"
      },
      "source": [
        "if use_cuda:\n",
        "    torch.cuda.synchronize()\n",
        "ranges_ij = from_matrix(x_ranges, y_ranges, keep)\n",
        "\n",
        "y_LT=LazyTensor(y.unsqueeze(0))\n",
        "D_ij=((y_LT-x_LT)**2).sum(-1)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-XMYUHAUbbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0212439-2166-4e88-b9d3-7dfae9f8bd31"
      },
      "source": [
        "#warmup\n",
        "D_ij=((y_LT-x_LT)**2).sum(-1)    \n",
        "D_ij.argKmin(K=5,axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling libKeOpstorch1c124fa0f1 in /root/.cache/pykeops-1.4.2-cpython-36:\n",
            "       formula: ArgKMin_Reduction(Sum(Square((Var(0,2,1) - Var(1,2,0)))),5,0)\n",
            "       aliases: Var(0,2,1); Var(1,2,0); \n",
            "       dtype  : float32\n",
            "... Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 291,  298,  240,  293,  274],\n",
              "        [ 268,  109,  280,    3,   96],\n",
              "        [ 211,   53,  137,  196,  215],\n",
              "        ...,\n",
              "        [9872, 9880, 9953, 9878, 9944],\n",
              "        [9925, 9895, 9888, 9913, 9962],\n",
              "        [9927, 9902, 9864, 9904, 9861]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVJHdfSHD6Xk",
        "outputId": "00f8905e-07bd-4b30-c628-69afd913a26c"
      },
      "source": [
        "#actual timing\n",
        "brute_force_times=[]\n",
        "for _ in range(10):\n",
        "  start=time.time()\n",
        "  D_ij=((y_LT-x_LT)**2).sum(-1)    \n",
        "  a=D_ij.argKmin(K=5,axis=1)\n",
        "  brute_force_times.append(time.time()-start)\n",
        "\n",
        "print('Time taken for brute force search:',np.mean(brute_force_times))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken for brute force search: 0.003003859519958496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxevyLXTEER0",
        "outputId": "d8cda612-f38e-4426-cd23-a0af8002ede9"
      },
      "source": [
        "#testing with reduction\n",
        "if use_cuda:\n",
        "    torch.cuda.synchronize()\n",
        "reduced_times=[]\n",
        "for _ in range(10):\n",
        "  start=time.time()\n",
        "  D_ij=((y_LT-x_LT)**2).sum(-1)  \n",
        "  D_ij.ranges=ranges_ij\n",
        "  a_sparse=D_ij.argKmin(K=5,axis=1)\n",
        "  reduced_times.append(time.time()-start)\n",
        "print('Time taken with sparse reduction:',np.mean(reduced_times))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken with sparse reduction: 0.0015053033828735351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG7ABEgcYOA9",
        "outputId": "b7e31c7e-6fcd-4582-eda9-0aa2850dc9b8"
      },
      "source": [
        "reduction=np.mean(reduced_times)/np.mean(brute_force_times)\n",
        "print('Reduction in time taken:',1-reduction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reduction in time taken: 0.4988769039058346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHFYebwvE07K",
        "outputId": "2b43d556-b133-4a7c-b7a9-2e58f03643f5"
      },
      "source": [
        "accuracy=len(torch.nonzero((a==a_sparse).view(-1)))/(N*5)\n",
        "print(\"Accuracy:\",accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.98172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE19P_5np38y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c4d7f6-66fc-4e17-ed93-0782fbb0e439"
      },
      "source": [
        "#actual from argmin\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 291,  298,  240,  293,  274],\n",
              "        [ 268,  109,  280,    3,   96],\n",
              "        [ 211,   53,  137,  196,  215],\n",
              "        ...,\n",
              "        [9872, 9880, 9953, 9878, 9944],\n",
              "        [9925, 9895, 9888, 9913, 9962],\n",
              "        [9927, 9902, 9864, 9904, 9861]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iecQkGEHSLP",
        "outputId": "1edcdb21-b892-4a0d-a446-57e868fef704"
      },
      "source": [
        "#with reduction from block sparsity \n",
        "a_sparse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 291,  298,  240,  293,  274],\n",
              "        [ 268,  109,  280,    3,   96],\n",
              "        [ 211,   53,  137,  196,  215],\n",
              "        ...,\n",
              "        [9872, 9880, 9953, 9878, 9944],\n",
              "        [9925, 9895, 9888, 9913, 9962],\n",
              "        [9927, 9902, 9864, 9904, 9861]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}