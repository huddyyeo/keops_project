{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nystrom_master_code.ipynb","provenance":[{"file_id":"1VAfNUmXg4KHcHsyWIVTj2JXuBVl72MZ1","timestamp":1611597537215}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"sWuFPkopIETu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612033114709,"user_tz":-120,"elapsed":16734,"user":{"displayName":"Yaniel Cabrera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnuKAiqQmMSKvIwoiQyk5G_g5QALh-semcxgjuQ6o=s64","userId":"16420725285670537399"}},"outputId":"bb555387-e5e4-471a-907c-00cf7893ef0b"},"source":["!pip install pykeops[full] > log.log\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: breathe 4.26.1 has requirement Sphinx<3.5,>=3.0, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O0FOh2d-0RH1"},"source":["# Nystrom implementation"]},{"cell_type":"code","metadata":{"id":"ocj9Fw-MOigF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612033120738,"user_tz":-120,"elapsed":2390,"user":{"displayName":"Yaniel Cabrera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnuKAiqQmMSKvIwoiQyk5G_g5QALh-semcxgjuQ6o=s64","userId":"16420725285670537399"}},"outputId":"891550c8-e77d-44ec-9fe5-1042aa8a418d"},"source":["import numpy as np\r\n","import torch\r\n","from sklearn.utils import check_random_state, as_float_array\r\n","from scipy.linalg import svd\r\n","from pykeops.torch import LazyTensor\r\n","from pykeops.numpy import LazyTensor as LazyTensor_n\r\n","from sklearn.kernel_approximation import Nystroem\r\n","from scipy.sparse.linalg import aslinearoperator, eigsh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[pyKeOps]: Warning, cuda was detected, but driver API could not be initialized. Switching to cpu only.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UrWsCEutqEDM"},"source":["##############################################################################\n","\n","'''\n","The two classes below implement the Nystrom algorithm. One can transform\n","the data into the approximated feature-space and/or obtain the approximated \n","kernel.\n","\n","Example of usage:\n","\n","Let x be a numpy array of shape =  (length, features), then \n","\n","NN = Nystrom_N(n_components=100 ,kernel='rbf', gamma=1.) # creates an instance\n","NN.fit(X)  # fits to data         \n","X_new_i = NN.transform(X)  # transform data to approximated features\n","K_approx = NN.K_approx(X)  # obtain approximated kernel\n","\n","'''\n","\n","class Nystrom_N:\n","    '''\n","        This class implements Nystrom on numpy arrays.\n","    \n","        * The fit method computes K^{-1}_q.\n","\n","        * The transform method maps the data into the feature space underlying\n","        the Nystrom-approximated kernel.\n","\n","        * The method K_approx directly computes the Nystrom approximation.\n","\n","        Parameters:\n","\n","        n_components [int] = how many samples to select from data.\n","        kernel [str] = type of kernel to use. Current options = {linear, rbf}.\n","        gamma [float] = exponential constant for the RBF kernel. \n","        random_state=[None, float] = to set a random seed for the random\n","                                     sampling of the samples. To be used when \n","                                     reproducibility is needed.\n","\n","    '''\n","  \n","    def __init__(self, n_components=100, kernel='linear', gamma:float = 1., \n","                 random_state=None): \n","\n","        self.n_components = n_components\n","        self.kernel = kernel\n","        self.random_state = random_state\n","        self.gamma = gamma\n","\n","\n","    def fit(self, X:np.array):\n","        ''' \n","        Args:   X = data array with (n_samples, n_features)\n","\n","        Returns: Fitted instance of the class\n","        '''\n","\n","        # Basic checks\n","        assert type(X) == np.ndarray, 'Input to fit(.) must be an array.'\n","        assert X.shape[0] >= self.n_components, f'The application needs X.shape[0] >= n_components.'\n","\n","        # Number of samples\n","        n_samples = X.shape[0]\n","        # Define basis\n","        rnd = check_random_state(self.random_state)\n","        inds = rnd.permutation(n_samples)\n","        basis_inds = inds[:self.n_components]\n","        basis = X[basis_inds]\n","        # Build smaller kernel\n","        basis_kernel = self._pairwise_kernels(basis, kernel = self.kernel)  \n","        # Get SVD\n","        U, S, V = svd(basis_kernel)\n","        S = np.maximum(S, 1e-12)\n","        self.normalization_ = np.dot(U / np.sqrt(S), V)\n","        self.components_ = basis\n","        self.component_indices_ = inds\n","        return self\n","\n","\n","    def _pairwise_kernels(self, x:np.array, y:np.array = None, kernel='linear',\n","                          gamma = 1.) -> np.array:\n","        '''Helper function to build kernel\n","        \n","        Args:   X = numpy array of dimension 2.\n","                kernel = type of Kernel to return\n","        '''\n","        \n","        if y is None:\n","            y = x\n","        if kernel == 'linear':\n","            K = x @ y.T \n","        elif kernel == 'rbf':\n","            K =  ( (x[:,None,:] - y[None,:,:])**2 ).sum(-1)\n","            K = np.exp(- gamma* K)\n","  \n","        return K\n","\n","    def transform(self, x:np.array) -> np.array:\n","        ''' Applies transform on the data.\n","        \n","        Args:\n","            x [np.array] = data to transform\n","        Returns\n","            x_new [np.array] = data after transformation\n","        '''\n","        K_nq = self._pairwise_kernels(x, self.components_, self.kernel)\n","        x_new = K_nq @ self.normalization_.T\n","\n","        return x_new\n","\n","    \n","    def K_approx(self, x:np.array) -> np.array:\n","        ''' Function to return Nystrom approximation to the kernel.\n","        \n","        Args:\n","            X[np.array] = data used in fit(.) function.\n","        Returns\n","            K[np.array] = Nystrom approximation to kernel'''\n","        \n","        K_nq = self._pairwise_kernels(x, self.components_, self.kernel)\n","        K_approx = K_nq @ self.normalization_ @ K_nq.T\n","\n","        return K_approx\n","\n","\n","\n","\n","##########################################################################\n","\n","# Same as LazyNystrom_N but written with Pytorch\n","\n","class LazyNystrom_T:\n","    '''\n","        Class to implement Nystrom on torch LazyTensors.\n","        This class works as an interface between lazy tensors and \n","        the Nystrom algorithm in NumPy.\n","\n","        * The fit method computes K^{-1}_q.\n","\n","        * The transform method maps the data into the feature space underlying\n","        the Nystrom-approximated kernel.\n","\n","        * The method K_approx directly computes the Nystrom approximation.\n","\n","        Parameters:\n","\n","        n_components [int] = how many samples to select from data.\n","        kernel [str] = type of kernel to use. Current options = {linear, rbf}.\n","        gamma [float] = exponential constant for the RBF kernel. \n","        random_state=[None, float] = to set a random seed for the random\n","                                     sampling of the samples. To be used when \n","                                     reproducibility is needed.\n","\n","    '''\n","  \n","    def __init__(self, n_components=100, kernel='linear',  gamma:float = 1., \n","                 random_state=None ):\n","        \n","        self.n_components = n_components\n","        self.kernel = kernel\n","        self.random_state = random_state\n","        self.gamma = gamma\n","\n","\n","    def fit(self, X:LazyTensor):\n","        ''' \n","        Args:   X = torch lazy tensor with features of shape \n","                (1, n_samples, n_features)\n","\n","        Returns: Fitted instance of the class\n","        '''\n","\n","        # Basic checks: we have a lazy tensor and n_components isn't too large\n","        assert type(X) == LazyTensor, 'Input to fit(.) must be a LazyTensor.'\n","        assert X.shape[1] >= self.n_components, f'The application needs X.shape[1] >= n_components.'\n","\n","        X = X.sum(dim=0) \n","        # Number of samples\n","        n_samples = X.size(0)\n","        # Define basis\n","        rnd = check_random_state(self.random_state)\n","        inds = rnd.permutation(n_samples)\n","        basis_inds = inds[:self.n_components]\n","        basis = X[basis_inds]\n","        # Build smaller kernel\n","        basis_kernel = self._pairwise_kernels(basis, kernel = self.kernel)  \n","        # Get SVD\n","        U, S, V = torch.svd(basis_kernel)\n","        S = torch.maximum(S, torch.ones(S.size()) * 1e-12)\n","        self.normalization_ = torch.mm(U / np.sqrt(S), V.t())\n","        self.components_ = basis\n","        self.component_indices_ = inds\n","        \n","        return self\n","\n","\n","    def _pairwise_kernels(self, x:torch.tensor, y:torch.tensor = None, kernel='linear',\n","                          gamma = 1.) -> torch.tensor:\n","        '''Helper function to build kernel\n","        \n","        Args:   X = torch tensor of dimension 2.\n","                K_type = type of Kernel to return\n","        '''\n","        \n","        if y is None:\n","            y = x\n","        if kernel == 'linear':\n","            K = x @ y.T\n","        elif kernel == 'rbf':\n","            K =  ( (x[:,None,:] - y[None,:,:])**2 ).sum(-1)\n","            K = torch.exp(- gamma * K )\n","\n","        return K\n","\n","    def transform(self, X:LazyTensor) -> LazyTensor:\n","        ''' Applies transform on the data.\n","        \n","        Args:\n","            X [LazyTensor] = data to transform\n","        Returns\n","            X [LazyTensor] = data after transformation\n","        '''\n","        \n","        X = X.sum(dim=0)\n","        K_nq = self._pairwise_kernels(X, self.components_, self.kernel)\n","        return LazyTensor((K_nq @ self.normalization_.t())[None,:,:])\n","\n","    \n","    def K_approx(self, X:LazyTensor) -> LazyTensor:\n","        ''' Function to return Nystrom approximation to the kernel.\n","        \n","        Args:\n","            X[LazyTensor] = data used in fit(.) function.\n","        Returns\n","            K[LazyTensor] = Nystrom approximation to kernel'''\n","        \n","        X = X.sum(dim=0)\n","        K_nq = self._pairwise_kernels(X, self.components_, self.kernel)\n","        K_approx = K_nq @ self.normalization_ @ K_nq.t()\n","        return LazyTensor(K_approx[None,:,:])\n","\n","\n","\n","\n","################################################################################\n","\n","class Nystrom_NK:\n","    '''\n","        Class to implement Nystrom using numpy and PyKeops.\n","\n","        * The fit method computes K^{-1}_q.\n","\n","        * The transform method maps the data into the feature space underlying\n","        the Nystrom-approximated kernel.\n","\n","        * The method K_approx directly computes the Nystrom approximation.\n","\n","        Parameters:\n","\n","        n_components [int] = how many samples to select from data.\n","        kernel [str] = type of kernel to use. Current options = {rbf}.\n","        gamma [float] = exponential constant for the RBF kernel. \n","        random_state=[None, float] = to set a random seed for the random\n","                                     sampling of the samples. To be used when \n","                                     reproducibility is needed.\n","\n","    '''\n","  \n","    def __init__(self, n_components=100, kernel='rbf', gamma:float = 1., \n","                 random_state=None): \n","\n","        self.n_components = n_components\n","        self.kernel = kernel\n","        self.random_state = random_state\n","        self.gamma = gamma\n","\n","\n","    def fit(self, x:np.ndarray):\n","        ''' \n","        Args:   x = numpy array of shape (n_samples, n_features)\n","\n","        Returns: Fitted instance of the class\n","\n","        '''\n","\n","        # Basic checks\n","        assert type(x) == np.ndarray, 'Input to fit(.) must be an array.'\n","        assert x.shape[0] >= self.n_components, f'The application needs X.shape[0] >= n_components.'\n","\n","        # Number of samples\n","        n_samples = x.shape[0]\n","        # Define basis\n","        rnd = check_random_state(self.random_state)\n","        inds = rnd.permutation(n_samples) \n","        basis_inds = inds[:self.n_components] \n","        basis = x[basis_inds]\n","        # Build smaller kernel\n","        basis_kernel = self._pairwise_kernels(basis, kernel = self.kernel)  \n","        # Spectral decomposition\n","        S, U = self._spectral(basis_kernel)\n","        S = np.maximum(S, 1e-12)\n","        self.normalization_ = np.dot(U / np.sqrt(S), U.T)\n","        self.components_ = basis\n","        self.component_indices_ = inds\n","        return self\n","\n","\n","    def _pairwise_kernels(self, x:np.array, y:np.array = None, kernel='rbf',\n","                          gamma = 1.) -> LazyTensor:\n","        '''Helper function to build kernel\n","        \n","        Args:   X = torch tensor of dimension 2,\n","                K_type = type of Kernel to return.\n","\n","        Returns:\n","                K_ij[LazyTensor]\n","        '''\n","        if y is None:\n","            y = x\n","        if kernel == 'linear': \n","            K = x @ y.T \n","        elif kernel == 'rbf':\n","            x *= gamma\n","            x_i, x_j = LazyTensor_n(x[:, None, :]), LazyTensor_n(y[None, :, :])\n","            K_ij = ((-1*(x_i - x_j)**2).sum(2)).exp()\n","            \n","        return K_ij\n","\n","\n","    def _spectral(self, X_i:LazyTensor):\n","        '''\n","        Helper function to compute eigendecomposition of K_q.\n","\n","        Args: X_i[numpy LazyTensor]\n","\n","        Returns S[np.array] eigenvalues,\n","                U[np.array] eigenvectors\n","        '''\n","        K_linear = aslinearoperator(X_i)\n","        k = K_linear.shape[0] - 1\n","        S, U = eigsh(K_linear, k=k, which='LM')\n","        return S, U\n","        \n","\n","    def transform(self, x:np.ndarray) -> LazyTensor:\n","        ''' Applies transform on the data.\n","        \n","        Args:\n","            X [LazyTensor] = data to transform\n","        Returns\n","            X [LazyTensor] = data after transformation\n","        '''\n","        \n","        K_nq = self._pairwise_kernels(x, self.components_, self.kernel)\n","        x_new = K_nq @ self.normalization_.T\n","        return x_new\n","\n","    \n","    def K_approx(self, X:np.array) -> LazyTensor:\n","        ''' Function to return Nystrom approximation to the kernel.\n","        \n","        Args:\n","            X[LazyTensor] = data used in fit(.) function.\n","        Returns\n","            K[LazyTensor] = Nystrom approximation to kernel'''\n","        \n","        K_nq = self._pairwise_kernels(x, self.components_, self.kernel)\n","        K_nq = K_nq @ np.eye(K_nq.shape[1])\n","        K_approx =  K_nq @ self.normalization_  @ K_nq.T\n","        return K_approx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXy6HOCLqWzl"},"source":[""],"execution_count":null,"outputs":[]}]}