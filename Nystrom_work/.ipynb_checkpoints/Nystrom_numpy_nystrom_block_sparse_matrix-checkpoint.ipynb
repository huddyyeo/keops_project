{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sWuFPkopIETu"
   },
   "outputs": [],
   "source": [
    "!pip install pykeops[full] > log.log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0FOh2d-0RH1"
   },
   "source": [
    "# Nystrom implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "ocj9Fw-MOigF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.utils import check_random_state, as_float_array\n",
    "from scipy.linalg import svd\n",
    "from pykeops.torch import LazyTensor\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "import scipy\n",
    "from pykeops.numpy import LazyTensor\n",
    "import pykeops.config\n",
    "from pykeops.numpy.cluster import grid_cluster\n",
    "from pykeops.numpy.cluster import cluster_ranges_centroids\n",
    "from pykeops.numpy.cluster import sort_clusters\n",
    "from pykeops.numpy.cluster import from_matrix\n",
    "\n",
    "dtype = \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "UrWsCEutqEDM"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "\n",
    "class LazyNystrom_N:\n",
    "    '''\n",
    "        Class to implement Nystrom on torch LazyTensors.\n",
    "        This class works as an interface between lazy tensors and \n",
    "        the Nystrom algorithm in NumPy.\n",
    "\n",
    "        * The fit method computes K^{-1}_q.\n",
    "\n",
    "        * The transform method maps the data into the feature space underlying\n",
    "        the Nystrom-approximated kernel.\n",
    "\n",
    "        * The method K_approx directly computes the Nystrom approximation.\n",
    "\n",
    "        Parameters:\n",
    "\n",
    "        n_components [int] = how many samples to select from data.\n",
    "        kernel [str] = type of kernel to use. Current options = {linear, rbf}.\n",
    "        gamma [float] = exponential constant for the RBF kernel. \n",
    "\n",
    "    '''\n",
    "  \n",
    "    def __init__(self, n_components=500, kernel='linear', gamma:float = 1., \n",
    "                 random_state=None): \n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.kernel = kernel\n",
    "        self.random_state = random_state\n",
    "        self.gamma = gamma\n",
    "\n",
    "\n",
    "    def fit(self, X:LazyTensor):\n",
    "        ''' \n",
    "        Args:   X = lazy tensor with features of shape \n",
    "                (1, n_samples, n_features)\n",
    "\n",
    "        Returns: Fitted instance of the class\n",
    "        '''\n",
    "\n",
    "        # Basic checks\n",
    "        assert type(X) == LazyTensor, 'Input to fit(.) must be a LazyTensor.'\n",
    "        assert X.shape[1] >= self.n_components, f'The application needs X.shape[1] >= n_components.'\n",
    "\n",
    "        X = X.sum(dim=0).numpy()\n",
    "        # Number of samples\n",
    "        n_samples = X.shape[0]\n",
    "        # Define basis\n",
    "        rnd = check_random_state(self.random_state)\n",
    "        inds = rnd.permutation(n_samples)\n",
    "        basis_inds = inds[:self.n_components]\n",
    "        basis = X[basis_inds]\n",
    "        # Build smaller kernel\n",
    "        basis_kernel = self._pairwise_kernels(basis, kernel = self.kernel)  \n",
    "        # Get SVD\n",
    "        U, S, V = svd(basis_kernel)\n",
    "        S = np.maximum(S, 1e-12)\n",
    "        self.normalization_ = np.dot(U / np.sqrt(S), V)\n",
    "        self.components_ = basis\n",
    "        self.component_indices_ = inds\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _pairwise_kernels(self, x:np.array, y:np.array = None, kernel='linear',\n",
    "                          gamma = 1., mask=False):\n",
    "        '''Helper function to build kernel\n",
    "        \n",
    "        Args:   X = torch tensor of dimension 2.\n",
    "                K_type = type of Kernel to return\n",
    "        '''\n",
    "        \n",
    "        if y is None:\n",
    "            y = x\n",
    "        if kernel == 'linear':\n",
    "            K = x @ y.T \n",
    "        elif kernel == 'rbf':\n",
    "            K =  ( (x[:,None,:] - y[None,:,:])**2 ).sum(-1)\n",
    "            K = np.exp(- gamma* K)\n",
    "\n",
    "        if mask:\n",
    "            ranges_ij = binary_mask(x,y)\n",
    "            K.ranges = ranges_ij  # block-sparsity pattern\n",
    "  \n",
    "        return K\n",
    "\n",
    "    \n",
    "\n",
    "    def transform(self, X:LazyTensor) -> LazyTensor:\n",
    "        ''' Applies transform on the data.\n",
    "        \n",
    "        Args:\n",
    "            X [LazyTensor] = data to transform\n",
    "        Returns\n",
    "            X [LazyTensor] = data after transformation\n",
    "        '''\n",
    "        \n",
    "        X = X.sum(dim=0)\n",
    "        K_nq = self._pairwise_kernels(X, self.components_, self.kernel)\n",
    "\n",
    "        return LazyTensor((K_nq @ self.normalization_.T)[None,:,:])\n",
    "\n",
    "\n",
    "    def binary_mask(x, y):\n",
    "        eps = 0.05  # Size of our square bins\n",
    "        #perform clustering\n",
    "        x_labels = grid_cluster(x, eps)  # class labels\n",
    "        y_labels = grid_cluster(y, eps)  # class labels\n",
    "        #centroids and memory footpring of each class\n",
    "        self.x_ranges, self.x_centroids, _ = cluster_ranges_centroids(x, x_labels)\n",
    "        self.y_ranges, self.y_centroids, _ = cluster_ranges_centroids(y, y_labels)\n",
    "        #sort so that all clusters are stored contiguously in memory:\n",
    "        x, self.x_labels = sort_clusters(x, x_labels)\n",
    "        y, self.y_labels = sort_clusters(y, y_labels)\n",
    "        # binary mask\n",
    "        sigma = 0.05  # Characteristic length of interaction\n",
    "        # Compute a coarse Boolean mask:\n",
    "        D = np.sum((self.x_centroids[:, None, :] - self.y_centroids[None, :, :]) ** 2, 2)\n",
    "        self.keep = D < (4 * sigma) ** 2\n",
    "        ranges_ij = from_matrix(self.x_ranges, self.y_ranges, self.keep)\n",
    "        return ranges_ij\n",
    "\n",
    "    def plotting(ranges_ij ):\n",
    "        # Find the cluster centroid which is closest to the (.43,.6) point:\n",
    "        dist_target = np.sum(((self.x_centroids - np.array([0.43, 0.6]).astype(dtype)) ** 2), axis=1)\n",
    "        clust_i = np.argmin(dist_target)\n",
    "\n",
    "        if M + N <= 500000:\n",
    "            ranges_i, slices_j, redranges_j = self.ranges_ij[0:3]\n",
    "            start_i, end_i = ranges_i[clust_i]  # Indices of the points that make up our cluster\n",
    "            start, end = (\n",
    "                slices_j[clust_i - 1],\n",
    "                slices_j[clust_i],\n",
    "            )  # Ranges of the cluster's neighbors\n",
    "\n",
    "            keep = self.keep.astype(float)\n",
    "            keep[clust_i] += 2\n",
    "\n",
    "            plt.ion()\n",
    "            plt.matshow(keep)\n",
    "\n",
    "            plt.figure(figsize=(10, 10))\n",
    "\n",
    "            plt.scatter(\n",
    "                x[:, 0],\n",
    "                x[:, 1],\n",
    "                c=self.x_labels,\n",
    "                cmap=plt.cm.Wistia,\n",
    "                s=25 * 500 / len(x),\n",
    "                label=\"Target points\",\n",
    "            )\n",
    "            plt.scatter(\n",
    "                y[:, 0],\n",
    "                y[:, 1],\n",
    "                c=self.y_labels,\n",
    "                cmap=plt.cm.winter,\n",
    "                s=25 * 500 / len(y),\n",
    "                label=\"Source points\",\n",
    "            )\n",
    "\n",
    "            # Target clusters:\n",
    "            for start_j, end_j in redranges_j[start:end]:\n",
    "                plt.scatter(\n",
    "                    y[start_j:end_j, 0], y[start_j:end_j, 1], c=\"magenta\", s=50 * 500 / len(y)\n",
    "                )\n",
    "\n",
    "            # Source cluster:\n",
    "            plt.scatter(\n",
    "                x[start_i:end_i, 0],\n",
    "                x[start_i:end_i, 1],\n",
    "                c=\"cyan\",\n",
    "                s=10,\n",
    "                label=\"Cluster {}\".format(clust_i),\n",
    "            )\n",
    "\n",
    "            plt.scatter(\n",
    "                self.x_centroids[:, 0],\n",
    "                self.x_centroids[:, 1],\n",
    "                c=\"black\",\n",
    "                s=10,\n",
    "                alpha=0.5,\n",
    "                label=\"Cluster centroids\",\n",
    "            )\n",
    "\n",
    "            plt.legend(loc=\"lower right\")\n",
    "\n",
    "            # sphinx_gallery_thumbnail_number = 2\n",
    "            plt.axis(\"equal\")\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.tight_layout()\n",
    "            plt.show(block=True)\n",
    "                \n",
    "\n",
    "    \n",
    "    def K_approx(self, X:LazyTensor) -> LazyTensor:\n",
    "        ''' Function to return Nystrom approximation to the kernel.\n",
    "        \n",
    "        Args:\n",
    "            X[LazyTensor] = data used in fit(.) function.\n",
    "        Returns\n",
    "            K[LazyTensor] = Nystrom approximation to kernel'''\n",
    "        \n",
    "        X = X.sum(dim=0).numpy()\n",
    "        K_nq = self._pairwise_kernels(X, self.components_, self.kernel)\n",
    "        K_approx = K_nq @ self.normalization_ @ K_nq.T\n",
    "        K_approx = torch.tensor(K_approx)\n",
    "        return LazyTensor(K_approx[None,:,:])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "0_0U3bCgEUQz"
   },
   "outputs": [],
   "source": [
    "# NUMPY gen data\n",
    "M, N = (5000, 5000) if pykeops.config.gpu_available else (2000, 2000)\n",
    "\n",
    "t = np.linspace(0, 2 * np.pi, M + 1)[:-1]\n",
    "x = np.stack((0.4 + 0.4 * (t / 7) * np.cos(t), 0.5 + 0.3 * np.sin(t)), 1)\n",
    "x = x + 0.01 * np.random.randn(*x.shape)\n",
    "x = x.astype(dtype)\n",
    "\n",
    "y = np.random.randn(N, 2).astype(dtype)\n",
    "y = y / 10 + np.array([0.6, 0.6]).astype(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "polFC-ymVZK2",
    "outputId": "14b808c9-b9ce-492b-868c-d2d94eb8f598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pykeops.numpy.lazytensor.LazyTensor.LazyTensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "kernel K_nq and normalisation\n",
      "[[0.97277653 0.94454575 0.9583175  ... 0.93694556 0.91865563 0.91584736]\n",
      " [0.9710361  0.9485484  0.96028477 ... 0.93645626 0.9224755  0.9138108 ]\n",
      " [0.9725648  0.9498752  0.9640769  ... 0.9405182  0.9211253  0.91736037]\n",
      " ...\n",
      " [0.875665   0.7318018  0.75065804 ... 0.7782721  0.7497433  0.8007208 ]\n",
      " [0.88536566 0.72463804 0.75535893 ... 0.7910082  0.73532104 0.81723213]\n",
      " [0.88104385 0.7367087  0.75702375 ... 0.78487855 0.75305444 0.8070697 ]]\n",
      "[[-98.4149      -2.7437384  -11.836015   ...   2.3420856    1.599436\n",
      "    0.42536885]\n",
      " [  7.4600897    6.114054    25.0116     ...   7.319084    -3.858205\n",
      "   -9.145769  ]\n",
      " [109.40387     21.012632    -7.9959846  ...  -2.5300145    1.2492018\n",
      "  -11.485975  ]\n",
      " ...\n",
      " [-77.89973      6.2144027    0.82074106 ...   4.882506     7.2108083\n",
      "  -13.289615  ]\n",
      " [ 78.70853      4.4706807    4.6666555  ...   8.346193   -16.480232\n",
      "   12.601715  ]\n",
      " [-15.062228   -11.799507   -13.5548115  ...  12.707085     7.7864676\n",
      "   -0.55266905]]\n",
      "<class 'pykeops.numpy.lazytensor.LazyTensor.LazyTensor'>\n",
      "transformed_data shape\n",
      "(1, 5000, 500)\n",
      "(5000, 500) (1, 500)\n"
     ]
    }
   ],
   "source": [
    "nystroem = LazyNystrom_N(kernel='rbf')\n",
    "X = LazyTensor(x[:, None, :])\n",
    "data = nystroem.fit(X)\n",
    "transformed_data = nystroem.transform(X)#.sum(dim=0)\n",
    "\n",
    "print(\"transformed_data shape\")\n",
    "print(transformed_data.shape)\n",
    "transformed1 = transformed_data.sum(dim=0)\n",
    "transformed2 = transformed_data.sum(dim=1)\n",
    "print(transformed1.shape, transformed2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "OhYKP54vhEpb",
    "outputId": "88758d66-cee0-4aea-eccb-2c586b231db5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-fbdb9986fb0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the cluster centroid which is closest to the (.43,.6) point:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdist_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_centroids\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclust_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m500000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_centroids' is not defined"
     ]
    }
   ],
   "source": [
    "# Find the cluster centroid which is closest to the (.43,.6) point:\n",
    "dist_target = np.sum(((x_centroids - np.array([0.43, 0.6]).astype(dtype)) ** 2), axis=1)\n",
    "clust_i = np.argmin(dist_target)\n",
    "\n",
    "if M + N <= 500000:\n",
    "    ranges_i, slices_j, redranges_j = ranges_ij[0:3]\n",
    "    start_i, end_i = ranges_i[clust_i]  # Indices of the points that make up our cluster\n",
    "    start, end = (\n",
    "        slices_j[clust_i - 1],\n",
    "        slices_j[clust_i],\n",
    "    )  # Ranges of the cluster's neighbors\n",
    "\n",
    "    keep = keep.astype(float)\n",
    "    keep[clust_i] += 2\n",
    "\n",
    "    plt.ion()\n",
    "    plt.matshow(keep)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.scatter(\n",
    "        x[:, 0],\n",
    "        x[:, 1],\n",
    "        c=x_labels,\n",
    "        cmap=plt.cm.Wistia,\n",
    "        s=25 * 500 / len(x),\n",
    "        label=\"Target points\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        y[:, 0],\n",
    "        y[:, 1],\n",
    "        c=y_labels,\n",
    "        cmap=plt.cm.winter,\n",
    "        s=25 * 500 / len(y),\n",
    "        label=\"Source points\",\n",
    "    )\n",
    "\n",
    "    # Target clusters:\n",
    "    for start_j, end_j in redranges_j[start:end]:\n",
    "        plt.scatter(\n",
    "            y[start_j:end_j, 0], y[start_j:end_j, 1], c=\"magenta\", s=50 * 500 / len(y)\n",
    "        )\n",
    "\n",
    "    # Source cluster:\n",
    "    plt.scatter(\n",
    "        x[start_i:end_i, 0],\n",
    "        x[start_i:end_i, 1],\n",
    "        c=\"cyan\",\n",
    "        s=10,\n",
    "        label=\"Cluster {}\".format(clust_i),\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        x_centroids[:, 0],\n",
    "        x_centroids[:, 1],\n",
    "        c=\"black\",\n",
    "        s=10,\n",
    "        alpha=0.5,\n",
    "        label=\"Cluster centroids\",\n",
    "    )\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # sphinx_gallery_thumbnail_number = 2\n",
    "    plt.axis(\"equal\")\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CT1OKK1lWw2V"
   },
   "outputs": [],
   "source": [
    "\n",
    "##########################################################################\n",
    "\n",
    "# Same as LazyNystrom_N but written with Pytorch\n",
    "\n",
    "class LazyNystrom_T:\n",
    "    '''\n",
    "        Class to implement Nystrom on torch LazyTensors.\n",
    "        This class works as an interface between lazy tensors and \n",
    "        the Nystrom algorithm in NumPy.\n",
    "\n",
    "        * The fit method computes K^{-1}_q.\n",
    "\n",
    "        * The transform method maps the data into the feature space underlying\n",
    "        the Nystrom-approximated kernel.\n",
    "\n",
    "        * The method K_approx directly computes the Nystrom approximation.\n",
    "\n",
    "        Parameters:\n",
    "\n",
    "        n_components [int] = how many samples to select from data.\n",
    "        kernel [str] = type of kernel to use. Current options = {linear, rbf}.\n",
    "        gamma [float] = exponential constant for the RBF kernel. \n",
    "\n",
    "    '''\n",
    "  \n",
    "    def __init__(self, n_components=100, kernel='linear',  gamma:float = 1., \n",
    "                 random_state=None ):\n",
    "        \n",
    "        self.n_components = n_components\n",
    "        self.kernel = kernel\n",
    "        self.random_state = random_state\n",
    "        self.gamma = gamma\n",
    "\n",
    "\n",
    "    def fit(self, X:LazyTensor):\n",
    "        ''' \n",
    "        Args:   X = torch lazy tensor with features of shape # WHY INPUT IS LAZY TENSOR\n",
    "                (1, n_samples, n_features)\n",
    "\n",
    "        Returns: Fitted instance of the class\n",
    "        '''\n",
    "\n",
    "        # Basic checks: we have a lazy tensor and n_components isn't too large\n",
    "        assert type(X) == LazyTensor, 'Input to fit(.) must be a LazyTensor.'\n",
    "        assert X.shape[0] >= self.n_components, f'The application needs X.shape[1] >= n_components.'\n",
    "\n",
    "        X = X#.sum(dim=0) # ASK ABOUT REDOCTION\n",
    "        \n",
    "        # Number of samples\n",
    "        n_samples = X.size(0)\n",
    "        # Define basis\n",
    "        rnd = check_random_state(self.random_state)\n",
    "        inds = rnd.permutation(n_samples)\n",
    "        basis_inds = inds[:self.n_components]\n",
    "        basis = X[basis_inds]\n",
    "        # Build smaller kernel\n",
    "        basis_kernel = self._pairwise_kernels(basis, kernel = self.kernel)  \n",
    "        # Get SVD\n",
    "        U, S, V = torch.svd(basis_kernel)\n",
    "        S = torch.maximum(S, torch.ones(S.size()) * 1e-12)\n",
    "        self.normalization_ = torch.mm(U / np.sqrt(S), V.t())\n",
    "        self.components_ = basis\n",
    "        self.component_indices_ = inds\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def _pairwise_kernels(self, x:torch.tensor, y:torch.tensor = None, kernel='linear',\n",
    "                          gamma = 1.) -> torch.tensor:\n",
    "        '''Helper function to build kernel\n",
    "        \n",
    "        Args:   X = torch tensor of dimension 2.\n",
    "                K_type = type of Kernel to return\n",
    "        '''\n",
    "        \n",
    "        if y is None:\n",
    "            y = x\n",
    "        if kernel == 'linear':\n",
    "            K = x @ y.T\n",
    "        elif kernel == 'rbf':\n",
    "            K =  ( (x[:,None,:] - y[None,:,:])**2 ).sum(-1)\n",
    "            K = torch.exp(- gamma * K )\n",
    "\n",
    "        return K\n",
    "\n",
    "    def transform(self, X:LazyTensor) -> LazyTensor:\n",
    "        ''' Applies transform on the data.\n",
    "        \n",
    "        Args:\n",
    "            X [LazyTensor] = data to transform\n",
    "        Returns\n",
    "            X [LazyTensor] = data after transformation\n",
    "        '''\n",
    "        \n",
    "        X = X.sum(dim=0)\n",
    "        K_nq = self._pairwise_kernels(X, self.components_, self.kernel)\n",
    "        return LazyTensor((K_nq @ self.normalization_.t())[None,:,:])\n",
    "\n",
    "    \n",
    "    def K_approx(self, X:LazyTensor) -> LazyTensor:\n",
    "        ''' Function to return Nystrom approximation to the kernel.\n",
    "        \n",
    "        Args:\n",
    "            X[LazyTensor] = data used in fit(.) function.\n",
    "        Returns\n",
    "            K[LazyTensor] = Nystrom approximation to kernel'''\n",
    "        \n",
    "        X = X.sum(dim=0)\n",
    "        K_nq = self._pairwise_kernels(X, self.components_, self.kernel)\n",
    "        K_approx = K_nq @ self.normalization_ @ K_nq.t()\n",
    "        return LazyTensor(K_approx[None,:,:])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Nystrom_work_nystrom_master_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
