{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nystrom_common.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJpPnus_x3m6"
      },
      "source": [
        "# Nystrom_common class\n",
        "\n",
        "*     Note: k_approx to be added in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuFTDo7htDgC"
      },
      "source": [
        "# If using colab, make sure you install via:  !pip install pykeops[full] > log.log\n",
        "# makes plot outputs appear and be stored within the notebook\n",
        "%matplotlib inline \n",
        "\n",
        "!apt-get install cuda=10.2.89-1\n",
        "!pip install si_prefix\n",
        "!pip install sphinx\n",
        "!pip install pykeops[full] > log.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5Oc5uQi3GD_",
        "outputId": "f510bced-55f1-4214-dca5-cd8867e5222c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqinKAuq3GtM",
        "outputId": "076df10d-7094-4d30-f08c-6a1337dd8c4b"
      },
      "source": [
        "cd /content/drive/MyDrive/keops"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/keops\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_vC3F7--DN3"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/keops')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIqgr0Rch9_p"
      },
      "source": [
        "from numpy_utils import numpytools\n",
        "from torch_utils import torchtools\n",
        "\n",
        "# from common.nystrom import Nystrom_common -> needed when integrating into the lib"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnWh01kbsI7-"
      },
      "source": [
        "import numpy as np\n",
        "import pykeops\n",
        "import numbers\n",
        "import torch\n",
        "\n",
        "# For LinearOperator math\n",
        "from scipy.sparse.linalg import aslinearoperator, eigsh\n",
        "from scipy.sparse.linalg.interface import IdentityOperator"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZeLCOPCiODF"
      },
      "source": [
        "## Abstract class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOUGHMPYsL-w"
      },
      "source": [
        "class Nystrom_common:\n",
        "\n",
        "    def __init__(self, n_components=100, kernel='rbf', sigma:float = 1.,\n",
        "            exp_sigma:float = 1.0, eps:float = 0.05, mask_radius:float = None,\n",
        "            k_means = 10, n_iter:int = 10, inv_eps:float = None, dtype = np.float32, \n",
        "            backend = None, verbose = False, random_state=None, tools = None): \n",
        "\n",
        "        self.n_components = n_components\n",
        "        self.kernel = kernel\n",
        "        self.random_state = random_state\n",
        "        self.sigma = sigma\n",
        "        self.exp_sigma = exp_sigma\n",
        "        self.eps = eps\n",
        "        self.mask_radius = mask_radius\n",
        "        self.k_means = k_means\n",
        "        self.n_iter = n_iter\n",
        "        self.dtype = dtype\n",
        "        self.tools = None\n",
        "        self.verbose = verbose # -> NUMPY ONLY\n",
        "\n",
        "        ### THIS IS DIFFERENT -> CAN IT BE MERGED OR NOT?\n",
        "        if not backend:\n",
        "            self.backend = 'GPU' if pykeops.config.gpu_available else 'CPU'\n",
        "        else:\n",
        "            self.backend = backend\n",
        "        # --------end of code to check\n",
        "\n",
        "        # as of now torch has some extra lines for linear kernel -> delete that\n",
        "        if inv_eps:\n",
        "            self.inv_eps = inv_eps\n",
        "        else:\n",
        "            self.inv_eps = 1e-8\n",
        "\n",
        "        if not mask_radius:\n",
        "            if kernel == 'rbf':\n",
        "                self.mask_radius = 2* np.sqrt(2) * self.sigma\n",
        "            elif kernel == 'exp':\n",
        "                self.mask_radius = 8 * self.exp_sigma\n",
        "\n",
        "    def fit(self, x):\n",
        "        ### UPDATE DOCSTRING\n",
        "        ''' \n",
        "        Args:   x = numpy array of shape (n_samples, n_features)\n",
        "        Returns: Fitted instance of the class\n",
        "        '''\n",
        "\n",
        "        # specific to numpy, but i set verbose = None in torch so this should be \n",
        "        # skipped\n",
        "        if self.verbose:\n",
        "            print(f'Working with backend = {self.backend}')\n",
        "        \n",
        "        # Basic checks\n",
        "\n",
        "        ### this uses a common method - how do i personalize the error message?\n",
        "        assert self.tools.is_tensor(x), 'Input to fit(.) must be an array.'\n",
        "\n",
        "        ### can i use .shape for a tensor, too ?\n",
        "        assert x.shape[0] >= self.n_components, 'The application needs X.shape[0] >= n_components.'\n",
        "\n",
        "        assert self.exp_sigma > 0, 'Should be working with decaying exponential.'\n",
        "\n",
        "        # Update dtype\n",
        "        self._update_dtype(x) ### COMMENTED OUT FOR TORCH\n",
        "\n",
        "        # Number of samples\n",
        "        n_samples = x.shape[0]\n",
        "\n",
        "        # Define basis\n",
        "        rnd = self._check_random_state(self.random_state)\n",
        "        inds = rnd.permutation(n_samples) \n",
        "        basis_inds = inds[:self.n_components] \n",
        "        basis = x[basis_inds]\n",
        "        # Build smaller kernel\n",
        "\n",
        "        basis_kernel = self._pairwise_kernels(basis, dense=False)\n",
        "\n",
        "        # Decomposition is an abstract method that needs to be defined in each class\n",
        "        self.normalization_ = self._decomposition_and_norm(basis_kernel)\n",
        "\n",
        "        self.components_ = basis\n",
        "        self.component_indices_ = inds\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _decomposition_and_norm(self, basis_kernel):\n",
        "        \"\"\"\n",
        "        to be defined in the lang-specific classes\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def transform(self, x):\n",
        "        ### UPDATE DOCSTRING\n",
        "        ''' Applies transform on the data.\n",
        "        \n",
        "        Args:\n",
        "            X [np.array] = data to transform\n",
        "        Returns\n",
        "            X [np.array] = data after transformation\n",
        "        '''\n",
        "\n",
        "        K_nq = self._pairwise_kernels(x, self.components_, dense=True)\n",
        "        x_new = K_nq @ self.tools.transpose(self.normalization_) ### COMMON TRANSFORM NEEDED\n",
        "        return x_new\n",
        "\n",
        "    def _pairwise_kernels(self, x, y = None, dense = False):\n",
        "        ### UPDATE DOCSTRING\n",
        "        '''Helper function to build kernel\n",
        "        \n",
        "        Args:   x[np.array] = data\n",
        "                y[np.array] = array \n",
        "                dense[bool] = False to work with lazy tensor reduction,\n",
        "                              True to work with dense arrays\n",
        "        Returns:\n",
        "                K_ij[LazyTensor] if dense = False\n",
        "                K_ij[np.array] if dense = True\n",
        "\n",
        "        '''\n",
        "        if y is None:\n",
        "            y = x\n",
        "        if self.kernel == 'rbf':\n",
        "            x /= self.sigma\n",
        "            y /= self.sigma\n",
        "            if dense:\n",
        "                x_i, x_j = x[:, None, :], y[None, :, :]\n",
        "                K_ij = self.tools.exp( -(( (x_i - x_j)**2 ).sum(axis=2)) )\n",
        "            else:\n",
        "                x_i, x_j = LazyTensor(x[:, None, :]), LazyTensor(y[None, :, :])\n",
        "                K_ij = ( -(( (x_i - x_j)**2 ).sum(dim=2) ) ).exp()\n",
        "                # block-sparse reduction preprocess\n",
        "                K_ij = self._Gauss_block_sparse_pre(x, y, K_ij)\n",
        "        elif self.kernel == 'exp':\n",
        "            x /= self.exp_sigma\n",
        "            y /= self.exp_sigma\n",
        "            if dense:\n",
        "                x_i, x_j = x[:, None, :], y[None, :, :]\n",
        "                K_ij =  self.tools.exp(-self.tools.sqrt( ( ((x_i - x_j) ** 2).sum(axis=2) )))\n",
        "            else:\n",
        "                x_i, x_j = LazyTensor(x[:, None, :]), LazyTensor(y[None, :, :])\n",
        "                K_ij = (-(((x_i - x_j) ** 2).sum(-1)).sqrt()).exp()\n",
        "                # block-sparse reduction preprocess\n",
        "                K_ij = self._Gauss_block_sparse_pre(x, y, K_ij) # TODO \n",
        "       \n",
        "        if not dense:\n",
        "            K_ij.backend = self.backend\n",
        "        \n",
        "        return K_ij\n",
        "\n",
        "    def _Gauss_block_sparse_pre(self, x, y, K_ij):\n",
        "        ''' \n",
        "        Helper function to preprocess data for block-sparse reduction\n",
        "        of the Gaussian kernel\n",
        "    \n",
        "        Args: \n",
        "            x[np.array], y[np.array] = arrays giving rise to Gaussian kernel K(x,y)\n",
        "            K_ij[LazyTensor_n] = symbolic representation of K(x,y)\n",
        "            eps[float] = size for square bins\n",
        "        Returns:\n",
        "            K_ij[LazyTensor_n] = symbolic representation of K(x,y) with \n",
        "                                set sparse ranges\n",
        "        '''\n",
        "        # labels for low dimensions\n",
        "        if x.shape[1] < 4 or y.shape[1] < 4:\n",
        "            x_labels = grid_cluster(x, self.eps) \n",
        "            y_labels = grid_cluster(y, self.eps) \n",
        "            # range and centroid per class\n",
        "            x_ranges, x_centroids, _ = cluster_ranges_centroids(x, x_labels)\n",
        "            y_ranges, y_centroids, _ = cluster_ranges_centroids(y, y_labels)\n",
        "        else:\n",
        "        # labels for higher dimensions\n",
        "            x_labels, x_centroids = self._KMeans(x)\n",
        "            y_labels, y_centroids = self._KMeans(y)\n",
        "            # compute ranges\n",
        "            x_ranges = cluster_ranges(x_labels)\n",
        "            y_ranges = cluster_ranges(y_labels)\n",
        "\n",
        "        # sort points\n",
        "        x, x_labels = sort_clusters(x, x_labels)\n",
        "        y, y_labels = sort_clusters(y, y_labels) \n",
        "        # Compute a coarse Boolean mask:\n",
        "        if self.kernel == 'rbf':\n",
        "            D = self.tools.arraysum((x_centroids[:, None, :] - y_centroids[None, :, :]) ** 2, 2)\n",
        "        elif self.kernel == 'exp':\n",
        "            D = self.tools.sqrt(self.tools.arraysum((x_centroids[:, None, :] - y_centroids[None, :, :]) ** 2, 2))\n",
        "        keep = D < (self.mask_radius) ** 2\n",
        "        # mask -> set of integer tensors\n",
        "        ranges_ij = from_matrix(x_ranges, y_ranges, keep)\n",
        "        K_ij.ranges = ranges_ij  # block-sparsity pattern\n",
        "\n",
        "        return K_ij\n",
        "\n",
        "    def _KMeans(self,x):\n",
        "        ''' KMeans with Pykeops to do binning of original data.\n",
        "        Args:\n",
        "            x[np.array] = data\n",
        "            k_means[int] = number of bins to build\n",
        "            n_iter[int] = number iterations of KMeans loop\n",
        "        Returns:\n",
        "            labels[np.array] = class labels for each point in x\n",
        "            clusters[np.array] = coordinates for each centroid\n",
        "        '''\n",
        "        N, D = x.shape  \n",
        "        clusters = self.tools.copy(x[:self.k_means, :])  # initialization of clusters\n",
        "        x_i = LazyTensor(x[:, None, :])  \n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "\n",
        "            clusters_j = LazyTensor(clusters[None, :, :])  \n",
        "            D_ij = ((x_i - clusters_j) ** 2).sum(-1)  # points-clusters kernel\n",
        "            labels = self._astype(D_ij.argmin(axis=1), int).reshape(N)  # Points -> Nearest cluster\n",
        "            Ncl = self._astype(self.tools.bincount(labels), self.dtype)  # Class weights\n",
        "            for d in range(D):  # Compute the cluster centroids with bincount:\n",
        "                clusters[:, d] = self.tools.bincount(labels, weights=x[:, d]) / Ncl\n",
        "\n",
        "        return labels, clusters\n",
        "\n",
        "    def _astype(self, data, type):\n",
        "        return data\n",
        "\n",
        "    def _update_dtype(self,x):\n",
        "        ''' Helper function that sets dtype to that of \n",
        "            the given data in the fitting step.\n",
        "            \n",
        "        Args:\n",
        "            x [np.array] = raw data to remap\n",
        "        Returns:\n",
        "            nothing\n",
        "        '''\n",
        "        self.dtype = x.dtype\n",
        "        self.inv_eps = np.array([self.inv_eps]).astype(self.dtype)[0]\n",
        "\n",
        "    def _check_random_state(self, seed):\n",
        "        '''Set/get np.random.RandomState instance for permutation\n",
        "\n",
        "        Args\n",
        "            seed[None, int] \n",
        "        Returns:\n",
        "            numpy random state\n",
        "        '''\n",
        "        if seed is None:\n",
        "            return np.random.mtrand._rand\n",
        "        elif type(seed) == int:\n",
        "            return np.random.RandomState(seed)\n",
        "        raise ValueError(f'Seed {seed} must be None or an integer.')\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQAToZ2M3tt-"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg-K9flslgvQ"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# data\n",
        "\n",
        "length = 10000\n",
        "n_sampling = 500\n",
        "\n",
        "# data set with clusters\n",
        "data_clustered, _ = make_blobs(n_samples= length, n_features=3, centers=5)\n",
        "data_clustered_t = torch.tensor(data_clustered, dtype=torch.float32)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv-Mo2bsiSvD"
      },
      "source": [
        "## Numpy class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOWrlaM5iGb-"
      },
      "source": [
        "from pykeops.numpy import LazyTensor\n",
        "from pykeops.numpy.cluster import grid_cluster\n",
        "from pykeops.numpy.cluster import from_matrix\n",
        "from pykeops.numpy.cluster import cluster_ranges_centroids, cluster_ranges\n",
        "from pykeops.numpy.cluster import sort_clusters\n",
        "\n",
        "class Nystrom_NK(Nystrom_common):\n",
        "\n",
        "    def __init__(self, n_components=100, kernel='rbf', sigma:float = 1.,\n",
        "            exp_sigma:float = 1.0, eps:float = 0.05, mask_radius:float = None,\n",
        "            k_means = 10, n_iter:int = 10, inv_eps:float = None, dtype = np.float32, \n",
        "            backend = None, verbose = False, random_state=None, tools = None):\n",
        "\n",
        "        super().__init__(n_components, kernel, sigma, exp_sigma, eps, mask_radius,\n",
        "                         k_means, n_iter, inv_eps, dtype, backend, verbose, random_state)\n",
        "        \n",
        "        self.tools = numpytools\n",
        "        \n",
        "    def _decomposition_and_norm(self, basis_kernel):\n",
        "\n",
        "        K_linear = aslinearoperator(basis_kernel)\n",
        "        # K <- K + eps\n",
        "        K_linear = K_linear + IdentityOperator(K_linear.shape, dtype=self.dtype) * self.inv_eps\n",
        "        k = K_linear.shape[0] - 1\n",
        "        S, U = eigsh(K_linear, k=k, which='LM')\n",
        "        S = np.maximum(S, 1e-12)\n",
        "\n",
        "        return np.dot(U / np.sqrt(S), U.T)\n",
        "\n",
        "    def K_approx(self, x:np.array) -> np.array:\n",
        "        ''' Function to return Nystrom approximation to the kernel.\n",
        "        \n",
        "        Args:\n",
        "            X[np.array] = data used in fit(.) function.\n",
        "        Returns\n",
        "            K[np.array] = Nystrom approximation to kernel'''\n",
        "    \n",
        "        K_nq = self._pairwise_kernels(x, self.components_, dense=True)\n",
        "        # For arrays: K_approx = K_nq @ K_q_inv @ K_nq.T\n",
        "        # But to use @ with lazy tensors we have:\n",
        "        K_q_inv = self.normalization_.T @ self.normalization_\n",
        "        K_approx = K_nq @ (K_nq @ K_q_inv ).T\n",
        "        return K_approx.T \n",
        "\n",
        "    def _astype(self, data, d_type):\n",
        "        return data.astype(d_type)\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WFPBWtj3xPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6741d81a-b6bd-4d47-8a5e-dcaf98505ffe"
      },
      "source": [
        "Nystrom_n = Nystrom_NK(n_components = n_sampling, kernel = 'rbf', random_state = 0).fit(data_clustered)\n",
        "X_new = Nystrom_n.transform(data_clustered)\n",
        "print(X_new)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.42059824e-13 -1.55609038e-12  5.54878433e-13 ... -1.32998794e-12\n",
            "  -4.34449577e-13  8.81071264e-02]\n",
            " [ 4.14120202e-12 -1.18383725e-11  8.37015162e-12 ...  3.33310623e-12\n",
            "  -1.87731258e-11  3.43142639e-04]\n",
            " [-8.77232119e-12 -1.44424937e-11  7.79232872e-13 ...  2.95213893e-11\n",
            "   2.40884278e+02 -8.81582458e-12]\n",
            " ...\n",
            " [-6.23601415e-12  5.31719945e-12 -1.08875306e-11 ...  9.50387839e-12\n",
            "   2.57495022e-11  1.18679847e-01]\n",
            " [-1.10843734e-12 -1.18425358e-12  9.16791026e-13 ... -2.55597858e-12\n",
            "   4.18685743e-13  1.11279659e-01]\n",
            " [-4.53859328e-13 -4.25322301e-13 -3.54006946e-13 ...  1.46565331e-12\n",
            "   2.42316418e-12 -2.22560924e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FghgEhJEiW1F"
      },
      "source": [
        "## Torch class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPyCvSXdiKj8"
      },
      "source": [
        "from pykeops.torch import LazyTensor\n",
        "from pykeops.torch.cluster import grid_cluster\n",
        "from pykeops.torch.cluster import from_matrix\n",
        "from pykeops.torch.cluster import cluster_ranges_centroids, cluster_ranges\n",
        "from pykeops.torch.cluster import sort_clusters\n",
        "\n",
        "class Nystrom_TK(Nystrom_common):\n",
        "    \n",
        "    def __init__(self, n_components=100, kernel='rbf', sigma:float = 1.,\n",
        "            exp_sigma:float = 1.0, eps:float = 0.05, mask_radius:float = None,\n",
        "            k_means = 10, n_iter:int = 10, inv_eps:float = None, dtype = np.float32, \n",
        "            backend = None, verbose = False, random_state=None, tools = None):\n",
        "        \n",
        "        super().__init__(n_components, kernel, sigma, exp_sigma, eps, mask_radius,\n",
        "                         k_means, n_iter, inv_eps, dtype, backend, verbose, random_state)\n",
        "        \n",
        "        self.tools = torchtools\n",
        "\n",
        "        # as of now torch doesn't deal w/ these two, so just make them null?\n",
        "        self.backend = None\n",
        "        self.verbose = None\n",
        "\n",
        "    # is this enough to overwrite the superclass function & make it do nothing?\n",
        "    def _update_dtype(self, x):\n",
        "        pass\n",
        "    \n",
        "    def _decomposition_and_norm(self, basis_kernel):\n",
        "        \n",
        "        basis_kernel = basis_kernel @ torch.diag(torch.ones(basis_kernel.shape[1]))\n",
        "        U, S, V = torch.svd(basis_kernel)\n",
        "        S = torch.maximum(S, torch.ones(S.size()) * 1e-12)\n",
        "\n",
        "        return torch.mm(U / np.sqrt(S), V.t())\n",
        "    \n",
        "    def K_approx(self, X: torch.tensor) -> torch.tensor:\n",
        "        ''' Function to return Nystrom approximation to the kernel.\n",
        "        Args:\n",
        "            X[torch.tensor] = data used in fit(.) function.\n",
        "        Returns\n",
        "            K[torch.tensor] = Nystrom approximation to kernel'''\n",
        "\n",
        "        K_nq = self._pairwise_kernels(X, self.components_)\n",
        "        K_approx = K_nq @ self.normalization_ @ K_nq.t()\n",
        "        return K_approx"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMxFO0Mv30d_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d92aca-ad7d-4ab3-d48a-dc55c183a47b"
      },
      "source": [
        "Nystrom_t = Nystrom_TK(n_components = n_sampling, kernel = 'rbf', random_state = 0).fit(data_clustered_t)\n",
        "X_new = Nystrom_n.transform(data_clustered_t)\n",
        "print(X_new)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.4206e-13, -1.5561e-12,  5.5488e-13,  ..., -1.3300e-12,\n",
            "         -4.3445e-13,  8.8107e-02],\n",
            "        [ 4.1412e-12, -1.1838e-11,  8.3701e-12,  ...,  3.3331e-12,\n",
            "         -1.8773e-11,  3.4314e-04],\n",
            "        [-8.7723e-12, -1.4442e-11,  7.7925e-13,  ...,  2.9521e-11,\n",
            "          2.4088e+02, -8.8158e-12],\n",
            "        ...,\n",
            "        [-6.2360e-12,  5.3172e-12, -1.0888e-11,  ...,  9.5039e-12,\n",
            "          2.5750e-11,  1.1868e-01],\n",
            "        [-1.1084e-12, -1.1843e-12,  9.1679e-13,  ..., -2.5560e-12,\n",
            "          4.1869e-13,  1.1128e-01],\n",
            "        [-4.5386e-13, -4.2532e-13, -3.5401e-13,  ...,  1.4657e-12,\n",
            "          2.4232e-12, -2.2256e-05]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}